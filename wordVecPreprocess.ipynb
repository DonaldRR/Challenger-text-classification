{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/donald/datasets/ChallengerText_DS/wordVec'\n",
    "f = open(data_path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = int(f.readline().split(' ')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1348468"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1348468/1348468 [01:01<00:00, 21958.80it/s]\n"
     ]
    }
   ],
   "source": [
    "word_vec_dict = {}\n",
    "for i in tqdm(range(num_words)):\n",
    "    line = f.readline().split(' ')[:-1]\n",
    "    word = line[0]\n",
    "    vec = line[1:]\n",
    "    word_vec_dict[word] = np.array(vec, dtype=np.float16)\n",
    "np.save('wordVecDict.npy', word_vec_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_content = np.load('train_content.npy')\n",
    "Validation_content = np.load('validation_content.npy')\n",
    "Test_content = np.load('test_content.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105000/105000 [00:10<00:00, 10214.34it/s]\n",
      "100%|██████████| 15000/15000 [00:01<00:00, 10101.34it/s]\n",
      "100%|██████████| 15000/15000 [00:01<00:00, 10042.27it/s]\n"
     ]
    }
   ],
   "source": [
    "train_embeddings = []\n",
    "for i in tqdm(range(Train_content.shape[0])):\n",
    "    words = Train_content[i].split(' ')[1:-1]\n",
    "    vecs = []\n",
    "    for j in range(len(words)):\n",
    "        try:\n",
    "            vecs.append(word_vec_dict[words[j]])\n",
    "        except:\n",
    "            continue\n",
    "    train_embeddings.append(np.array(vecs))\n",
    "train_embeddings = np.array(train_embeddings)\n",
    "\n",
    "validation_embeddings = []\n",
    "for i in tqdm(range(Validation_content.shape[0])):\n",
    "    words = Validation_content[i].split(' ')[1:-1]\n",
    "    vecs = []\n",
    "    for j in range(len(words)):\n",
    "        try:\n",
    "            vecs.append(word_vec_dict[words[j]])\n",
    "        except:\n",
    "            continue\n",
    "    validation_embeddings.append(np.array(vecs))\n",
    "validation_embeddings = np.array(validation_embeddings)\n",
    "\n",
    "test_embeddings = []\n",
    "for i in tqdm(range(Test_content.shape[0])):\n",
    "    words = Test_content[i].split(' ')[1:-1]\n",
    "    vecs = []\n",
    "    for j in range(len(words)):\n",
    "        try:\n",
    "            vecs.append(word_vec_dict[words[j]])\n",
    "        except:\n",
    "            continue\n",
    "    test_embeddings.append(np.array(vecs))\n",
    "test_embeddings = np.array(test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4000e2d607af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_vecs.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'validation_vecs.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_vecs.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         format.write_array(fid, arr, allow_pickle=allow_pickle,\n\u001b[0;32m--> 521\u001b[0;31m                            pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    522\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mown_fid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.6/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mwrite_array\u001b[0;34m(fp, array, version, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpickle_kwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0mpickle_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_contiguous\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_contiguous\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# np.save('train_vecs.npy', train_embeddings)\n",
    "# np.save('validation_vecs.npy', validation_embeddings)\n",
    "# np.save('test_vecs.npy', test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Embedding, Activation, Input, Flatten, BatchNormalization, Conv1D, MaxPooling1D, Concatenate, LSTM\n",
    "def Base_model(input_node):\n",
    "    a = Input(shape = (input_node,300,))\n",
    "#     a = Embedding(len(dictionary),256)(c)\n",
    "#     conv_1 = Conv1D(filters = 6, kernel_size = 3, strides = 1, padding = 'same',activation = 'relu')(a)\n",
    "#     conv_2 = Conv1D(filters = 6, kernel_size = 4, strides = 1, padding = 'same',activation = 'relu')(a)\n",
    "#     conv_3 = Conv1D(filters = 6, kernel_size = 5, strides = 1, padding = 'same',activation = 'relu')(a)\n",
    "    \n",
    "#     pool_1 = MaxPooling1D(pool_size = 2, strides=1, padding = 'valid')(conv_1)\n",
    "#     pool_2 = MaxPooling1D(pool_size = 2, strides=1, padding = 'valid')(conv_2)\n",
    "#     pool_3 = MaxPooling1D(pool_size = 2, strides=1, padding = 'valid')(conv_3)\n",
    "    \n",
    "#     tmp_1 = Flatten()(pool_1)\n",
    "#     tmp_2 = Flatten()(pool_2)\n",
    "#     tmp_3 = Flatten()(pool_3)\n",
    "    \n",
    "#     tmp = Concatenate(axis = -1)([tmp_1, tmp_2, tmp_3])\n",
    "#     feature = Dense(256, activation='relu')(tmp_1)\n",
    "#     feature_bm = BatchNormalization()(feature)\n",
    "    \n",
    "    feature_1 = LSTM(256)(a)\n",
    "    feature_2 = LSTM(256)(a)\n",
    "    feature_3 = LSTM(256)(a)\n",
    "    feature_4 = LSTM(256)(a)\n",
    "    feature_5 = LSTM(256)(a)\n",
    "    feature_6 = LSTM(256)(a)\n",
    "    feature_7 = LSTM(256)(a)\n",
    "    feature_8 = LSTM(256)(a)\n",
    "    feature_9 = LSTM(256)(a)\n",
    "    feature_10 = LSTM(256)(a)\n",
    "    feature_11 = LSTM(256)(a)\n",
    "    feature_12 = LSTM(256)(a)\n",
    "    feature_13 = LSTM(256)(a)\n",
    "    feature_14 = LSTM(256)(a)\n",
    "    feature_15 = LSTM(256)(a)\n",
    "    feature_16 = LSTM(256)(a)\n",
    "    feature_17 = LSTM(256)(a)\n",
    "    feature_18 = LSTM(256)(a)\n",
    "    feature_19 = LSTM(256)(a)\n",
    "    feature_20 = LSTM(256)(a)\n",
    "    \n",
    "    \n",
    "    feature_11 = Dense(128, activation='softmax')(feature_1)\n",
    "    feature_21 = Dense(128, activation='softmax')(feature_2)\n",
    "    feature_31 = Dense(128, activation='softmax')(feature_3)\n",
    "    feature_41 = Dense(128, activation='softmax')(feature_4)\n",
    "    feature_51 = Dense(128, activation='softmax')(feature_5)\n",
    "    feature_61 = Dense(128, activation='softmax')(feature_6)\n",
    "    feature_71 = Dense(128, activation='softmax')(feature_7)\n",
    "    feature_81 = Dense(128, activation='softmax')(feature_8)\n",
    "    feature_91 = Dense(128, activation='softmax')(feature_9)\n",
    "    feature_101 = Dense(128, activation='softmax')(feature_10)\n",
    "    feature_111 = Dense(128, activation='softmax')(feature_11)\n",
    "    feature_121 = Dense(128, activation='softmax')(feature_12)\n",
    "    feature_131 = Dense(128, activation='softmax')(feature_13)\n",
    "    feature_141 = Dense(128, activation='softmax')(feature_14)\n",
    "    feature_151 = Dense(128, activation='softmax')(feature_15)\n",
    "    feature_161 = Dense(128, activation='softmax')(feature_16)\n",
    "    feature_171 = Dense(128, activation='softmax')(feature_17)\n",
    "    feature_181 = Dense(128, activation='softmax')(feature_18)\n",
    "    feature_191 = Dense(128, activation='softmax')(feature_19)\n",
    "    feature_201 = Dense(128, activation='softmax')(feature_20)\n",
    "    \n",
    "\n",
    "    output_1 = Dense(4, activation='softmax')(feature_11)\n",
    "    output_2 = Dense(4, activation='softmax')(feature_21)\n",
    "    output_3 = Dense(4, activation='softmax')(feature_31)\n",
    "    output_4 = Dense(4, activation='softmax')(feature_41)\n",
    "    output_5 = Dense(4, activation='softmax')(feature_51)\n",
    "    output_6 = Dense(4, activation='softmax')(feature_61)\n",
    "    output_7 = Dense(4, activation='softmax')(feature_71)\n",
    "    output_8 = Dense(4, activation='softmax')(feature_81)\n",
    "    output_9 = Dense(4, activation='softmax')(feature_91)\n",
    "    output_10 = Dense(4, activation='softmax')(feature_101)\n",
    "    output_11 = Dense(4, activation='softmax')(feature_111)\n",
    "    output_12 = Dense(4, activation='softmax')(feature_121)\n",
    "    output_13 = Dense(4, activation='softmax')(feature_131)\n",
    "    output_14 = Dense(4, activation='softmax')(feature_141)\n",
    "    output_15 = Dense(4, activation='softmax')(feature_151)\n",
    "    output_16 = Dense(4, activation='softmax')(feature_161)\n",
    "    output_17 = Dense(4, activation='softmax')(feature_171)\n",
    "    output_18 = Dense(4, activation='softmax')(feature_181)\n",
    "    output_19 = Dense(4, activation='softmax')(feature_191)\n",
    "    output_20 = Dense(4, activation='softmax')(feature_201)\n",
    "\n",
    "    output_final = [output_1,output_2,output_3,output_4,output_5,output_6,\n",
    "                   output_7,output_8,output_9,output_10,output_11,output_12,\n",
    "                   output_13,output_14,output_15,output_16,output_17,output_18,\n",
    "                   output_19,output_20]\n",
    "    \n",
    "    model = Model(inputs=a, outputs=output_final, name='base')\n",
    "    print(model.summary())\n",
    "    return model\n",
    "#     model.add(Embedding(len(dictionary), 128, input_length=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "class Metrics(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.val_f1s = []\n",
    "        self.val_recalls = []\n",
    "        self.val_precisions = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_predict = (numpy.asarray(self.model.predict(\n",
    "            self.validation_data[0]))).round()\n",
    "        val_targ = self.validation_data[1]\n",
    "        _val_f1 = f1_score(val_targ, val_predict)\n",
    "        _val_recall = recall_score(val_targ, val_predict)\n",
    "        _val_precision = precision_score(val_targ, val_predict)\n",
    "        self.val_f1s.append(_val_f1)\n",
    "        self.val_recalls.append(_val_recall)\n",
    "        self.val_precisions.append(_val_precision)\n",
    "        return\n",
    "metrics = Metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 300, 300)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_21 (LSTM)                  (None, 256)          570368      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 128)          32896       lstm_21[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_22 (LSTM)                  (None, 256)          570368      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_23 (LSTM)                  (None, 256)          570368      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_24 (LSTM)                  (None, 256)          570368      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_25 (LSTM)                  (None, 256)          570368      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_26 (LSTM)                  (None, 256)          570368      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_27 (LSTM)                  (None, 256)          570368      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_28 (LSTM)                  (None, 256)          570368      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_29 (LSTM)                  (None, 256)          570368      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_30 (LSTM)                  (None, 256)          570368      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_32 (LSTM)                  (None, 256)          570368      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_33 (LSTM)                  (None, 256)          570368      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_34 (LSTM)                  (None, 256)          570368      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_35 (LSTM)                  (None, 256)          570368      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_36 (LSTM)                  (None, 256)          570368      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_37 (LSTM)                  (None, 256)          570368      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_38 (LSTM)                  (None, 256)          570368      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_39 (LSTM)                  (None, 256)          570368      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_40 (LSTM)                  (None, 256)          570368      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 128)          32896       lstm_22[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 128)          32896       lstm_23[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 128)          32896       lstm_24[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 128)          32896       lstm_25[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 128)          32896       lstm_26[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 128)          32896       lstm_27[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 128)          32896       lstm_28[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 128)          32896       lstm_29[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 128)          32896       lstm_30[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 128)          16512       dense_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_51 (Dense)                (None, 128)          32896       lstm_32[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_52 (Dense)                (None, 128)          32896       lstm_33[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_53 (Dense)                (None, 128)          32896       lstm_34[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_54 (Dense)                (None, 128)          32896       lstm_35[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_55 (Dense)                (None, 128)          32896       lstm_36[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_56 (Dense)                (None, 128)          32896       lstm_37[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_57 (Dense)                (None, 128)          32896       lstm_38[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_58 (Dense)                (None, 128)          32896       lstm_39[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_59 (Dense)                (None, 128)          32896       lstm_40[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_60 (Dense)                (None, 4)            516         dense_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_61 (Dense)                (None, 4)            516         dense_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_62 (Dense)                (None, 4)            516         dense_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_63 (Dense)                (None, 4)            516         dense_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_64 (Dense)                (None, 4)            516         dense_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_65 (Dense)                (None, 4)            516         dense_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_66 (Dense)                (None, 4)            516         dense_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_67 (Dense)                (None, 4)            516         dense_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_68 (Dense)                (None, 4)            516         dense_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_69 (Dense)                (None, 4)            516         dense_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_70 (Dense)                (None, 4)            516         dense_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_71 (Dense)                (None, 4)            516         dense_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_72 (Dense)                (None, 4)            516         dense_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_73 (Dense)                (None, 4)            516         dense_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_74 (Dense)                (None, 4)            516         dense_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_75 (Dense)                (None, 4)            516         dense_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_76 (Dense)                (None, 4)            516         dense_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_77 (Dense)                (None, 4)            516         dense_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_78 (Dense)                (None, 4)            516         dense_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_79 (Dense)                (None, 4)            516         dense_59[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 11,488,848\n",
      "Trainable params: 11,488,848\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'label_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-acc7c00661b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mTrain_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mValidation_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mTrain_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mValidation_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mValidation_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'label_name' is not defined"
     ]
    }
   ],
   "source": [
    "model = Base_model(300)\n",
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['categorical_accuracy'])\n",
    "Train_label = []\n",
    "Validation_label = []\n",
    "for name in label_name:\n",
    "    Train_label.append(Train_labels[name])\n",
    "    Validation_label.append(Validation_labels[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_3 to have 3 dimensions, but got array with shape (105000, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-34e8f8043e97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'model_v'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrain_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1438\u001b[0m         \u001b[0msteps_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'steps_per_epoch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1439\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1440\u001b[0;31m         validation_split=validation_split)\n\u001b[0m\u001b[1;32m   1441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1442\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split)\u001b[0m\n\u001b[1;32m    942\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_element\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m     x, y, sample_weights = self._standardize_weights(x, y, sample_weight,\n\u001b[0;32m--> 944\u001b[0;31m                                                      class_weight, batch_size)\n\u001b[0m\u001b[1;32m    945\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_weights\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size)\u001b[0m\n\u001b[1;32m   1067\u001b[0m         \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m         exception_prefix='input')\n\u001b[0m\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    320\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_3 to have 3 dimensions, but got array with shape (105000, 1)"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "for i in range(5):\n",
    "    name = 'model_v' + str(i)\n",
    "    model.fit(train_embeddings, Train_label, epochs=1, batch_size = 64)\n",
    "    model.save(name)\n",
    "\n",
    "    val_test = model.predict(Validation_pad)\n",
    "    val_label = np.zeros((15000))\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "\n",
    "    for i in range(len(label_name)):\n",
    "        y_pred.append(np.argmax(val_test[i], axis = 1))\n",
    "        y_true.append(np.argmax(Validation_labels[label_name[i]], axis=1))\n",
    "    # val_label = np.copy(Validation_labels)\n",
    "\n",
    "    from sklearn import metrics\n",
    "\n",
    "    f1 = []\n",
    "    for j in range(len(y_pred)):\n",
    "        f1.append(metrics.f1_score(y_true[j], y_pred[j], average = 'micro'))\n",
    "\n",
    "        \n",
    "    print('================================================')\n",
    "    print(np.average(f1))\n",
    "    print('================================================')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
