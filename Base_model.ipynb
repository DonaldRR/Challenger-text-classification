{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##定义函数，进行分词和去停词\n",
    "\n",
    "import jieba\n",
    "from tqdm import *\n",
    "\n",
    "def stopwordslist(filepath):\n",
    "    stopwords = [line.strip() for line in open(filepath, 'r',encoding='utf-8').readlines()]\n",
    "    return stopwords\n",
    "\n",
    "def content_preprocess(Train_raw):\n",
    "    #content：需要分词，需要删除停词的内容list#\n",
    "    \n",
    "    #读取停词\n",
    "    filepath = 'stop_words_zh.txt'\n",
    "    stopwords = stopwordslist(filepath)\n",
    "    \n",
    "    #开始分词\n",
    "    content_all = []\n",
    "    for i in tqdm(range(len(Train_raw))):\n",
    "        content = Train_raw['content'][i]\n",
    "        out_str = ''\n",
    "        content_cut = jieba.cut(content, cut_all = True)\n",
    "        for word in content_cut:\n",
    "            if word not in stopwords:\n",
    "                if word != '' and '\\n' not in word:\n",
    "                    out_str = out_str + ' ' + word\n",
    "        out_str = out_str + '\\n' \n",
    "        content_all.append(out_str)\n",
    "    \n",
    "    return content_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##分别读取训练数据，验证数据和测试数据集\n",
    "import pandas as pd\n",
    "\n",
    "Train_data_raw = pd.read_csv('dataset\\sentiment_analysis_trainingset.csv')\n",
    "Validation_data_raw = pd.read_csv('dataset\\sentiment_analysis_validationset.csv')\n",
    "Test_data_raw = pd.read_csv('dataset\\sentiment_analysis_testa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                               | 0/105000 [00:00<?, ?it/s]Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\18092482\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.762 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "100%|█████████████████████████████████| 105000/105000 [04:24<00:00, 396.70it/s]\n",
      "100%|███████████████████████████████████| 15000/15000 [00:36<00:00, 405.98it/s]\n",
      "100%|███████████████████████████████████| 15000/15000 [00:37<00:00, 403.71it/s]\n"
     ]
    }
   ],
   "source": [
    "Train_content = content_preprocess(Train_data_raw)\n",
    "Validation_content = content_preprocess(Validation_data_raw)\n",
    "Test_content = content_preprocess(Test_data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在处理文本\n",
      "正在生成词典并保存\n"
     ]
    }
   ],
   "source": [
    "##对训练数据进行拟合，生成词典并保存，同时将验证和测试数据都转化为序列\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "print('正在处理文本')\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(Train_content)\n",
    "Train_sequence = tokenizer.texts_to_sequences(Train_content)\n",
    "Vlidation_sequence = tokenizer.texts_to_sequences(Validation_content)\n",
    "Test_sequence = tokenizer.texts_to_sequences(Test_content)\n",
    "\n",
    "#保存生成的词典\n",
    "print('正在生成词典并保存')\n",
    "dictionary = tokenizer.word_index\n",
    "file = 'dictionary.txt'\n",
    "f = open(file,'w',encoding='utf-8')\n",
    "f.write(str(dictionary))\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'location_traffic_convenience': array([[0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       ...,\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.]], dtype=float32), 'location_distance_from_business_district': array([[0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       ...,\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0.]], dtype=float32), 'location_easy_to_find': array([[0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       ...,\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0.]], dtype=float32), 'service_wait_time': array([[0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       ...,\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.]], dtype=float32), 'service_waiters_attitude': array([[0., 1., 0., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0.],\n",
      "       ...,\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0.]], dtype=float32), 'service_parking_convenience': array([[0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       ...,\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.]], dtype=float32), 'service_serving_speed': array([[0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.]], dtype=float32), 'price_level': array([[0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.]], dtype=float32), 'price_cost_effective': array([[0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       ...,\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.]], dtype=float32), 'price_discount': array([[0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1.]], dtype=float32), 'environment_decoration': array([[0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       ...,\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0.]], dtype=float32), 'environment_noise': array([[0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       ...,\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.]], dtype=float32), 'environment_space': array([[0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.]], dtype=float32), 'environment_cleaness': array([[0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       ...,\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0.]], dtype=float32), 'dish_portion': array([[0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 0., 0., 1.]], dtype=float32), 'dish_taste': array([[0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0.],\n",
      "       ...,\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0.]], dtype=float32), 'dish_look': array([[0., 1., 0., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       ...,\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0.]], dtype=float32), 'dish_recommendation': array([[0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       ...,\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.]], dtype=float32), 'others_overall_experience': array([[0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       ...,\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0.]], dtype=float32), 'others_willing_to_consume_again': array([[0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       ...,\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 0., 0., 1.]], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "#处理标签。\n",
    "\n",
    "label_name = Train_data_raw.keys()\n",
    "label_name = label_name.tolist()\n",
    "label_name.remove('id')\n",
    "label_name.remove('content')\n",
    "\n",
    "def label_process(label_ori):\n",
    "    label = label_ori.as_matrix()\n",
    "    label[label == -1] = 2\n",
    "    label[label == -2] = 3\n",
    "    label_onehot = tf.keras.utils.to_categorical(label)\n",
    "    return label_onehot\n",
    "    \n",
    "Train_labels = {}\n",
    "Validation_labels = {}\n",
    "\n",
    "#预处理训练集标签\n",
    "for i in range(len(label_name)):\n",
    "    tmp = label_process(Train_data_raw[label_name[i]])\n",
    "    Train_labels[label_name[i]] = tmp\n",
    "    \n",
    "#预处理验证集标签\n",
    "for i in range(len(label_name)):\n",
    "    tmp = label_process(Validation_data_raw[label_name[i]])\n",
    "    Validation_labels[label_name[i]] = tmp\n",
    "    \n",
    "print(Train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使文本序列等长\n",
    "import numpy as np\n",
    "Train_pad = tf.keras.preprocessing.sequence.pad_sequences(Train_sequence, maxlen=100,value=0.0, padding = 'post')\n",
    "Validation_pad = tf.keras.preprocessing.sequence.pad_sequences(Vlidation_sequence, maxlen=100,value=0.0, padding = 'post')\n",
    "Test_pad = tf.keras.preprocessing.sequence.pad_sequences(Test_sequence, maxlen=100,value=0.0, padding = 'post')\n",
    "\n",
    "Train_pad = np.array(Train_pad)\n",
    "Validation_pad = np.array(Validation_pad)\n",
    "Test_pad = np.array(Test_pad)\n",
    "\n",
    "Train_pad[Train_pad>len(dictionary)-1] = 0\n",
    "Validation_pad[Validation_pad>len(dictionary)-1] = 0\n",
    "Test_pad[Test_pad>len(dictionary)-1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Embedding, Activation, Input, Flatten, BatchNormalization, Conv1D, MaxPooling1D, Concatenate, LSTM\n",
    "def Base_model(input_node):\n",
    "    c = Input(shape = (input_node,))\n",
    "    a = Embedding(len(dictionary),256)(c)\n",
    "#     conv_1 = Conv1D(filters = 6, kernel_size = 3, strides = 1, padding = 'same',activation = 'relu')(a)\n",
    "#     conv_2 = Conv1D(filters = 6, kernel_size = 4, strides = 1, padding = 'same',activation = 'relu')(a)\n",
    "#     conv_3 = Conv1D(filters = 6, kernel_size = 5, strides = 1, padding = 'same',activation = 'relu')(a)\n",
    "    \n",
    "#     pool_1 = MaxPooling1D(pool_size = 2, strides=1, padding = 'valid')(conv_1)\n",
    "#     pool_2 = MaxPooling1D(pool_size = 2, strides=1, padding = 'valid')(conv_2)\n",
    "#     pool_3 = MaxPooling1D(pool_size = 2, strides=1, padding = 'valid')(conv_3)\n",
    "    \n",
    "#     tmp_1 = Flatten()(pool_1)\n",
    "#     tmp_2 = Flatten()(pool_2)\n",
    "#     tmp_3 = Flatten()(pool_3)\n",
    "    \n",
    "#     tmp = Concatenate(axis = -1)([tmp_1, tmp_2, tmp_3])\n",
    "#     feature = Dense(256, activation='relu')(tmp_1)\n",
    "#     feature_bm = BatchNormalization()(feature)\n",
    "    \n",
    "    feature_1 = LSTM(256)(a)\n",
    "    feature_2 = LSTM(256)(a)\n",
    "    feature_3 = LSTM(256)(a)\n",
    "    feature_4 = LSTM(256)(a)\n",
    "    feature_5 = LSTM(256)(a)\n",
    "    feature_6 = LSTM(256)(a)\n",
    "    feature_7 = LSTM(256)(a)\n",
    "    feature_8 = LSTM(256)(a)\n",
    "    feature_9 = LSTM(256)(a)\n",
    "    feature_10 = LSTM(256)(a)\n",
    "    feature_11 = LSTM(256)(a)\n",
    "    feature_12 = LSTM(256)(a)\n",
    "    feature_13 = LSTM(256)(a)\n",
    "    feature_14 = LSTM(256)(a)\n",
    "    feature_15 = LSTM(256)(a)\n",
    "    feature_16 = LSTM(256)(a)\n",
    "    feature_17 = LSTM(256)(a)\n",
    "    feature_18 = LSTM(256)(a)\n",
    "    feature_19 = LSTM(256)(a)\n",
    "    feature_20 = LSTM(256)(a)\n",
    "    \n",
    "    \n",
    "    feature_11 = Dense(128, activation='softmax')(feature_1)\n",
    "    feature_21 = Dense(128, activation='softmax')(feature_2)\n",
    "    feature_31 = Dense(128, activation='softmax')(feature_3)\n",
    "    feature_41 = Dense(128, activation='softmax')(feature_4)\n",
    "    feature_51 = Dense(128, activation='softmax')(feature_5)\n",
    "    feature_61 = Dense(128, activation='softmax')(feature_6)\n",
    "    feature_71 = Dense(128, activation='softmax')(feature_7)\n",
    "    feature_81 = Dense(128, activation='softmax')(feature_8)\n",
    "    feature_91 = Dense(128, activation='softmax')(feature_9)\n",
    "    feature_101 = Dense(128, activation='softmax')(feature_10)\n",
    "    feature_111 = Dense(128, activation='softmax')(feature_11)\n",
    "    feature_121 = Dense(128, activation='softmax')(feature_12)\n",
    "    feature_131 = Dense(128, activation='softmax')(feature_13)\n",
    "    feature_141 = Dense(128, activation='softmax')(feature_14)\n",
    "    feature_151 = Dense(128, activation='softmax')(feature_15)\n",
    "    feature_161 = Dense(128, activation='softmax')(feature_16)\n",
    "    feature_171 = Dense(128, activation='softmax')(feature_17)\n",
    "    feature_181 = Dense(128, activation='softmax')(feature_18)\n",
    "    feature_191 = Dense(128, activation='softmax')(feature_19)\n",
    "    feature_201 = Dense(128, activation='softmax')(feature_20)\n",
    "    \n",
    "\n",
    "    output_1 = Dense(4, activation='softmax')(feature_11)\n",
    "    output_2 = Dense(4, activation='softmax')(feature_21)\n",
    "    output_3 = Dense(4, activation='softmax')(feature_31)\n",
    "    output_4 = Dense(4, activation='softmax')(feature_41)\n",
    "    output_5 = Dense(4, activation='softmax')(feature_51)\n",
    "    output_6 = Dense(4, activation='softmax')(feature_61)\n",
    "    output_7 = Dense(4, activation='softmax')(feature_71)\n",
    "    output_8 = Dense(4, activation='softmax')(feature_81)\n",
    "    output_9 = Dense(4, activation='softmax')(feature_91)\n",
    "    output_10 = Dense(4, activation='softmax')(feature_101)\n",
    "    output_11 = Dense(4, activation='softmax')(feature_111)\n",
    "    output_12 = Dense(4, activation='softmax')(feature_121)\n",
    "    output_13 = Dense(4, activation='softmax')(feature_131)\n",
    "    output_14 = Dense(4, activation='softmax')(feature_141)\n",
    "    output_15 = Dense(4, activation='softmax')(feature_151)\n",
    "    output_16 = Dense(4, activation='softmax')(feature_161)\n",
    "    output_17 = Dense(4, activation='softmax')(feature_171)\n",
    "    output_18 = Dense(4, activation='softmax')(feature_181)\n",
    "    output_19 = Dense(4, activation='softmax')(feature_191)\n",
    "    output_20 = Dense(4, activation='softmax')(feature_201)\n",
    "\n",
    "    output_final = [output_1,output_2,output_3,output_4,output_5,output_6,\n",
    "                   output_7,output_8,output_9,output_10,output_11,output_12,\n",
    "                   output_13,output_14,output_15,output_16,output_17,output_18,\n",
    "                   output_19,output_20]\n",
    "    \n",
    "    model = Model(inputs=c, outputs=output_final, name='base')\n",
    "    print(model.summary())\n",
    "    return model\n",
    "#     model.add(Embedding(len(dictionary), 128, input_length=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "class Metrics(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.val_f1s = []\n",
    "        self.val_recalls = []\n",
    "        self.val_precisions = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_predict = (numpy.asarray(self.model.predict(\n",
    "            self.validation_data[0]))).round()\n",
    "        val_targ = self.validation_data[1]\n",
    "        _val_f1 = f1_score(val_targ, val_predict)\n",
    "        _val_recall = recall_score(val_targ, val_predict)\n",
    "        _val_precision = precision_score(val_targ, val_predict)\n",
    "        self.val_f1s.append(_val_f1)\n",
    "        self.val_recalls.append(_val_recall)\n",
    "        self.val_precisions.append(_val_precision)\n",
    "        return\n",
    "metrics = Metrics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 100, 256)     26466816    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_20 (LSTM)                  (None, 256)          525312      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 128)          32896       lstm_20[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_21 (LSTM)                  (None, 256)          525312      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_22 (LSTM)                  (None, 256)          525312      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_23 (LSTM)                  (None, 256)          525312      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_24 (LSTM)                  (None, 256)          525312      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_25 (LSTM)                  (None, 256)          525312      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_26 (LSTM)                  (None, 256)          525312      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_27 (LSTM)                  (None, 256)          525312      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_28 (LSTM)                  (None, 256)          525312      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_29 (LSTM)                  (None, 256)          525312      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_31 (LSTM)                  (None, 256)          525312      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_32 (LSTM)                  (None, 256)          525312      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_33 (LSTM)                  (None, 256)          525312      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_34 (LSTM)                  (None, 256)          525312      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_35 (LSTM)                  (None, 256)          525312      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_36 (LSTM)                  (None, 256)          525312      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_37 (LSTM)                  (None, 256)          525312      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_38 (LSTM)                  (None, 256)          525312      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_39 (LSTM)                  (None, 256)          525312      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 128)          32896       lstm_21[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 128)          32896       lstm_22[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 128)          32896       lstm_23[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 128)          32896       lstm_24[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 128)          32896       lstm_25[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 128)          32896       lstm_26[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 128)          32896       lstm_27[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 128)          32896       lstm_28[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 128)          32896       lstm_29[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 128)          16512       dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 128)          32896       lstm_31[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 128)          32896       lstm_32[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 128)          32896       lstm_33[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 128)          32896       lstm_34[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 128)          32896       lstm_35[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 128)          32896       lstm_36[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (None, 128)          32896       lstm_37[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 128)          32896       lstm_38[0][0]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 128)          32896       lstm_39[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 4)            516         dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 4)            516         dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 4)            516         dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 4)            516         dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 4)            516         dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 4)            516         dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 4)            516         dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 4)            516         dense_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 4)            516         dense_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_51 (Dense)                (None, 4)            516         dense_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_52 (Dense)                (None, 4)            516         dense_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_53 (Dense)                (None, 4)            516         dense_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_54 (Dense)                (None, 4)            516         dense_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_55 (Dense)                (None, 4)            516         dense_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_56 (Dense)                (None, 4)            516         dense_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_57 (Dense)                (None, 4)            516         dense_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_58 (Dense)                (None, 4)            516         dense_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_59 (Dense)                (None, 4)            516         dense_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_60 (Dense)                (None, 4)            516         dense_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_61 (Dense)                (None, 4)            516         dense_41[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 37,099,600\n",
      "Trainable params: 37,099,600\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Base_model(100)\n",
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['categorical_accuracy'])\n",
    "Train_label = []\n",
    "Validation_label = []\n",
    "for name in label_name:\n",
    "    Train_label.append(Train_labels[name])\n",
    "    Validation_label.append(Validation_labels[name])\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   448/105000 [..............................] - ETA: 20:02:07 - loss: 11.2517 - dense_42_loss: 0.5648 - dense_43_loss: 0.5616 - dense_44_loss: 0.5581 - dense_45_loss: 0.5639 - dense_46_loss: 0.5630 - dense_47_loss: 0.5662 - dense_48_loss: 0.5622 - dense_49_loss: 0.5602 - dense_50_loss: 0.5628 - dense_51_loss: 0.5597 - dense_52_loss: 0.5642 - dense_53_loss: 0.5626 - dense_54_loss: 0.5625 - dense_55_loss: 0.5629 - dense_56_loss: 0.5644 - dense_57_loss: 0.5626 - dense_58_loss: 0.5614 - dense_59_loss: 0.5627 - dense_60_loss: 0.5636 - dense_61_loss: 0.5624 - dense_42_categorical_accuracy: 0.0000e+00 - dense_43_categorical_accuracy: 0.4219 - dense_44_categorical_accuracy: 0.8281 - dense_45_categorical_accuracy: 0.0000e+00 - dense_46_categorical_accuracy: 0.1562 - dense_47_categorical_accuracy: 0.0156 - dense_48_categorical_accuracy: 0.1094 - dense_49_categorical_accuracy: 0.3594 - dense_50_categorical_accuracy: 0.0312 - dense_51_categorical_accuracy: 0.5781 - dense_52_categorical_accuracy: 0.0938 - dense_53_categorical_accuracy: 0.0312 - dense_54_categorical_accuracy: 0.2500 - dense_55_categorical_accuracy: 0.0938 - dense_56_categorical_accuracy: 0.1719 - dense_57_categorical_accuracy: 0.0938 - dense_58_categorical_accuracy: 0.5312 - dense_59_categorical_accuracy: 0.1719 - dense_60_categorical_accuracy: 0.1562 - dense_61_categorical_accuracy: 0.21 - ETA: 16:09:12 - loss: 11.2482 - dense_42_loss: 0.5644 - dense_43_loss: 0.5614 - dense_44_loss: 0.5582 - dense_45_loss: 0.5635 - dense_46_loss: 0.5625 - dense_47_loss: 0.5659 - dense_48_loss: 0.5619 - dense_49_loss: 0.5601 - dense_50_loss: 0.5625 - dense_51_loss: 0.5598 - dense_52_loss: 0.5641 - dense_53_loss: 0.5624 - dense_54_loss: 0.5626 - dense_55_loss: 0.5626 - dense_56_loss: 0.5642 - dense_57_loss: 0.5626 - dense_58_loss: 0.5611 - dense_59_loss: 0.5625 - dense_60_loss: 0.5638 - dense_61_loss: 0.5621 - dense_42_categorical_accuracy: 0.0000e+00 - dense_43_categorical_accuracy: 0.6250 - dense_44_categorical_accuracy: 0.7812 - dense_45_categorical_accuracy: 0.0156 - dense_46_categorical_accuracy: 0.1953 - dense_47_categorical_accuracy: 0.0156 - dense_48_categorical_accuracy: 0.1016 - dense_49_categorical_accuracy: 0.4375 - dense_50_categorical_accuracy: 0.0391 - dense_51_categorical_accuracy: 0.5312 - dense_52_categorical_accuracy: 0.0859 - dense_53_categorical_accuracy: 0.2344 - dense_54_categorical_accuracy: 0.2109 - dense_55_categorical_accuracy: 0.1172 - dense_56_categorical_accuracy: 0.2109 - dense_57_categorical_accuracy: 0.1094 - dense_58_categorical_accuracy: 0.6484 - dense_59_categorical_accuracy: 0.1484 - dense_60_categorical_accuracy: 0.1250 - dense_61_categorical_accuracy: 0.2812   - ETA: 15:27:50 - loss: 11.2444 - dense_42_loss: 0.5641 - dense_43_loss: 0.5613 - dense_44_loss: 0.5580 - dense_45_loss: 0.5631 - dense_46_loss: 0.5623 - dense_47_loss: 0.5656 - dense_48_loss: 0.5617 - dense_49_loss: 0.5599 - dense_50_loss: 0.5619 - dense_51_loss: 0.5595 - dense_52_loss: 0.5640 - dense_53_loss: 0.5622 - dense_54_loss: 0.5623 - dense_55_loss: 0.5625 - dense_56_loss: 0.5643 - dense_57_loss: 0.5625 - dense_58_loss: 0.5609 - dense_59_loss: 0.5622 - dense_60_loss: 0.5639 - dense_61_loss: 0.5620 - dense_42_categorical_accuracy: 0.0000e+00 - dense_43_categorical_accuracy: 0.6667 - dense_44_categorical_accuracy: 0.7760 - dense_45_categorical_accuracy: 0.0208 - dense_46_categorical_accuracy: 0.2604 - dense_47_categorical_accuracy: 0.0208 - dense_48_categorical_accuracy: 0.0781 - dense_49_categorical_accuracy: 0.4844 - dense_50_categorical_accuracy: 0.0365 - dense_51_categorical_accuracy: 0.5677 - dense_52_categorical_accuracy: 0.0781 - dense_53_categorical_accuracy: 0.3490 - dense_54_categorical_accuracy: 0.2448 - dense_55_categorical_accuracy: 0.0990 - dense_56_categorical_accuracy: 0.1979 - dense_57_categorical_accuracy: 0.1875 - dense_58_categorical_accuracy: 0.6510 - dense_59_categorical_accuracy: 0.1615 - dense_60_categorical_accuracy: 0.1042 - dense_61_categorical_accuracy: 0.30 - ETA: 15:07:55 - loss: 11.2417 - dense_42_loss: 0.5639 - dense_43_loss: 0.5614 - dense_44_loss: 0.5580 - dense_45_loss: 0.5627 - dense_46_loss: 0.5625 - dense_47_loss: 0.5652 - dense_48_loss: 0.5615 - dense_49_loss: 0.5597 - dense_50_loss: 0.5617 - dense_51_loss: 0.5596 - dense_52_loss: 0.5639 - dense_53_loss: 0.5621 - dense_54_loss: 0.5622 - dense_55_loss: 0.5625 - dense_56_loss: 0.5640 - dense_57_loss: 0.5624 - dense_58_loss: 0.5608 - dense_59_loss: 0.5620 - dense_60_loss: 0.5638 - dense_61_loss: 0.5618 - dense_42_categorical_accuracy: 0.0039 - dense_43_categorical_accuracy: 0.6680 - dense_44_categorical_accuracy: 0.7500 - dense_45_categorical_accuracy: 0.0352 - dense_46_categorical_accuracy: 0.2695 - dense_47_categorical_accuracy: 0.0156 - dense_48_categorical_accuracy: 0.0820 - dense_49_categorical_accuracy: 0.4922 - dense_50_categorical_accuracy: 0.0391 - dense_51_categorical_accuracy: 0.5508 - dense_52_categorical_accuracy: 0.0820 - dense_53_categorical_accuracy: 0.4414 - dense_54_categorical_accuracy: 0.2383 - dense_55_categorical_accuracy: 0.1406 - dense_56_categorical_accuracy: 0.2305 - dense_57_categorical_accuracy: 0.2422 - dense_58_categorical_accuracy: 0.6680 - dense_59_categorical_accuracy: 0.1641 - dense_60_categorical_accuracy: 0.1055 - dense_61_categorical_accuracy: 0.3242   - ETA: 14:55:11 - loss: 11.2379 - dense_42_loss: 0.5636 - dense_43_loss: 0.5611 - dense_44_loss: 0.5577 - dense_45_loss: 0.5624 - dense_46_loss: 0.5625 - dense_47_loss: 0.5649 - dense_48_loss: 0.5612 - dense_49_loss: 0.5597 - dense_50_loss: 0.5615 - dense_51_loss: 0.5593 - dense_52_loss: 0.5638 - dense_53_loss: 0.5619 - dense_54_loss: 0.5622 - dense_55_loss: 0.5623 - dense_56_loss: 0.5639 - dense_57_loss: 0.5623 - dense_58_loss: 0.5606 - dense_59_loss: 0.5618 - dense_60_loss: 0.5637 - dense_61_loss: 0.5617 - dense_42_categorical_accuracy: 0.0063 - dense_43_categorical_accuracy: 0.6969 - dense_44_categorical_accuracy: 0.7719 - dense_45_categorical_accuracy: 0.0312 - dense_46_categorical_accuracy: 0.2875 - dense_47_categorical_accuracy: 0.0156 - dense_48_categorical_accuracy: 0.0813 - dense_49_categorical_accuracy: 0.4938 - dense_50_categorical_accuracy: 0.1344 - dense_51_categorical_accuracy: 0.5687 - dense_52_categorical_accuracy: 0.0813 - dense_53_categorical_accuracy: 0.5000 - dense_54_categorical_accuracy: 0.2281 - dense_55_categorical_accuracy: 0.2125 - dense_56_categorical_accuracy: 0.2344 - dense_57_categorical_accuracy: 0.2750 - dense_58_categorical_accuracy: 0.6875 - dense_59_categorical_accuracy: 0.2344 - dense_60_categorical_accuracy: 0.1000 - dense_61_categorical_accuracy: 0.32 - ETA: 15:01:04 - loss: 11.2345 - dense_42_loss: 0.5634 - dense_43_loss: 0.5609 - dense_44_loss: 0.5574 - dense_45_loss: 0.5620 - dense_46_loss: 0.5625 - dense_47_loss: 0.5646 - dense_48_loss: 0.5611 - dense_49_loss: 0.5596 - dense_50_loss: 0.5614 - dense_51_loss: 0.5592 - dense_52_loss: 0.5637 - dense_53_loss: 0.5617 - dense_54_loss: 0.5621 - dense_55_loss: 0.5621 - dense_56_loss: 0.5637 - dense_57_loss: 0.5622 - dense_58_loss: 0.5604 - dense_59_loss: 0.5615 - dense_60_loss: 0.5636 - dense_61_loss: 0.5616 - dense_42_categorical_accuracy: 0.0078 - dense_43_categorical_accuracy: 0.7057 - dense_44_categorical_accuracy: 0.7760 - dense_45_categorical_accuracy: 0.0417 - dense_46_categorical_accuracy: 0.2943 - dense_47_categorical_accuracy: 0.0182 - dense_48_categorical_accuracy: 0.1354 - dense_49_categorical_accuracy: 0.5026 - dense_50_categorical_accuracy: 0.2188 - dense_51_categorical_accuracy: 0.5781 - dense_52_categorical_accuracy: 0.0755 - dense_53_categorical_accuracy: 0.5339 - dense_54_categorical_accuracy: 0.2318 - dense_55_categorical_accuracy: 0.2865 - dense_56_categorical_accuracy: 0.2552 - dense_57_categorical_accuracy: 0.2969 - dense_58_categorical_accuracy: 0.6875 - dense_59_categorical_accuracy: 0.3333 - dense_60_categorical_accuracy: 0.1042 - dense_61_categorical_accuracy: 0.32 - ETA: 15:09:22 - loss: 11.2315 - dense_42_loss: 0.5631 - dense_43_loss: 0.5607 - dense_44_loss: 0.5571 - dense_45_loss: 0.5618 - dense_46_loss: 0.5625 - dense_47_loss: 0.5642 - dense_48_loss: 0.5607 - dense_49_loss: 0.5596 - dense_50_loss: 0.5612 - dense_51_loss: 0.5591 - dense_52_loss: 0.5636 - dense_53_loss: 0.5615 - dense_54_loss: 0.5620 - dense_55_loss: 0.5620 - dense_56_loss: 0.5636 - dense_57_loss: 0.5621 - dense_58_loss: 0.5602 - dense_59_loss: 0.5613 - dense_60_loss: 0.5635 - dense_61_loss: 0.5615 - dense_42_categorical_accuracy: 0.0089 - dense_43_categorical_accuracy: 0.7098 - dense_44_categorical_accuracy: 0.7790 - dense_45_categorical_accuracy: 0.0603 - dense_46_categorical_accuracy: 0.2969 - dense_47_categorical_accuracy: 0.0156 - dense_48_categorical_accuracy: 0.2232 - dense_49_categorical_accuracy: 0.4933 - dense_50_categorical_accuracy: 0.2902 - dense_51_categorical_accuracy: 0.5759 - dense_52_categorical_accuracy: 0.0826 - dense_53_categorical_accuracy: 0.5603 - dense_54_categorical_accuracy: 0.2344 - dense_55_categorical_accuracy: 0.3393 - dense_56_categorical_accuracy: 0.2612 - dense_57_categorical_accuracy: 0.3259 - dense_58_categorical_accuracy: 0.6987 - dense_59_categorical_accuracy: 0.3862 - dense_60_categorical_accuracy: 0.1004 - dense_61_categorical_accuracy: 0.3348\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   896/105000 [..............................] - ETA: 15:28:23 - loss: 11.2281 - dense_42_loss: 0.5629 - dense_43_loss: 0.5605 - dense_44_loss: 0.5571 - dense_45_loss: 0.5615 - dense_46_loss: 0.5625 - dense_47_loss: 0.5639 - dense_48_loss: 0.5605 - dense_49_loss: 0.5595 - dense_50_loss: 0.5610 - dense_51_loss: 0.5588 - dense_52_loss: 0.5635 - dense_53_loss: 0.5613 - dense_54_loss: 0.5618 - dense_55_loss: 0.5618 - dense_56_loss: 0.5636 - dense_57_loss: 0.5620 - dense_58_loss: 0.5601 - dense_59_loss: 0.5611 - dense_60_loss: 0.5633 - dense_61_loss: 0.5613 - dense_42_categorical_accuracy: 0.0508 - dense_43_categorical_accuracy: 0.7188 - dense_44_categorical_accuracy: 0.7676 - dense_45_categorical_accuracy: 0.1074 - dense_46_categorical_accuracy: 0.3066 - dense_47_categorical_accuracy: 0.1074 - dense_48_categorical_accuracy: 0.2988 - dense_49_categorical_accuracy: 0.5000 - dense_50_categorical_accuracy: 0.3516 - dense_51_categorical_accuracy: 0.5898 - dense_52_categorical_accuracy: 0.0801 - dense_53_categorical_accuracy: 0.5840 - dense_54_categorical_accuracy: 0.2324 - dense_55_categorical_accuracy: 0.3789 - dense_56_categorical_accuracy: 0.2559 - dense_57_categorical_accuracy: 0.3633 - dense_58_categorical_accuracy: 0.6875 - dense_59_categorical_accuracy: 0.4375 - dense_60_categorical_accuracy: 0.0977 - dense_61_categorical_accuracy: 0.34 - ETA: 15:41:32 - loss: 11.2248 - dense_42_loss: 0.5627 - dense_43_loss: 0.5602 - dense_44_loss: 0.5570 - dense_45_loss: 0.5612 - dense_46_loss: 0.5624 - dense_47_loss: 0.5636 - dense_48_loss: 0.5602 - dense_49_loss: 0.5596 - dense_50_loss: 0.5606 - dense_51_loss: 0.5587 - dense_52_loss: 0.5634 - dense_53_loss: 0.5612 - dense_54_loss: 0.5618 - dense_55_loss: 0.5617 - dense_56_loss: 0.5636 - dense_57_loss: 0.5619 - dense_58_loss: 0.5599 - dense_59_loss: 0.5609 - dense_60_loss: 0.5631 - dense_61_loss: 0.5612 - dense_42_categorical_accuracy: 0.1302 - dense_43_categorical_accuracy: 0.7257 - dense_44_categorical_accuracy: 0.7604 - dense_45_categorical_accuracy: 0.1892 - dense_46_categorical_accuracy: 0.3194 - dense_47_categorical_accuracy: 0.1979 - dense_48_categorical_accuracy: 0.3594 - dense_49_categorical_accuracy: 0.4983 - dense_50_categorical_accuracy: 0.4062 - dense_51_categorical_accuracy: 0.5938 - dense_52_categorical_accuracy: 0.0764 - dense_53_categorical_accuracy: 0.5938 - dense_54_categorical_accuracy: 0.2274 - dense_55_categorical_accuracy: 0.4080 - dense_56_categorical_accuracy: 0.2483 - dense_57_categorical_accuracy: 0.3854 - dense_58_categorical_accuracy: 0.6927 - dense_59_categorical_accuracy: 0.4774 - dense_60_categorical_accuracy: 0.1024 - dense_61_categorical_accuracy: 0.37 - ETA: 15:47:36 - loss: 11.2208 - dense_42_loss: 0.5624 - dense_43_loss: 0.5599 - dense_44_loss: 0.5568 - dense_45_loss: 0.5609 - dense_46_loss: 0.5624 - dense_47_loss: 0.5632 - dense_48_loss: 0.5599 - dense_49_loss: 0.5594 - dense_50_loss: 0.5603 - dense_51_loss: 0.5585 - dense_52_loss: 0.5633 - dense_53_loss: 0.5610 - dense_54_loss: 0.5616 - dense_55_loss: 0.5616 - dense_56_loss: 0.5635 - dense_57_loss: 0.5618 - dense_58_loss: 0.5598 - dense_59_loss: 0.5606 - dense_60_loss: 0.5629 - dense_61_loss: 0.5611 - dense_42_categorical_accuracy: 0.2094 - dense_43_categorical_accuracy: 0.7406 - dense_44_categorical_accuracy: 0.7641 - dense_45_categorical_accuracy: 0.2562 - dense_46_categorical_accuracy: 0.3281 - dense_47_categorical_accuracy: 0.2672 - dense_48_categorical_accuracy: 0.4047 - dense_49_categorical_accuracy: 0.5078 - dense_50_categorical_accuracy: 0.4484 - dense_51_categorical_accuracy: 0.6031 - dense_52_categorical_accuracy: 0.0781 - dense_53_categorical_accuracy: 0.6078 - dense_54_categorical_accuracy: 0.2297 - dense_55_categorical_accuracy: 0.4313 - dense_56_categorical_accuracy: 0.2516 - dense_57_categorical_accuracy: 0.3875 - dense_58_categorical_accuracy: 0.6922 - dense_59_categorical_accuracy: 0.5125 - dense_60_categorical_accuracy: 0.1094 - dense_61_categorical_accuracy: 0.39 - ETA: 15:55:11 - loss: 11.2174 - dense_42_loss: 0.5622 - dense_43_loss: 0.5597 - dense_44_loss: 0.5565 - dense_45_loss: 0.5606 - dense_46_loss: 0.5623 - dense_47_loss: 0.5629 - dense_48_loss: 0.5596 - dense_49_loss: 0.5592 - dense_50_loss: 0.5601 - dense_51_loss: 0.5582 - dense_52_loss: 0.5632 - dense_53_loss: 0.5608 - dense_54_loss: 0.5615 - dense_55_loss: 0.5614 - dense_56_loss: 0.5635 - dense_57_loss: 0.5617 - dense_58_loss: 0.5597 - dense_59_loss: 0.5604 - dense_60_loss: 0.5628 - dense_61_loss: 0.5609 - dense_42_categorical_accuracy: 0.2514 - dense_43_categorical_accuracy: 0.7443 - dense_44_categorical_accuracy: 0.7628 - dense_45_categorical_accuracy: 0.3153 - dense_46_categorical_accuracy: 0.3338 - dense_47_categorical_accuracy: 0.3224 - dense_48_categorical_accuracy: 0.4503 - dense_49_categorical_accuracy: 0.5156 - dense_50_categorical_accuracy: 0.4773 - dense_51_categorical_accuracy: 0.6136 - dense_52_categorical_accuracy: 0.0795 - dense_53_categorical_accuracy: 0.6165 - dense_54_categorical_accuracy: 0.2230 - dense_55_categorical_accuracy: 0.4489 - dense_56_categorical_accuracy: 0.2472 - dense_57_categorical_accuracy: 0.3963 - dense_58_categorical_accuracy: 0.6889 - dense_59_categorical_accuracy: 0.5355 - dense_60_categorical_accuracy: 0.1136 - dense_61_categorical_accuracy: 0.42 - ETA: 16:04:51 - loss: 11.2139 - dense_42_loss: 0.5620 - dense_43_loss: 0.5593 - dense_44_loss: 0.5564 - dense_45_loss: 0.5603 - dense_46_loss: 0.5621 - dense_47_loss: 0.5626 - dense_48_loss: 0.5594 - dense_49_loss: 0.5592 - dense_50_loss: 0.5599 - dense_51_loss: 0.5581 - dense_52_loss: 0.5631 - dense_53_loss: 0.5607 - dense_54_loss: 0.5614 - dense_55_loss: 0.5613 - dense_56_loss: 0.5634 - dense_57_loss: 0.5617 - dense_58_loss: 0.5595 - dense_59_loss: 0.5601 - dense_60_loss: 0.5627 - dense_61_loss: 0.5608 - dense_42_categorical_accuracy: 0.2930 - dense_43_categorical_accuracy: 0.7552 - dense_44_categorical_accuracy: 0.7591 - dense_45_categorical_accuracy: 0.3620 - dense_46_categorical_accuracy: 0.3464 - dense_47_categorical_accuracy: 0.3724 - dense_48_categorical_accuracy: 0.4831 - dense_49_categorical_accuracy: 0.5182 - dense_50_categorical_accuracy: 0.4974 - dense_51_categorical_accuracy: 0.6159 - dense_52_categorical_accuracy: 0.0781 - dense_53_categorical_accuracy: 0.6237 - dense_54_categorical_accuracy: 0.2227 - dense_55_categorical_accuracy: 0.4635 - dense_56_categorical_accuracy: 0.2513 - dense_57_categorical_accuracy: 0.4023 - dense_58_categorical_accuracy: 0.6927 - dense_59_categorical_accuracy: 0.5612 - dense_60_categorical_accuracy: 0.1133 - dense_61_categorical_accuracy: 0.42 - ETA: 16:15:11 - loss: 11.2106 - dense_42_loss: 0.5618 - dense_43_loss: 0.5590 - dense_44_loss: 0.5562 - dense_45_loss: 0.5600 - dense_46_loss: 0.5621 - dense_47_loss: 0.5623 - dense_48_loss: 0.5591 - dense_49_loss: 0.5592 - dense_50_loss: 0.5598 - dense_51_loss: 0.5579 - dense_52_loss: 0.5630 - dense_53_loss: 0.5605 - dense_54_loss: 0.5612 - dense_55_loss: 0.5612 - dense_56_loss: 0.5632 - dense_57_loss: 0.5616 - dense_58_loss: 0.5594 - dense_59_loss: 0.5599 - dense_60_loss: 0.5626 - dense_61_loss: 0.5607 - dense_42_categorical_accuracy: 0.3317 - dense_43_categorical_accuracy: 0.7608 - dense_44_categorical_accuracy: 0.7596 - dense_45_categorical_accuracy: 0.4002 - dense_46_categorical_accuracy: 0.3498 - dense_47_categorical_accuracy: 0.4147 - dense_48_categorical_accuracy: 0.5108 - dense_49_categorical_accuracy: 0.5144 - dense_50_categorical_accuracy: 0.5144 - dense_51_categorical_accuracy: 0.6154 - dense_52_categorical_accuracy: 0.1106 - dense_53_categorical_accuracy: 0.6322 - dense_54_categorical_accuracy: 0.2236 - dense_55_categorical_accuracy: 0.4712 - dense_56_categorical_accuracy: 0.2596 - dense_57_categorical_accuracy: 0.4062 - dense_58_categorical_accuracy: 0.6887 - dense_59_categorical_accuracy: 0.5805 - dense_60_categorical_accuracy: 0.1106 - dense_61_categorical_accuracy: 0.44 - ETA: 16:25:28 - loss: 11.2073 - dense_42_loss: 0.5616 - dense_43_loss: 0.5588 - dense_44_loss: 0.5560 - dense_45_loss: 0.5597 - dense_46_loss: 0.5620 - dense_47_loss: 0.5619 - dense_48_loss: 0.5589 - dense_49_loss: 0.5591 - dense_50_loss: 0.5596 - dense_51_loss: 0.5578 - dense_52_loss: 0.5629 - dense_53_loss: 0.5603 - dense_54_loss: 0.5611 - dense_55_loss: 0.5611 - dense_56_loss: 0.5632 - dense_57_loss: 0.5614 - dense_58_loss: 0.5592 - dense_59_loss: 0.5596 - dense_60_loss: 0.5625 - dense_61_loss: 0.5606 - dense_42_categorical_accuracy: 0.3583 - dense_43_categorical_accuracy: 0.7634 - dense_44_categorical_accuracy: 0.7578 - dense_45_categorical_accuracy: 0.4330 - dense_46_categorical_accuracy: 0.3560 - dense_47_categorical_accuracy: 0.4531 - dense_48_categorical_accuracy: 0.5301 - dense_49_categorical_accuracy: 0.5156 - dense_50_categorical_accuracy: 0.5301 - dense_51_categorical_accuracy: 0.6161 - dense_52_categorical_accuracy: 0.1395 - dense_53_categorical_accuracy: 0.6406 - dense_54_categorical_accuracy: 0.2176 - dense_55_categorical_accuracy: 0.4810 - dense_56_categorical_accuracy: 0.2634 - dense_57_categorical_accuracy: 0.4208 - dense_58_categorical_accuracy: 0.6875 - dense_59_categorical_accuracy: 0.5993 - dense_60_categorical_accuracy: 0.1071 - dense_61_categorical_accuracy: 0.4587"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1344/105000 [..............................] - ETA: 16:41:25 - loss: 11.2041 - dense_42_loss: 0.5613 - dense_43_loss: 0.5585 - dense_44_loss: 0.5558 - dense_45_loss: 0.5594 - dense_46_loss: 0.5619 - dense_47_loss: 0.5616 - dense_48_loss: 0.5586 - dense_49_loss: 0.5592 - dense_50_loss: 0.5593 - dense_51_loss: 0.5577 - dense_52_loss: 0.5628 - dense_53_loss: 0.5602 - dense_54_loss: 0.5610 - dense_55_loss: 0.5610 - dense_56_loss: 0.5631 - dense_57_loss: 0.5614 - dense_58_loss: 0.5590 - dense_59_loss: 0.5594 - dense_60_loss: 0.5624 - dense_61_loss: 0.5604 - dense_42_categorical_accuracy: 0.3906 - dense_43_categorical_accuracy: 0.7677 - dense_44_categorical_accuracy: 0.7583 - dense_45_categorical_accuracy: 0.4635 - dense_46_categorical_accuracy: 0.3563 - dense_47_categorical_accuracy: 0.4865 - dense_48_categorical_accuracy: 0.5490 - dense_49_categorical_accuracy: 0.5062 - dense_50_categorical_accuracy: 0.5490 - dense_51_categorical_accuracy: 0.6125 - dense_52_categorical_accuracy: 0.1552 - dense_53_categorical_accuracy: 0.6396 - dense_54_categorical_accuracy: 0.2250 - dense_55_categorical_accuracy: 0.4823 - dense_56_categorical_accuracy: 0.2615 - dense_57_categorical_accuracy: 0.4250 - dense_58_categorical_accuracy: 0.6927 - dense_59_categorical_accuracy: 0.6146 - dense_60_categorical_accuracy: 0.1031 - dense_61_categorical_accuracy: 0.47 - ETA: 17:01:09 - loss: 11.2005 - dense_42_loss: 0.5611 - dense_43_loss: 0.5583 - dense_44_loss: 0.5555 - dense_45_loss: 0.5591 - dense_46_loss: 0.5618 - dense_47_loss: 0.5612 - dense_48_loss: 0.5583 - dense_49_loss: 0.5591 - dense_50_loss: 0.5591 - dense_51_loss: 0.5576 - dense_52_loss: 0.5628 - dense_53_loss: 0.5600 - dense_54_loss: 0.5609 - dense_55_loss: 0.5609 - dense_56_loss: 0.5630 - dense_57_loss: 0.5613 - dense_58_loss: 0.5589 - dense_59_loss: 0.5592 - dense_60_loss: 0.5623 - dense_61_loss: 0.5603 - dense_42_categorical_accuracy: 0.4150 - dense_43_categorical_accuracy: 0.7676 - dense_44_categorical_accuracy: 0.7637 - dense_45_categorical_accuracy: 0.4912 - dense_46_categorical_accuracy: 0.3633 - dense_47_categorical_accuracy: 0.5127 - dense_48_categorical_accuracy: 0.5693 - dense_49_categorical_accuracy: 0.5088 - dense_50_categorical_accuracy: 0.5664 - dense_51_categorical_accuracy: 0.6143 - dense_52_categorical_accuracy: 0.1689 - dense_53_categorical_accuracy: 0.6436 - dense_54_categorical_accuracy: 0.2520 - dense_55_categorical_accuracy: 0.4902 - dense_56_categorical_accuracy: 0.2666 - dense_57_categorical_accuracy: 0.4248 - dense_58_categorical_accuracy: 0.6924 - dense_59_categorical_accuracy: 0.6201 - dense_60_categorical_accuracy: 0.1094 - dense_61_categorical_accuracy: 0.48 - ETA: 17:19:08 - loss: 11.1972 - dense_42_loss: 0.5608 - dense_43_loss: 0.5581 - dense_44_loss: 0.5552 - dense_45_loss: 0.5588 - dense_46_loss: 0.5618 - dense_47_loss: 0.5609 - dense_48_loss: 0.5582 - dense_49_loss: 0.5590 - dense_50_loss: 0.5589 - dense_51_loss: 0.5574 - dense_52_loss: 0.5627 - dense_53_loss: 0.5598 - dense_54_loss: 0.5607 - dense_55_loss: 0.5608 - dense_56_loss: 0.5629 - dense_57_loss: 0.5612 - dense_58_loss: 0.5587 - dense_59_loss: 0.5590 - dense_60_loss: 0.5621 - dense_61_loss: 0.5601 - dense_42_categorical_accuracy: 0.4403 - dense_43_categorical_accuracy: 0.7665 - dense_44_categorical_accuracy: 0.7665 - dense_45_categorical_accuracy: 0.5119 - dense_46_categorical_accuracy: 0.3631 - dense_47_categorical_accuracy: 0.5404 - dense_48_categorical_accuracy: 0.5809 - dense_49_categorical_accuracy: 0.5138 - dense_50_categorical_accuracy: 0.5781 - dense_51_categorical_accuracy: 0.6213 - dense_52_categorical_accuracy: 0.1903 - dense_53_categorical_accuracy: 0.6507 - dense_54_categorical_accuracy: 0.2757 - dense_55_categorical_accuracy: 0.4963 - dense_56_categorical_accuracy: 0.2665 - dense_57_categorical_accuracy: 0.4301 - dense_58_categorical_accuracy: 0.6903 - dense_59_categorical_accuracy: 0.6278 - dense_60_categorical_accuracy: 0.1259 - dense_61_categorical_accuracy: 0.49 - ETA: 17:34:23 - loss: 11.1938 - dense_42_loss: 0.5606 - dense_43_loss: 0.5579 - dense_44_loss: 0.5550 - dense_45_loss: 0.5585 - dense_46_loss: 0.5617 - dense_47_loss: 0.5605 - dense_48_loss: 0.5579 - dense_49_loss: 0.5590 - dense_50_loss: 0.5588 - dense_51_loss: 0.5573 - dense_52_loss: 0.5626 - dense_53_loss: 0.5596 - dense_54_loss: 0.5606 - dense_55_loss: 0.5607 - dense_56_loss: 0.5628 - dense_57_loss: 0.5611 - dense_58_loss: 0.5586 - dense_59_loss: 0.5588 - dense_60_loss: 0.5620 - dense_61_loss: 0.5600 - dense_42_categorical_accuracy: 0.4618 - dense_43_categorical_accuracy: 0.7700 - dense_44_categorical_accuracy: 0.7682 - dense_45_categorical_accuracy: 0.5304 - dense_46_categorical_accuracy: 0.3698 - dense_47_categorical_accuracy: 0.5642 - dense_48_categorical_accuracy: 0.5964 - dense_49_categorical_accuracy: 0.5078 - dense_50_categorical_accuracy: 0.5816 - dense_51_categorical_accuracy: 0.6224 - dense_52_categorical_accuracy: 0.2101 - dense_53_categorical_accuracy: 0.6545 - dense_54_categorical_accuracy: 0.2943 - dense_55_categorical_accuracy: 0.5000 - dense_56_categorical_accuracy: 0.2691 - dense_57_categorical_accuracy: 0.4375 - dense_58_categorical_accuracy: 0.6866 - dense_59_categorical_accuracy: 0.6363 - dense_60_categorical_accuracy: 0.1536 - dense_61_categorical_accuracy: 0.50 - ETA: 17:44:08 - loss: 11.1903 - dense_42_loss: 0.5603 - dense_43_loss: 0.5576 - dense_44_loss: 0.5547 - dense_45_loss: 0.5582 - dense_46_loss: 0.5617 - dense_47_loss: 0.5601 - dense_48_loss: 0.5576 - dense_49_loss: 0.5590 - dense_50_loss: 0.5585 - dense_51_loss: 0.5572 - dense_52_loss: 0.5625 - dense_53_loss: 0.5595 - dense_54_loss: 0.5604 - dense_55_loss: 0.5606 - dense_56_loss: 0.5627 - dense_57_loss: 0.5610 - dense_58_loss: 0.5584 - dense_59_loss: 0.5586 - dense_60_loss: 0.5618 - dense_61_loss: 0.5599 - dense_42_categorical_accuracy: 0.4836 - dense_43_categorical_accuracy: 0.7730 - dense_44_categorical_accuracy: 0.7714 - dense_45_categorical_accuracy: 0.5526 - dense_46_categorical_accuracy: 0.3684 - dense_47_categorical_accuracy: 0.5839 - dense_48_categorical_accuracy: 0.6077 - dense_49_categorical_accuracy: 0.5033 - dense_50_categorical_accuracy: 0.5929 - dense_51_categorical_accuracy: 0.6225 - dense_52_categorical_accuracy: 0.2270 - dense_53_categorical_accuracy: 0.6530 - dense_54_categorical_accuracy: 0.3141 - dense_55_categorical_accuracy: 0.5058 - dense_56_categorical_accuracy: 0.2738 - dense_57_categorical_accuracy: 0.4416 - dense_58_categorical_accuracy: 0.6933 - dense_59_categorical_accuracy: 0.6390 - dense_60_categorical_accuracy: 0.1809 - dense_61_categorical_accuracy: 0.50 - ETA: 17:49:44 - loss: 11.1870 - dense_42_loss: 0.5601 - dense_43_loss: 0.5574 - dense_44_loss: 0.5545 - dense_45_loss: 0.5579 - dense_46_loss: 0.5616 - dense_47_loss: 0.5598 - dense_48_loss: 0.5575 - dense_49_loss: 0.5589 - dense_50_loss: 0.5583 - dense_51_loss: 0.5571 - dense_52_loss: 0.5624 - dense_53_loss: 0.5593 - dense_54_loss: 0.5603 - dense_55_loss: 0.5605 - dense_56_loss: 0.5627 - dense_57_loss: 0.5609 - dense_58_loss: 0.5582 - dense_59_loss: 0.5584 - dense_60_loss: 0.5617 - dense_61_loss: 0.5597 - dense_42_categorical_accuracy: 0.4969 - dense_43_categorical_accuracy: 0.7734 - dense_44_categorical_accuracy: 0.7719 - dense_45_categorical_accuracy: 0.5703 - dense_46_categorical_accuracy: 0.3703 - dense_47_categorical_accuracy: 0.6023 - dense_48_categorical_accuracy: 0.6148 - dense_49_categorical_accuracy: 0.5031 - dense_50_categorical_accuracy: 0.6023 - dense_51_categorical_accuracy: 0.6211 - dense_52_categorical_accuracy: 0.2398 - dense_53_categorical_accuracy: 0.6555 - dense_54_categorical_accuracy: 0.3289 - dense_55_categorical_accuracy: 0.5109 - dense_56_categorical_accuracy: 0.2703 - dense_57_categorical_accuracy: 0.4477 - dense_58_categorical_accuracy: 0.6953 - dense_59_categorical_accuracy: 0.6477 - dense_60_categorical_accuracy: 0.2070 - dense_61_categorical_accuracy: 0.51 - ETA: 17:57:01 - loss: 11.1838 - dense_42_loss: 0.5600 - dense_43_loss: 0.5571 - dense_44_loss: 0.5544 - dense_45_loss: 0.5576 - dense_46_loss: 0.5616 - dense_47_loss: 0.5594 - dense_48_loss: 0.5572 - dense_49_loss: 0.5589 - dense_50_loss: 0.5580 - dense_51_loss: 0.5570 - dense_52_loss: 0.5623 - dense_53_loss: 0.5591 - dense_54_loss: 0.5602 - dense_55_loss: 0.5603 - dense_56_loss: 0.5626 - dense_57_loss: 0.5608 - dense_58_loss: 0.5580 - dense_59_loss: 0.5582 - dense_60_loss: 0.5616 - dense_61_loss: 0.5596 - dense_42_categorical_accuracy: 0.5007 - dense_43_categorical_accuracy: 0.7775 - dense_44_categorical_accuracy: 0.7686 - dense_45_categorical_accuracy: 0.5826 - dense_46_categorical_accuracy: 0.3698 - dense_47_categorical_accuracy: 0.6183 - dense_48_categorical_accuracy: 0.6280 - dense_49_categorical_accuracy: 0.5037 - dense_50_categorical_accuracy: 0.6124 - dense_51_categorical_accuracy: 0.6183 - dense_52_categorical_accuracy: 0.2537 - dense_53_categorical_accuracy: 0.6592 - dense_54_categorical_accuracy: 0.3445 - dense_55_categorical_accuracy: 0.5186 - dense_56_categorical_accuracy: 0.2708 - dense_57_categorical_accuracy: 0.4501 - dense_58_categorical_accuracy: 0.6964 - dense_59_categorical_accuracy: 0.6548 - dense_60_categorical_accuracy: 0.2262 - dense_61_categorical_accuracy: 0.5208"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1792/105000 [..............................] - ETA: 18:07:03 - loss: 11.1807 - dense_42_loss: 0.5597 - dense_43_loss: 0.5569 - dense_44_loss: 0.5541 - dense_45_loss: 0.5574 - dense_46_loss: 0.5616 - dense_47_loss: 0.5591 - dense_48_loss: 0.5569 - dense_49_loss: 0.5588 - dense_50_loss: 0.5578 - dense_51_loss: 0.5570 - dense_52_loss: 0.5622 - dense_53_loss: 0.5590 - dense_54_loss: 0.5601 - dense_55_loss: 0.5602 - dense_56_loss: 0.5625 - dense_57_loss: 0.5607 - dense_58_loss: 0.5578 - dense_59_loss: 0.5580 - dense_60_loss: 0.5614 - dense_61_loss: 0.5594 - dense_42_categorical_accuracy: 0.5142 - dense_43_categorical_accuracy: 0.7763 - dense_44_categorical_accuracy: 0.7720 - dense_45_categorical_accuracy: 0.5930 - dense_46_categorical_accuracy: 0.3693 - dense_47_categorical_accuracy: 0.6328 - dense_48_categorical_accuracy: 0.6364 - dense_49_categorical_accuracy: 0.5057 - dense_50_categorical_accuracy: 0.6193 - dense_51_categorical_accuracy: 0.6143 - dense_52_categorical_accuracy: 0.2642 - dense_53_categorical_accuracy: 0.6598 - dense_54_categorical_accuracy: 0.3558 - dense_55_categorical_accuracy: 0.5249 - dense_56_categorical_accuracy: 0.2649 - dense_57_categorical_accuracy: 0.4517 - dense_58_categorical_accuracy: 0.6982 - dense_59_categorical_accuracy: 0.6605 - dense_60_categorical_accuracy: 0.2450 - dense_61_categorical_accuracy: 0.52 - ETA: 18:15:43 - loss: 11.1776 - dense_42_loss: 0.5595 - dense_43_loss: 0.5566 - dense_44_loss: 0.5540 - dense_45_loss: 0.5571 - dense_46_loss: 0.5615 - dense_47_loss: 0.5587 - dense_48_loss: 0.5567 - dense_49_loss: 0.5588 - dense_50_loss: 0.5577 - dense_51_loss: 0.5570 - dense_52_loss: 0.5621 - dense_53_loss: 0.5589 - dense_54_loss: 0.5599 - dense_55_loss: 0.5601 - dense_56_loss: 0.5625 - dense_57_loss: 0.5606 - dense_58_loss: 0.5576 - dense_59_loss: 0.5577 - dense_60_loss: 0.5613 - dense_61_loss: 0.5593 - dense_42_categorical_accuracy: 0.5265 - dense_43_categorical_accuracy: 0.7772 - dense_44_categorical_accuracy: 0.7690 - dense_45_categorical_accuracy: 0.6033 - dense_46_categorical_accuracy: 0.3682 - dense_47_categorical_accuracy: 0.6461 - dense_48_categorical_accuracy: 0.6454 - dense_49_categorical_accuracy: 0.5014 - dense_50_categorical_accuracy: 0.6236 - dense_51_categorical_accuracy: 0.6087 - dense_52_categorical_accuracy: 0.2785 - dense_53_categorical_accuracy: 0.6596 - dense_54_categorical_accuracy: 0.3675 - dense_55_categorical_accuracy: 0.5312 - dense_56_categorical_accuracy: 0.2636 - dense_57_categorical_accuracy: 0.4538 - dense_58_categorical_accuracy: 0.6990 - dense_59_categorical_accuracy: 0.6658 - dense_60_categorical_accuracy: 0.2629 - dense_61_categorical_accuracy: 0.53 - ETA: 18:31:08 - loss: 11.1746 - dense_42_loss: 0.5593 - dense_43_loss: 0.5565 - dense_44_loss: 0.5538 - dense_45_loss: 0.5568 - dense_46_loss: 0.5615 - dense_47_loss: 0.5584 - dense_48_loss: 0.5564 - dense_49_loss: 0.5588 - dense_50_loss: 0.5575 - dense_51_loss: 0.5568 - dense_52_loss: 0.5620 - dense_53_loss: 0.5587 - dense_54_loss: 0.5598 - dense_55_loss: 0.5600 - dense_56_loss: 0.5624 - dense_57_loss: 0.5605 - dense_58_loss: 0.5575 - dense_59_loss: 0.5575 - dense_60_loss: 0.5612 - dense_61_loss: 0.5592 - dense_42_categorical_accuracy: 0.5332 - dense_43_categorical_accuracy: 0.7754 - dense_44_categorical_accuracy: 0.7663 - dense_45_categorical_accuracy: 0.6146 - dense_46_categorical_accuracy: 0.3704 - dense_47_categorical_accuracy: 0.6562 - dense_48_categorical_accuracy: 0.6556 - dense_49_categorical_accuracy: 0.4993 - dense_50_categorical_accuracy: 0.6283 - dense_51_categorical_accuracy: 0.6120 - dense_52_categorical_accuracy: 0.2891 - dense_53_categorical_accuracy: 0.6602 - dense_54_categorical_accuracy: 0.3783 - dense_55_categorical_accuracy: 0.5299 - dense_56_categorical_accuracy: 0.2637 - dense_57_categorical_accuracy: 0.4551 - dense_58_categorical_accuracy: 0.6986 - dense_59_categorical_accuracy: 0.6732 - dense_60_categorical_accuracy: 0.2780 - dense_61_categorical_accuracy: 0.53 - ETA: 18:38:21 - loss: 11.1712 - dense_42_loss: 0.5592 - dense_43_loss: 0.5563 - dense_44_loss: 0.5537 - dense_45_loss: 0.5565 - dense_46_loss: 0.5614 - dense_47_loss: 0.5581 - dense_48_loss: 0.5561 - dense_49_loss: 0.5587 - dense_50_loss: 0.5573 - dense_51_loss: 0.5567 - dense_52_loss: 0.5619 - dense_53_loss: 0.5585 - dense_54_loss: 0.5597 - dense_55_loss: 0.5598 - dense_56_loss: 0.5623 - dense_57_loss: 0.5604 - dense_58_loss: 0.5573 - dense_59_loss: 0.5573 - dense_60_loss: 0.5611 - dense_61_loss: 0.5591 - dense_42_categorical_accuracy: 0.5387 - dense_43_categorical_accuracy: 0.7725 - dense_44_categorical_accuracy: 0.7625 - dense_45_categorical_accuracy: 0.6262 - dense_46_categorical_accuracy: 0.3744 - dense_47_categorical_accuracy: 0.6675 - dense_48_categorical_accuracy: 0.6644 - dense_49_categorical_accuracy: 0.5025 - dense_50_categorical_accuracy: 0.6338 - dense_51_categorical_accuracy: 0.6138 - dense_52_categorical_accuracy: 0.3019 - dense_53_categorical_accuracy: 0.6650 - dense_54_categorical_accuracy: 0.3925 - dense_55_categorical_accuracy: 0.5375 - dense_56_categorical_accuracy: 0.2687 - dense_57_categorical_accuracy: 0.4569 - dense_58_categorical_accuracy: 0.7025 - dense_59_categorical_accuracy: 0.6763 - dense_60_categorical_accuracy: 0.2956 - dense_61_categorical_accuracy: 0.53 - ETA: 18:49:41 - loss: 11.1676 - dense_42_loss: 0.5589 - dense_43_loss: 0.5561 - dense_44_loss: 0.5535 - dense_45_loss: 0.5562 - dense_46_loss: 0.5614 - dense_47_loss: 0.5577 - dense_48_loss: 0.5558 - dense_49_loss: 0.5586 - dense_50_loss: 0.5570 - dense_51_loss: 0.5565 - dense_52_loss: 0.5618 - dense_53_loss: 0.5583 - dense_54_loss: 0.5596 - dense_55_loss: 0.5597 - dense_56_loss: 0.5622 - dense_57_loss: 0.5603 - dense_58_loss: 0.5570 - dense_59_loss: 0.5571 - dense_60_loss: 0.5609 - dense_61_loss: 0.5589 - dense_42_categorical_accuracy: 0.5511 - dense_43_categorical_accuracy: 0.7740 - dense_44_categorical_accuracy: 0.7644 - dense_45_categorical_accuracy: 0.6352 - dense_46_categorical_accuracy: 0.3768 - dense_47_categorical_accuracy: 0.6797 - dense_48_categorical_accuracy: 0.6731 - dense_49_categorical_accuracy: 0.5072 - dense_50_categorical_accuracy: 0.6394 - dense_51_categorical_accuracy: 0.6172 - dense_52_categorical_accuracy: 0.3095 - dense_53_categorical_accuracy: 0.6653 - dense_54_categorical_accuracy: 0.3996 - dense_55_categorical_accuracy: 0.5373 - dense_56_categorical_accuracy: 0.2716 - dense_57_categorical_accuracy: 0.4603 - dense_58_categorical_accuracy: 0.7061 - dense_59_categorical_accuracy: 0.6785 - dense_60_categorical_accuracy: 0.3113 - dense_61_categorical_accuracy: 0.54 - ETA: 18:57:44 - loss: 11.1647 - dense_42_loss: 0.5587 - dense_43_loss: 0.5558 - dense_44_loss: 0.5533 - dense_45_loss: 0.5559 - dense_46_loss: 0.5613 - dense_47_loss: 0.5573 - dense_48_loss: 0.5555 - dense_49_loss: 0.5586 - dense_50_loss: 0.5569 - dense_51_loss: 0.5564 - dense_52_loss: 0.5617 - dense_53_loss: 0.5582 - dense_54_loss: 0.5595 - dense_55_loss: 0.5597 - dense_56_loss: 0.5621 - dense_57_loss: 0.5602 - dense_58_loss: 0.5568 - dense_59_loss: 0.5568 - dense_60_loss: 0.5608 - dense_61_loss: 0.5588 - dense_42_categorical_accuracy: 0.5596 - dense_43_categorical_accuracy: 0.7743 - dense_44_categorical_accuracy: 0.7639 - dense_45_categorical_accuracy: 0.6458 - dense_46_categorical_accuracy: 0.3767 - dense_47_categorical_accuracy: 0.6892 - dense_48_categorical_accuracy: 0.6782 - dense_49_categorical_accuracy: 0.5064 - dense_50_categorical_accuracy: 0.6412 - dense_51_categorical_accuracy: 0.6175 - dense_52_categorical_accuracy: 0.3154 - dense_53_categorical_accuracy: 0.6632 - dense_54_categorical_accuracy: 0.4016 - dense_55_categorical_accuracy: 0.5312 - dense_56_categorical_accuracy: 0.2789 - dense_57_categorical_accuracy: 0.4612 - dense_58_categorical_accuracy: 0.7078 - dense_59_categorical_accuracy: 0.6829 - dense_60_categorical_accuracy: 0.3229 - dense_61_categorical_accuracy: 0.54 - ETA: 19:05:25 - loss: 11.1615 - dense_42_loss: 0.5585 - dense_43_loss: 0.5556 - dense_44_loss: 0.5532 - dense_45_loss: 0.5556 - dense_46_loss: 0.5613 - dense_47_loss: 0.5570 - dense_48_loss: 0.5553 - dense_49_loss: 0.5585 - dense_50_loss: 0.5567 - dense_51_loss: 0.5563 - dense_52_loss: 0.5616 - dense_53_loss: 0.5581 - dense_54_loss: 0.5594 - dense_55_loss: 0.5596 - dense_56_loss: 0.5621 - dense_57_loss: 0.5601 - dense_58_loss: 0.5566 - dense_59_loss: 0.5566 - dense_60_loss: 0.5606 - dense_61_loss: 0.5587 - dense_42_categorical_accuracy: 0.5675 - dense_43_categorical_accuracy: 0.7768 - dense_44_categorical_accuracy: 0.7612 - dense_45_categorical_accuracy: 0.6546 - dense_46_categorical_accuracy: 0.3761 - dense_47_categorical_accuracy: 0.6970 - dense_48_categorical_accuracy: 0.6847 - dense_49_categorical_accuracy: 0.5084 - dense_50_categorical_accuracy: 0.6451 - dense_51_categorical_accuracy: 0.6161 - dense_52_categorical_accuracy: 0.3225 - dense_53_categorical_accuracy: 0.6646 - dense_54_categorical_accuracy: 0.4096 - dense_55_categorical_accuracy: 0.5324 - dense_56_categorical_accuracy: 0.2818 - dense_57_categorical_accuracy: 0.4665 - dense_58_categorical_accuracy: 0.7093 - dense_59_categorical_accuracy: 0.6853 - dense_60_categorical_accuracy: 0.3354 - dense_61_categorical_accuracy: 0.5407"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2240/105000 [..............................] - ETA: 19:17:30 - loss: 11.1580 - dense_42_loss: 0.5582 - dense_43_loss: 0.5553 - dense_44_loss: 0.5530 - dense_45_loss: 0.5554 - dense_46_loss: 0.5612 - dense_47_loss: 0.5566 - dense_48_loss: 0.5549 - dense_49_loss: 0.5584 - dense_50_loss: 0.5565 - dense_51_loss: 0.5563 - dense_52_loss: 0.5615 - dense_53_loss: 0.5579 - dense_54_loss: 0.5593 - dense_55_loss: 0.5595 - dense_56_loss: 0.5620 - dense_57_loss: 0.5600 - dense_58_loss: 0.5565 - dense_59_loss: 0.5564 - dense_60_loss: 0.5605 - dense_61_loss: 0.5586 - dense_42_categorical_accuracy: 0.5754 - dense_43_categorical_accuracy: 0.7802 - dense_44_categorical_accuracy: 0.7613 - dense_45_categorical_accuracy: 0.6600 - dense_46_categorical_accuracy: 0.3788 - dense_47_categorical_accuracy: 0.7058 - dense_48_categorical_accuracy: 0.6918 - dense_49_categorical_accuracy: 0.5097 - dense_50_categorical_accuracy: 0.6482 - dense_51_categorical_accuracy: 0.6153 - dense_52_categorical_accuracy: 0.3346 - dense_53_categorical_accuracy: 0.6659 - dense_54_categorical_accuracy: 0.4170 - dense_55_categorical_accuracy: 0.5361 - dense_56_categorical_accuracy: 0.2866 - dense_57_categorical_accuracy: 0.4661 - dense_58_categorical_accuracy: 0.7085 - dense_59_categorical_accuracy: 0.6907 - dense_60_categorical_accuracy: 0.3459 - dense_61_categorical_accuracy: 0.54 - ETA: 19:26:47 - loss: 11.1550 - dense_42_loss: 0.5581 - dense_43_loss: 0.5551 - dense_44_loss: 0.5529 - dense_45_loss: 0.5550 - dense_46_loss: 0.5612 - dense_47_loss: 0.5563 - dense_48_loss: 0.5546 - dense_49_loss: 0.5585 - dense_50_loss: 0.5564 - dense_51_loss: 0.5562 - dense_52_loss: 0.5614 - dense_53_loss: 0.5577 - dense_54_loss: 0.5593 - dense_55_loss: 0.5594 - dense_56_loss: 0.5620 - dense_57_loss: 0.5598 - dense_58_loss: 0.5563 - dense_59_loss: 0.5561 - dense_60_loss: 0.5603 - dense_61_loss: 0.5584 - dense_42_categorical_accuracy: 0.5792 - dense_43_categorical_accuracy: 0.7786 - dense_44_categorical_accuracy: 0.7568 - dense_45_categorical_accuracy: 0.6693 - dense_46_categorical_accuracy: 0.3792 - dense_47_categorical_accuracy: 0.7135 - dense_48_categorical_accuracy: 0.6995 - dense_49_categorical_accuracy: 0.5062 - dense_50_categorical_accuracy: 0.6479 - dense_51_categorical_accuracy: 0.6125 - dense_52_categorical_accuracy: 0.3411 - dense_53_categorical_accuracy: 0.6677 - dense_54_categorical_accuracy: 0.4219 - dense_55_categorical_accuracy: 0.5375 - dense_56_categorical_accuracy: 0.2922 - dense_57_categorical_accuracy: 0.4688 - dense_58_categorical_accuracy: 0.7094 - dense_59_categorical_accuracy: 0.6964 - dense_60_categorical_accuracy: 0.3604 - dense_61_categorical_accuracy: 0.55 - ETA: 19:44:35 - loss: 11.1516 - dense_42_loss: 0.5578 - dense_43_loss: 0.5549 - dense_44_loss: 0.5527 - dense_45_loss: 0.5548 - dense_46_loss: 0.5611 - dense_47_loss: 0.5559 - dense_48_loss: 0.5544 - dense_49_loss: 0.5584 - dense_50_loss: 0.5563 - dense_51_loss: 0.5560 - dense_52_loss: 0.5613 - dense_53_loss: 0.5576 - dense_54_loss: 0.5591 - dense_55_loss: 0.5593 - dense_56_loss: 0.5619 - dense_57_loss: 0.5597 - dense_58_loss: 0.5560 - dense_59_loss: 0.5559 - dense_60_loss: 0.5602 - dense_61_loss: 0.5583 - dense_42_categorical_accuracy: 0.5852 - dense_43_categorical_accuracy: 0.7772 - dense_44_categorical_accuracy: 0.7576 - dense_45_categorical_accuracy: 0.6759 - dense_46_categorical_accuracy: 0.3836 - dense_47_categorical_accuracy: 0.7213 - dense_48_categorical_accuracy: 0.7026 - dense_49_categorical_accuracy: 0.5066 - dense_50_categorical_accuracy: 0.6507 - dense_51_categorical_accuracy: 0.6149 - dense_52_categorical_accuracy: 0.3488 - dense_53_categorical_accuracy: 0.6689 - dense_54_categorical_accuracy: 0.4289 - dense_55_categorical_accuracy: 0.5398 - dense_56_categorical_accuracy: 0.2974 - dense_57_categorical_accuracy: 0.4708 - dense_58_categorical_accuracy: 0.7137 - dense_59_categorical_accuracy: 0.7001 - dense_60_categorical_accuracy: 0.3720 - dense_61_categorical_accuracy: 0.55 - ETA: 19:58:10 - loss: 11.1484 - dense_42_loss: 0.5577 - dense_43_loss: 0.5547 - dense_44_loss: 0.5524 - dense_45_loss: 0.5544 - dense_46_loss: 0.5610 - dense_47_loss: 0.5556 - dense_48_loss: 0.5541 - dense_49_loss: 0.5584 - dense_50_loss: 0.5561 - dense_51_loss: 0.5559 - dense_52_loss: 0.5612 - dense_53_loss: 0.5574 - dense_54_loss: 0.5590 - dense_55_loss: 0.5592 - dense_56_loss: 0.5618 - dense_57_loss: 0.5597 - dense_58_loss: 0.5559 - dense_59_loss: 0.5556 - dense_60_loss: 0.5600 - dense_61_loss: 0.5582 - dense_42_categorical_accuracy: 0.5894 - dense_43_categorical_accuracy: 0.7773 - dense_44_categorical_accuracy: 0.7607 - dense_45_categorical_accuracy: 0.6836 - dense_46_categorical_accuracy: 0.3823 - dense_47_categorical_accuracy: 0.7275 - dense_48_categorical_accuracy: 0.7100 - dense_49_categorical_accuracy: 0.5044 - dense_50_categorical_accuracy: 0.6509 - dense_51_categorical_accuracy: 0.6152 - dense_52_categorical_accuracy: 0.3560 - dense_53_categorical_accuracy: 0.6709 - dense_54_categorical_accuracy: 0.4346 - dense_55_categorical_accuracy: 0.5444 - dense_56_categorical_accuracy: 0.3057 - dense_57_categorical_accuracy: 0.4702 - dense_58_categorical_accuracy: 0.7114 - dense_59_categorical_accuracy: 0.7031 - dense_60_categorical_accuracy: 0.3804 - dense_61_categorical_accuracy: 0.55 - ETA: 20:07:41 - loss: 11.1453 - dense_42_loss: 0.5574 - dense_43_loss: 0.5545 - dense_44_loss: 0.5522 - dense_45_loss: 0.5542 - dense_46_loss: 0.5610 - dense_47_loss: 0.5552 - dense_48_loss: 0.5538 - dense_49_loss: 0.5583 - dense_50_loss: 0.5559 - dense_51_loss: 0.5558 - dense_52_loss: 0.5611 - dense_53_loss: 0.5572 - dense_54_loss: 0.5590 - dense_55_loss: 0.5590 - dense_56_loss: 0.5618 - dense_57_loss: 0.5596 - dense_58_loss: 0.5557 - dense_59_loss: 0.5554 - dense_60_loss: 0.5599 - dense_61_loss: 0.5581 - dense_42_categorical_accuracy: 0.5961 - dense_43_categorical_accuracy: 0.7770 - dense_44_categorical_accuracy: 0.7609 - dense_45_categorical_accuracy: 0.6870 - dense_46_categorical_accuracy: 0.3826 - dense_47_categorical_accuracy: 0.7339 - dense_48_categorical_accuracy: 0.7150 - dense_49_categorical_accuracy: 0.5052 - dense_50_categorical_accuracy: 0.6544 - dense_51_categorical_accuracy: 0.6165 - dense_52_categorical_accuracy: 0.3603 - dense_53_categorical_accuracy: 0.6714 - dense_54_categorical_accuracy: 0.4347 - dense_55_categorical_accuracy: 0.5464 - dense_56_categorical_accuracy: 0.3101 - dense_57_categorical_accuracy: 0.4692 - dense_58_categorical_accuracy: 0.7121 - dense_59_categorical_accuracy: 0.7055 - dense_60_categorical_accuracy: 0.3878 - dense_61_categorical_accuracy: 0.55 - ETA: 20:15:47 - loss: 11.1416 - dense_42_loss: 0.5571 - dense_43_loss: 0.5542 - dense_44_loss: 0.5520 - dense_45_loss: 0.5540 - dense_46_loss: 0.5609 - dense_47_loss: 0.5549 - dense_48_loss: 0.5535 - dense_49_loss: 0.5583 - dense_50_loss: 0.5557 - dense_51_loss: 0.5557 - dense_52_loss: 0.5610 - dense_53_loss: 0.5570 - dense_54_loss: 0.5589 - dense_55_loss: 0.5588 - dense_56_loss: 0.5617 - dense_57_loss: 0.5595 - dense_58_loss: 0.5555 - dense_59_loss: 0.5552 - dense_60_loss: 0.5598 - dense_61_loss: 0.5580 - dense_42_categorical_accuracy: 0.6043 - dense_43_categorical_accuracy: 0.7785 - dense_44_categorical_accuracy: 0.7629 - dense_45_categorical_accuracy: 0.6903 - dense_46_categorical_accuracy: 0.3837 - dense_47_categorical_accuracy: 0.7399 - dense_48_categorical_accuracy: 0.7206 - dense_49_categorical_accuracy: 0.5046 - dense_50_categorical_accuracy: 0.6576 - dense_51_categorical_accuracy: 0.6149 - dense_52_categorical_accuracy: 0.3709 - dense_53_categorical_accuracy: 0.6774 - dense_54_categorical_accuracy: 0.4444 - dense_55_categorical_accuracy: 0.5533 - dense_56_categorical_accuracy: 0.3134 - dense_57_categorical_accuracy: 0.4697 - dense_58_categorical_accuracy: 0.7151 - dense_59_categorical_accuracy: 0.7082 - dense_60_categorical_accuracy: 0.3948 - dense_61_categorical_accuracy: 0.55 - ETA: 20:24:26 - loss: 11.1385 - dense_42_loss: 0.5569 - dense_43_loss: 0.5540 - dense_44_loss: 0.5518 - dense_45_loss: 0.5536 - dense_46_loss: 0.5609 - dense_47_loss: 0.5545 - dense_48_loss: 0.5532 - dense_49_loss: 0.5584 - dense_50_loss: 0.5556 - dense_51_loss: 0.5556 - dense_52_loss: 0.5609 - dense_53_loss: 0.5568 - dense_54_loss: 0.5588 - dense_55_loss: 0.5587 - dense_56_loss: 0.5617 - dense_57_loss: 0.5594 - dense_58_loss: 0.5553 - dense_59_loss: 0.5549 - dense_60_loss: 0.5597 - dense_61_loss: 0.5578 - dense_42_categorical_accuracy: 0.6089 - dense_43_categorical_accuracy: 0.7786 - dense_44_categorical_accuracy: 0.7612 - dense_45_categorical_accuracy: 0.6969 - dense_46_categorical_accuracy: 0.3857 - dense_47_categorical_accuracy: 0.7464 - dense_48_categorical_accuracy: 0.7250 - dense_49_categorical_accuracy: 0.5009 - dense_50_categorical_accuracy: 0.6589 - dense_51_categorical_accuracy: 0.6134 - dense_52_categorical_accuracy: 0.3754 - dense_53_categorical_accuracy: 0.6781 - dense_54_categorical_accuracy: 0.4469 - dense_55_categorical_accuracy: 0.5545 - dense_56_categorical_accuracy: 0.3196 - dense_57_categorical_accuracy: 0.4688 - dense_58_categorical_accuracy: 0.7152 - dense_59_categorical_accuracy: 0.7134 - dense_60_categorical_accuracy: 0.4004 - dense_61_categorical_accuracy: 0.5580"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2688/105000 [..............................] - ETA: 20:31:11 - loss: 11.1354 - dense_42_loss: 0.5568 - dense_43_loss: 0.5538 - dense_44_loss: 0.5516 - dense_45_loss: 0.5534 - dense_46_loss: 0.5608 - dense_47_loss: 0.5542 - dense_48_loss: 0.5530 - dense_49_loss: 0.5583 - dense_50_loss: 0.5553 - dense_51_loss: 0.5555 - dense_52_loss: 0.5608 - dense_53_loss: 0.5566 - dense_54_loss: 0.5587 - dense_55_loss: 0.5585 - dense_56_loss: 0.5616 - dense_57_loss: 0.5593 - dense_58_loss: 0.5552 - dense_59_loss: 0.5546 - dense_60_loss: 0.5596 - dense_61_loss: 0.5577 - dense_42_categorical_accuracy: 0.6111 - dense_43_categorical_accuracy: 0.7782 - dense_44_categorical_accuracy: 0.7604 - dense_45_categorical_accuracy: 0.7005 - dense_46_categorical_accuracy: 0.3880 - dense_47_categorical_accuracy: 0.7504 - dense_48_categorical_accuracy: 0.7253 - dense_49_categorical_accuracy: 0.5013 - dense_50_categorical_accuracy: 0.6632 - dense_51_categorical_accuracy: 0.6155 - dense_52_categorical_accuracy: 0.3806 - dense_53_categorical_accuracy: 0.6819 - dense_54_categorical_accuracy: 0.4540 - dense_55_categorical_accuracy: 0.5595 - dense_56_categorical_accuracy: 0.3242 - dense_57_categorical_accuracy: 0.4670 - dense_58_categorical_accuracy: 0.7140 - dense_59_categorical_accuracy: 0.7174 - dense_60_categorical_accuracy: 0.4062 - dense_61_categorical_accuracy: 0.55 - ETA: 20:35:59 - loss: 11.1321 - dense_42_loss: 0.5565 - dense_43_loss: 0.5535 - dense_44_loss: 0.5515 - dense_45_loss: 0.5531 - dense_46_loss: 0.5607 - dense_47_loss: 0.5538 - dense_48_loss: 0.5528 - dense_49_loss: 0.5583 - dense_50_loss: 0.5552 - dense_51_loss: 0.5553 - dense_52_loss: 0.5607 - dense_53_loss: 0.5564 - dense_54_loss: 0.5586 - dense_55_loss: 0.5584 - dense_56_loss: 0.5616 - dense_57_loss: 0.5592 - dense_58_loss: 0.5550 - dense_59_loss: 0.5544 - dense_60_loss: 0.5594 - dense_61_loss: 0.5576 - dense_42_categorical_accuracy: 0.6157 - dense_43_categorical_accuracy: 0.7791 - dense_44_categorical_accuracy: 0.7593 - dense_45_categorical_accuracy: 0.7044 - dense_46_categorical_accuracy: 0.3894 - dense_47_categorical_accuracy: 0.7551 - dense_48_categorical_accuracy: 0.7276 - dense_49_categorical_accuracy: 0.4996 - dense_50_categorical_accuracy: 0.6647 - dense_51_categorical_accuracy: 0.6174 - dense_52_categorical_accuracy: 0.3813 - dense_53_categorical_accuracy: 0.6812 - dense_54_categorical_accuracy: 0.4573 - dense_55_categorical_accuracy: 0.5621 - dense_56_categorical_accuracy: 0.3294 - dense_57_categorical_accuracy: 0.4713 - dense_58_categorical_accuracy: 0.7133 - dense_59_categorical_accuracy: 0.7213 - dense_60_categorical_accuracy: 0.4160 - dense_61_categorical_accuracy: 0.56 - ETA: 20:42:34 - loss: 11.1289 - dense_42_loss: 0.5563 - dense_43_loss: 0.5533 - dense_44_loss: 0.5513 - dense_45_loss: 0.5528 - dense_46_loss: 0.5607 - dense_47_loss: 0.5536 - dense_48_loss: 0.5525 - dense_49_loss: 0.5582 - dense_50_loss: 0.5550 - dense_51_loss: 0.5552 - dense_52_loss: 0.5606 - dense_53_loss: 0.5563 - dense_54_loss: 0.5585 - dense_55_loss: 0.5583 - dense_56_loss: 0.5615 - dense_57_loss: 0.5591 - dense_58_loss: 0.5549 - dense_59_loss: 0.5541 - dense_60_loss: 0.5592 - dense_61_loss: 0.5574 - dense_42_categorical_accuracy: 0.6197 - dense_43_categorical_accuracy: 0.7788 - dense_44_categorical_accuracy: 0.7590 - dense_45_categorical_accuracy: 0.7089 - dense_46_categorical_accuracy: 0.3898 - dense_47_categorical_accuracy: 0.7578 - dense_48_categorical_accuracy: 0.7311 - dense_49_categorical_accuracy: 0.4996 - dense_50_categorical_accuracy: 0.6665 - dense_51_categorical_accuracy: 0.6188 - dense_52_categorical_accuracy: 0.3832 - dense_53_categorical_accuracy: 0.6817 - dense_54_categorical_accuracy: 0.4609 - dense_55_categorical_accuracy: 0.5633 - dense_56_categorical_accuracy: 0.3347 - dense_57_categorical_accuracy: 0.4720 - dense_58_categorical_accuracy: 0.7130 - dense_59_categorical_accuracy: 0.7233 - dense_60_categorical_accuracy: 0.4227 - dense_61_categorical_accuracy: 0.56 - ETA: 20:49:22 - loss: 11.1257 - dense_42_loss: 0.5561 - dense_43_loss: 0.5530 - dense_44_loss: 0.5511 - dense_45_loss: 0.5525 - dense_46_loss: 0.5606 - dense_47_loss: 0.5532 - dense_48_loss: 0.5522 - dense_49_loss: 0.5582 - dense_50_loss: 0.5547 - dense_51_loss: 0.5551 - dense_52_loss: 0.5606 - dense_53_loss: 0.5562 - dense_54_loss: 0.5584 - dense_55_loss: 0.5582 - dense_56_loss: 0.5614 - dense_57_loss: 0.5590 - dense_58_loss: 0.5547 - dense_59_loss: 0.5539 - dense_60_loss: 0.5591 - dense_61_loss: 0.5573 - dense_42_categorical_accuracy: 0.6246 - dense_43_categorical_accuracy: 0.7808 - dense_44_categorical_accuracy: 0.7592 - dense_45_categorical_accuracy: 0.7127 - dense_46_categorical_accuracy: 0.3910 - dense_47_categorical_accuracy: 0.7616 - dense_48_categorical_accuracy: 0.7364 - dense_49_categorical_accuracy: 0.4976 - dense_50_categorical_accuracy: 0.6707 - dense_51_categorical_accuracy: 0.6174 - dense_52_categorical_accuracy: 0.3870 - dense_53_categorical_accuracy: 0.6807 - dense_54_categorical_accuracy: 0.4627 - dense_55_categorical_accuracy: 0.5633 - dense_56_categorical_accuracy: 0.3425 - dense_57_categorical_accuracy: 0.4760 - dense_58_categorical_accuracy: 0.7123 - dense_59_categorical_accuracy: 0.7244 - dense_60_categorical_accuracy: 0.4279 - dense_61_categorical_accuracy: 0.56 - ETA: 20:58:15 - loss: 11.1224 - dense_42_loss: 0.5559 - dense_43_loss: 0.5528 - dense_44_loss: 0.5509 - dense_45_loss: 0.5523 - dense_46_loss: 0.5606 - dense_47_loss: 0.5529 - dense_48_loss: 0.5519 - dense_49_loss: 0.5582 - dense_50_loss: 0.5546 - dense_51_loss: 0.5550 - dense_52_loss: 0.5605 - dense_53_loss: 0.5560 - dense_54_loss: 0.5582 - dense_55_loss: 0.5580 - dense_56_loss: 0.5614 - dense_57_loss: 0.5589 - dense_58_loss: 0.5546 - dense_59_loss: 0.5537 - dense_60_loss: 0.5590 - dense_61_loss: 0.5572 - dense_42_categorical_accuracy: 0.6289 - dense_43_categorical_accuracy: 0.7809 - dense_44_categorical_accuracy: 0.7590 - dense_45_categorical_accuracy: 0.7164 - dense_46_categorical_accuracy: 0.3918 - dense_47_categorical_accuracy: 0.7664 - dense_48_categorical_accuracy: 0.7391 - dense_49_categorical_accuracy: 0.4965 - dense_50_categorical_accuracy: 0.6719 - dense_51_categorical_accuracy: 0.6184 - dense_52_categorical_accuracy: 0.3895 - dense_53_categorical_accuracy: 0.6824 - dense_54_categorical_accuracy: 0.4656 - dense_55_categorical_accuracy: 0.5660 - dense_56_categorical_accuracy: 0.3461 - dense_57_categorical_accuracy: 0.4785 - dense_58_categorical_accuracy: 0.7109 - dense_59_categorical_accuracy: 0.7262 - dense_60_categorical_accuracy: 0.4348 - dense_61_categorical_accuracy: 0.56 - ETA: 21:09:57 - loss: 11.1190 - dense_42_loss: 0.5556 - dense_43_loss: 0.5526 - dense_44_loss: 0.5507 - dense_45_loss: 0.5519 - dense_46_loss: 0.5605 - dense_47_loss: 0.5525 - dense_48_loss: 0.5516 - dense_49_loss: 0.5581 - dense_50_loss: 0.5543 - dense_51_loss: 0.5548 - dense_52_loss: 0.5604 - dense_53_loss: 0.5558 - dense_54_loss: 0.5582 - dense_55_loss: 0.5579 - dense_56_loss: 0.5613 - dense_57_loss: 0.5588 - dense_58_loss: 0.5545 - dense_59_loss: 0.5535 - dense_60_loss: 0.5588 - dense_61_loss: 0.5571 - dense_42_categorical_accuracy: 0.6330 - dense_43_categorical_accuracy: 0.7820 - dense_44_categorical_accuracy: 0.7607 - dense_45_categorical_accuracy: 0.7218 - dense_46_categorical_accuracy: 0.3906 - dense_47_categorical_accuracy: 0.7717 - dense_48_categorical_accuracy: 0.7428 - dense_49_categorical_accuracy: 0.4973 - dense_50_categorical_accuracy: 0.6764 - dense_51_categorical_accuracy: 0.6189 - dense_52_categorical_accuracy: 0.3929 - dense_53_categorical_accuracy: 0.6825 - dense_54_categorical_accuracy: 0.4680 - dense_55_categorical_accuracy: 0.5663 - dense_56_categorical_accuracy: 0.3498 - dense_57_categorical_accuracy: 0.4783 - dense_58_categorical_accuracy: 0.7081 - dense_59_categorical_accuracy: 0.7268 - dense_60_categorical_accuracy: 0.4398 - dense_61_categorical_accuracy: 0.56 - ETA: 21:18:04 - loss: 11.1157 - dense_42_loss: 0.5554 - dense_43_loss: 0.5524 - dense_44_loss: 0.5505 - dense_45_loss: 0.5516 - dense_46_loss: 0.5605 - dense_47_loss: 0.5521 - dense_48_loss: 0.5513 - dense_49_loss: 0.5581 - dense_50_loss: 0.5541 - dense_51_loss: 0.5548 - dense_52_loss: 0.5603 - dense_53_loss: 0.5556 - dense_54_loss: 0.5581 - dense_55_loss: 0.5578 - dense_56_loss: 0.5612 - dense_57_loss: 0.5587 - dense_58_loss: 0.5544 - dense_59_loss: 0.5533 - dense_60_loss: 0.5586 - dense_61_loss: 0.5569 - dense_42_categorical_accuracy: 0.6362 - dense_43_categorical_accuracy: 0.7816 - dense_44_categorical_accuracy: 0.7593 - dense_45_categorical_accuracy: 0.7266 - dense_46_categorical_accuracy: 0.3906 - dense_47_categorical_accuracy: 0.7753 - dense_48_categorical_accuracy: 0.7452 - dense_49_categorical_accuracy: 0.4955 - dense_50_categorical_accuracy: 0.6767 - dense_51_categorical_accuracy: 0.6164 - dense_52_categorical_accuracy: 0.3958 - dense_53_categorical_accuracy: 0.6853 - dense_54_categorical_accuracy: 0.4717 - dense_55_categorical_accuracy: 0.5696 - dense_56_categorical_accuracy: 0.3527 - dense_57_categorical_accuracy: 0.4836 - dense_58_categorical_accuracy: 0.7087 - dense_59_categorical_accuracy: 0.7269 - dense_60_categorical_accuracy: 0.4483 - dense_61_categorical_accuracy: 0.5673"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3136/105000 [..............................] - ETA: 21:21:20 - loss: 11.1125 - dense_42_loss: 0.5552 - dense_43_loss: 0.5521 - dense_44_loss: 0.5503 - dense_45_loss: 0.5513 - dense_46_loss: 0.5604 - dense_47_loss: 0.5518 - dense_48_loss: 0.5512 - dense_49_loss: 0.5581 - dense_50_loss: 0.5540 - dense_51_loss: 0.5547 - dense_52_loss: 0.5602 - dense_53_loss: 0.5554 - dense_54_loss: 0.5580 - dense_55_loss: 0.5576 - dense_56_loss: 0.5612 - dense_57_loss: 0.5586 - dense_58_loss: 0.5542 - dense_59_loss: 0.5531 - dense_60_loss: 0.5585 - dense_61_loss: 0.5568 - dense_42_categorical_accuracy: 0.6403 - dense_43_categorical_accuracy: 0.7827 - dense_44_categorical_accuracy: 0.7605 - dense_45_categorical_accuracy: 0.7315 - dense_46_categorical_accuracy: 0.3917 - dense_47_categorical_accuracy: 0.7794 - dense_48_categorical_accuracy: 0.7438 - dense_49_categorical_accuracy: 0.4953 - dense_50_categorical_accuracy: 0.6781 - dense_51_categorical_accuracy: 0.6163 - dense_52_categorical_accuracy: 0.4004 - dense_53_categorical_accuracy: 0.6864 - dense_54_categorical_accuracy: 0.4757 - dense_55_categorical_accuracy: 0.5716 - dense_56_categorical_accuracy: 0.3557 - dense_57_categorical_accuracy: 0.4840 - dense_58_categorical_accuracy: 0.7078 - dense_59_categorical_accuracy: 0.7289 - dense_60_categorical_accuracy: 0.4520 - dense_61_categorical_accuracy: 0.56 - ETA: 21:27:26 - loss: 11.1094 - dense_42_loss: 0.5549 - dense_43_loss: 0.5519 - dense_44_loss: 0.5501 - dense_45_loss: 0.5510 - dense_46_loss: 0.5604 - dense_47_loss: 0.5514 - dense_48_loss: 0.5509 - dense_49_loss: 0.5580 - dense_50_loss: 0.5538 - dense_51_loss: 0.5546 - dense_52_loss: 0.5601 - dense_53_loss: 0.5552 - dense_54_loss: 0.5578 - dense_55_loss: 0.5575 - dense_56_loss: 0.5611 - dense_57_loss: 0.5585 - dense_58_loss: 0.5541 - dense_59_loss: 0.5529 - dense_60_loss: 0.5584 - dense_61_loss: 0.5567 - dense_42_categorical_accuracy: 0.6445 - dense_43_categorical_accuracy: 0.7820 - dense_44_categorical_accuracy: 0.7607 - dense_45_categorical_accuracy: 0.7347 - dense_46_categorical_accuracy: 0.3935 - dense_47_categorical_accuracy: 0.7830 - dense_48_categorical_accuracy: 0.7461 - dense_49_categorical_accuracy: 0.4929 - dense_50_categorical_accuracy: 0.6786 - dense_51_categorical_accuracy: 0.6151 - dense_52_categorical_accuracy: 0.4055 - dense_53_categorical_accuracy: 0.6886 - dense_54_categorical_accuracy: 0.4798 - dense_55_categorical_accuracy: 0.5728 - dense_56_categorical_accuracy: 0.3608 - dense_57_categorical_accuracy: 0.4844 - dense_58_categorical_accuracy: 0.7074 - dense_59_categorical_accuracy: 0.7287 - dense_60_categorical_accuracy: 0.4563 - dense_61_categorical_accuracy: 0.56 - ETA: 21:30:58 - loss: 11.1061 - dense_42_loss: 0.5547 - dense_43_loss: 0.5517 - dense_44_loss: 0.5499 - dense_45_loss: 0.5507 - dense_46_loss: 0.5603 - dense_47_loss: 0.5511 - dense_48_loss: 0.5506 - dense_49_loss: 0.5580 - dense_50_loss: 0.5536 - dense_51_loss: 0.5545 - dense_52_loss: 0.5600 - dense_53_loss: 0.5550 - dense_54_loss: 0.5577 - dense_55_loss: 0.5574 - dense_56_loss: 0.5610 - dense_57_loss: 0.5584 - dense_58_loss: 0.5539 - dense_59_loss: 0.5527 - dense_60_loss: 0.5582 - dense_61_loss: 0.5566 - dense_42_categorical_accuracy: 0.6479 - dense_43_categorical_accuracy: 0.7809 - dense_44_categorical_accuracy: 0.7601 - dense_45_categorical_accuracy: 0.7382 - dense_46_categorical_accuracy: 0.3944 - dense_47_categorical_accuracy: 0.7865 - dense_48_categorical_accuracy: 0.7497 - dense_49_categorical_accuracy: 0.4924 - dense_50_categorical_accuracy: 0.6809 - dense_51_categorical_accuracy: 0.6149 - dense_52_categorical_accuracy: 0.4080 - dense_53_categorical_accuracy: 0.6889 - dense_54_categorical_accuracy: 0.4840 - dense_55_categorical_accuracy: 0.5726 - dense_56_categorical_accuracy: 0.3656 - dense_57_categorical_accuracy: 0.4844 - dense_58_categorical_accuracy: 0.7069 - dense_59_categorical_accuracy: 0.7299 - dense_60_categorical_accuracy: 0.4622 - dense_61_categorical_accuracy: 0.57 - ETA: 21:34:24 - loss: 11.1031 - dense_42_loss: 0.5545 - dense_43_loss: 0.5515 - dense_44_loss: 0.5497 - dense_45_loss: 0.5504 - dense_46_loss: 0.5602 - dense_47_loss: 0.5507 - dense_48_loss: 0.5504 - dense_49_loss: 0.5580 - dense_50_loss: 0.5534 - dense_51_loss: 0.5544 - dense_52_loss: 0.5599 - dense_53_loss: 0.5549 - dense_54_loss: 0.5576 - dense_55_loss: 0.5573 - dense_56_loss: 0.5610 - dense_57_loss: 0.5583 - dense_58_loss: 0.5538 - dense_59_loss: 0.5525 - dense_60_loss: 0.5581 - dense_61_loss: 0.5565 - dense_42_categorical_accuracy: 0.6491 - dense_43_categorical_accuracy: 0.7799 - dense_44_categorical_accuracy: 0.7602 - dense_45_categorical_accuracy: 0.7415 - dense_46_categorical_accuracy: 0.3954 - dense_47_categorical_accuracy: 0.7908 - dense_48_categorical_accuracy: 0.7500 - dense_49_categorical_accuracy: 0.4918 - dense_50_categorical_accuracy: 0.6824 - dense_51_categorical_accuracy: 0.6138 - dense_52_categorical_accuracy: 0.4103 - dense_53_categorical_accuracy: 0.6882 - dense_54_categorical_accuracy: 0.4864 - dense_55_categorical_accuracy: 0.5724 - dense_56_categorical_accuracy: 0.3713 - dense_57_categorical_accuracy: 0.4861 - dense_58_categorical_accuracy: 0.7072 - dense_59_categorical_accuracy: 0.7306 - dense_60_categorical_accuracy: 0.4664 - dense_61_categorical_accuracy: 0.57 - ETA: 21:35:54 - loss: 11.0999 - dense_42_loss: 0.5543 - dense_43_loss: 0.5513 - dense_44_loss: 0.5495 - dense_45_loss: 0.5501 - dense_46_loss: 0.5602 - dense_47_loss: 0.5503 - dense_48_loss: 0.5502 - dense_49_loss: 0.5579 - dense_50_loss: 0.5532 - dense_51_loss: 0.5544 - dense_52_loss: 0.5598 - dense_53_loss: 0.5547 - dense_54_loss: 0.5575 - dense_55_loss: 0.5572 - dense_56_loss: 0.5609 - dense_57_loss: 0.5582 - dense_58_loss: 0.5536 - dense_59_loss: 0.5523 - dense_60_loss: 0.5580 - dense_61_loss: 0.5563 - dense_42_categorical_accuracy: 0.6526 - dense_43_categorical_accuracy: 0.7806 - dense_44_categorical_accuracy: 0.7606 - dense_45_categorical_accuracy: 0.7443 - dense_46_categorical_accuracy: 0.3956 - dense_47_categorical_accuracy: 0.7942 - dense_48_categorical_accuracy: 0.7507 - dense_49_categorical_accuracy: 0.4940 - dense_50_categorical_accuracy: 0.6835 - dense_51_categorical_accuracy: 0.6130 - dense_52_categorical_accuracy: 0.4136 - dense_53_categorical_accuracy: 0.6892 - dense_54_categorical_accuracy: 0.4900 - dense_55_categorical_accuracy: 0.5731 - dense_56_categorical_accuracy: 0.3770 - dense_57_categorical_accuracy: 0.4880 - dense_58_categorical_accuracy: 0.7074 - dense_59_categorical_accuracy: 0.7304 - dense_60_categorical_accuracy: 0.4704 - dense_61_categorical_accuracy: 0.57 - ETA: 21:39:30 - loss: 11.0967 - dense_42_loss: 0.5541 - dense_43_loss: 0.5511 - dense_44_loss: 0.5494 - dense_45_loss: 0.5498 - dense_46_loss: 0.5602 - dense_47_loss: 0.5500 - dense_48_loss: 0.5499 - dense_49_loss: 0.5578 - dense_50_loss: 0.5530 - dense_51_loss: 0.5543 - dense_52_loss: 0.5597 - dense_53_loss: 0.5546 - dense_54_loss: 0.5574 - dense_55_loss: 0.5571 - dense_56_loss: 0.5608 - dense_57_loss: 0.5581 - dense_58_loss: 0.5534 - dense_59_loss: 0.5521 - dense_60_loss: 0.5578 - dense_61_loss: 0.5562 - dense_42_categorical_accuracy: 0.6556 - dense_43_categorical_accuracy: 0.7806 - dense_44_categorical_accuracy: 0.7594 - dense_45_categorical_accuracy: 0.7464 - dense_46_categorical_accuracy: 0.3939 - dense_47_categorical_accuracy: 0.7965 - dense_48_categorical_accuracy: 0.7536 - dense_49_categorical_accuracy: 0.4961 - dense_50_categorical_accuracy: 0.6852 - dense_51_categorical_accuracy: 0.6123 - dense_52_categorical_accuracy: 0.4160 - dense_53_categorical_accuracy: 0.6888 - dense_54_categorical_accuracy: 0.4928 - dense_55_categorical_accuracy: 0.5742 - dense_56_categorical_accuracy: 0.3802 - dense_57_categorical_accuracy: 0.4889 - dense_58_categorical_accuracy: 0.7077 - dense_59_categorical_accuracy: 0.7301 - dense_60_categorical_accuracy: 0.4743 - dense_61_categorical_accuracy: 0.57 - ETA: 21:43:24 - loss: 11.0935 - dense_42_loss: 0.5539 - dense_43_loss: 0.5509 - dense_44_loss: 0.5492 - dense_45_loss: 0.5496 - dense_46_loss: 0.5601 - dense_47_loss: 0.5497 - dense_48_loss: 0.5496 - dense_49_loss: 0.5578 - dense_50_loss: 0.5528 - dense_51_loss: 0.5541 - dense_52_loss: 0.5596 - dense_53_loss: 0.5544 - dense_54_loss: 0.5572 - dense_55_loss: 0.5569 - dense_56_loss: 0.5607 - dense_57_loss: 0.5580 - dense_58_loss: 0.5533 - dense_59_loss: 0.5519 - dense_60_loss: 0.5577 - dense_61_loss: 0.5561 - dense_42_categorical_accuracy: 0.6578 - dense_43_categorical_accuracy: 0.7806 - dense_44_categorical_accuracy: 0.7577 - dense_45_categorical_accuracy: 0.7484 - dense_46_categorical_accuracy: 0.3951 - dense_47_categorical_accuracy: 0.7991 - dense_48_categorical_accuracy: 0.7561 - dense_49_categorical_accuracy: 0.4952 - dense_50_categorical_accuracy: 0.6865 - dense_51_categorical_accuracy: 0.6132 - dense_52_categorical_accuracy: 0.4184 - dense_53_categorical_accuracy: 0.6904 - dense_54_categorical_accuracy: 0.4965 - dense_55_categorical_accuracy: 0.5775 - dense_56_categorical_accuracy: 0.3830 - dense_57_categorical_accuracy: 0.4895 - dense_58_categorical_accuracy: 0.7070 - dense_59_categorical_accuracy: 0.7325 - dense_60_categorical_accuracy: 0.4783 - dense_61_categorical_accuracy: 0.5727"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3584/105000 [>.............................] - ETA: 21:46:13 - loss: 11.0907 - dense_42_loss: 0.5537 - dense_43_loss: 0.5507 - dense_44_loss: 0.5492 - dense_45_loss: 0.5493 - dense_46_loss: 0.5601 - dense_47_loss: 0.5493 - dense_48_loss: 0.5494 - dense_49_loss: 0.5577 - dense_50_loss: 0.5525 - dense_51_loss: 0.5541 - dense_52_loss: 0.5595 - dense_53_loss: 0.5543 - dense_54_loss: 0.5572 - dense_55_loss: 0.5569 - dense_56_loss: 0.5606 - dense_57_loss: 0.5579 - dense_58_loss: 0.5531 - dense_59_loss: 0.5517 - dense_60_loss: 0.5575 - dense_61_loss: 0.5559 - dense_42_categorical_accuracy: 0.6587 - dense_43_categorical_accuracy: 0.7797 - dense_44_categorical_accuracy: 0.7547 - dense_45_categorical_accuracy: 0.7500 - dense_46_categorical_accuracy: 0.3944 - dense_47_categorical_accuracy: 0.8016 - dense_48_categorical_accuracy: 0.7569 - dense_49_categorical_accuracy: 0.4956 - dense_50_categorical_accuracy: 0.6903 - dense_51_categorical_accuracy: 0.6103 - dense_52_categorical_accuracy: 0.4184 - dense_53_categorical_accuracy: 0.6878 - dense_54_categorical_accuracy: 0.4963 - dense_55_categorical_accuracy: 0.5753 - dense_56_categorical_accuracy: 0.3856 - dense_57_categorical_accuracy: 0.4906 - dense_58_categorical_accuracy: 0.7075 - dense_59_categorical_accuracy: 0.7334 - dense_60_categorical_accuracy: 0.4828 - dense_61_categorical_accuracy: 0.57 - ETA: 21:53:08 - loss: 11.0874 - dense_42_loss: 0.5534 - dense_43_loss: 0.5505 - dense_44_loss: 0.5490 - dense_45_loss: 0.5491 - dense_46_loss: 0.5600 - dense_47_loss: 0.5490 - dense_48_loss: 0.5491 - dense_49_loss: 0.5576 - dense_50_loss: 0.5523 - dense_51_loss: 0.5540 - dense_52_loss: 0.5595 - dense_53_loss: 0.5541 - dense_54_loss: 0.5571 - dense_55_loss: 0.5567 - dense_56_loss: 0.5606 - dense_57_loss: 0.5578 - dense_58_loss: 0.5529 - dense_59_loss: 0.5514 - dense_60_loss: 0.5574 - dense_61_loss: 0.5558 - dense_42_categorical_accuracy: 0.6624 - dense_43_categorical_accuracy: 0.7794 - dense_44_categorical_accuracy: 0.7546 - dense_45_categorical_accuracy: 0.7521 - dense_46_categorical_accuracy: 0.3964 - dense_47_categorical_accuracy: 0.8039 - dense_48_categorical_accuracy: 0.7589 - dense_49_categorical_accuracy: 0.4957 - dense_50_categorical_accuracy: 0.6924 - dense_51_categorical_accuracy: 0.6112 - dense_52_categorical_accuracy: 0.4185 - dense_53_categorical_accuracy: 0.6887 - dense_54_categorical_accuracy: 0.4982 - dense_55_categorical_accuracy: 0.5772 - dense_56_categorical_accuracy: 0.3894 - dense_57_categorical_accuracy: 0.4917 - dense_58_categorical_accuracy: 0.7089 - dense_59_categorical_accuracy: 0.7350 - dense_60_categorical_accuracy: 0.4871 - dense_61_categorical_accuracy: 0.57 - ETA: 21:54:57 - loss: 11.0837 - dense_42_loss: 0.5532 - dense_43_loss: 0.5502 - dense_44_loss: 0.5487 - dense_45_loss: 0.5487 - dense_46_loss: 0.5600 - dense_47_loss: 0.5486 - dense_48_loss: 0.5488 - dense_49_loss: 0.5576 - dense_50_loss: 0.5521 - dense_51_loss: 0.5539 - dense_52_loss: 0.5593 - dense_53_loss: 0.5539 - dense_54_loss: 0.5570 - dense_55_loss: 0.5566 - dense_56_loss: 0.5604 - dense_57_loss: 0.5577 - dense_58_loss: 0.5527 - dense_59_loss: 0.5512 - dense_60_loss: 0.5573 - dense_61_loss: 0.5557 - dense_42_categorical_accuracy: 0.6659 - dense_43_categorical_accuracy: 0.7812 - dense_44_categorical_accuracy: 0.7563 - dense_45_categorical_accuracy: 0.7557 - dense_46_categorical_accuracy: 0.3963 - dense_47_categorical_accuracy: 0.8068 - dense_48_categorical_accuracy: 0.7614 - dense_49_categorical_accuracy: 0.4970 - dense_50_categorical_accuracy: 0.6941 - dense_51_categorical_accuracy: 0.6109 - dense_52_categorical_accuracy: 0.4225 - dense_53_categorical_accuracy: 0.6899 - dense_54_categorical_accuracy: 0.5006 - dense_55_categorical_accuracy: 0.5790 - dense_56_categorical_accuracy: 0.3954 - dense_57_categorical_accuracy: 0.4919 - dense_58_categorical_accuracy: 0.7097 - dense_59_categorical_accuracy: 0.7362 - dense_60_categorical_accuracy: 0.4904 - dense_61_categorical_accuracy: 0.57 - ETA: 21:56:29 - loss: 11.0803 - dense_42_loss: 0.5529 - dense_43_loss: 0.5499 - dense_44_loss: 0.5485 - dense_45_loss: 0.5484 - dense_46_loss: 0.5599 - dense_47_loss: 0.5483 - dense_48_loss: 0.5486 - dense_49_loss: 0.5575 - dense_50_loss: 0.5519 - dense_51_loss: 0.5537 - dense_52_loss: 0.5593 - dense_53_loss: 0.5538 - dense_54_loss: 0.5569 - dense_55_loss: 0.5565 - dense_56_loss: 0.5604 - dense_57_loss: 0.5576 - dense_58_loss: 0.5526 - dense_59_loss: 0.5510 - dense_60_loss: 0.5571 - dense_61_loss: 0.5556 - dense_42_categorical_accuracy: 0.6683 - dense_43_categorical_accuracy: 0.7830 - dense_44_categorical_accuracy: 0.7571 - dense_45_categorical_accuracy: 0.7583 - dense_46_categorical_accuracy: 0.3977 - dense_47_categorical_accuracy: 0.8098 - dense_48_categorical_accuracy: 0.7624 - dense_49_categorical_accuracy: 0.4968 - dense_50_categorical_accuracy: 0.6949 - dense_51_categorical_accuracy: 0.6126 - dense_52_categorical_accuracy: 0.4242 - dense_53_categorical_accuracy: 0.6910 - dense_54_categorical_accuracy: 0.5029 - dense_55_categorical_accuracy: 0.5793 - dense_56_categorical_accuracy: 0.3989 - dense_57_categorical_accuracy: 0.4926 - dense_58_categorical_accuracy: 0.7096 - dense_59_categorical_accuracy: 0.7367 - dense_60_categorical_accuracy: 0.4938 - dense_61_categorical_accuracy: 0.57 - ETA: 21:57:43 - loss: 11.0767 - dense_42_loss: 0.5527 - dense_43_loss: 0.5496 - dense_44_loss: 0.5482 - dense_45_loss: 0.5481 - dense_46_loss: 0.5599 - dense_47_loss: 0.5479 - dense_48_loss: 0.5483 - dense_49_loss: 0.5575 - dense_50_loss: 0.5517 - dense_51_loss: 0.5536 - dense_52_loss: 0.5592 - dense_53_loss: 0.5536 - dense_54_loss: 0.5568 - dense_55_loss: 0.5564 - dense_56_loss: 0.5603 - dense_57_loss: 0.5575 - dense_58_loss: 0.5524 - dense_59_loss: 0.5507 - dense_60_loss: 0.5570 - dense_61_loss: 0.5555 - dense_42_categorical_accuracy: 0.6713 - dense_43_categorical_accuracy: 0.7847 - dense_44_categorical_accuracy: 0.7593 - dense_45_categorical_accuracy: 0.7607 - dense_46_categorical_accuracy: 0.3976 - dense_47_categorical_accuracy: 0.8131 - dense_48_categorical_accuracy: 0.7648 - dense_49_categorical_accuracy: 0.4957 - dense_50_categorical_accuracy: 0.6956 - dense_51_categorical_accuracy: 0.6143 - dense_52_categorical_accuracy: 0.4268 - dense_53_categorical_accuracy: 0.6916 - dense_54_categorical_accuracy: 0.5046 - dense_55_categorical_accuracy: 0.5787 - dense_56_categorical_accuracy: 0.4013 - dense_57_categorical_accuracy: 0.4931 - dense_58_categorical_accuracy: 0.7104 - dense_59_categorical_accuracy: 0.7399 - dense_60_categorical_accuracy: 0.4959 - dense_61_categorical_accuracy: 0.57 - ETA: 21:59:07 - loss: 11.0734 - dense_42_loss: 0.5524 - dense_43_loss: 0.5493 - dense_44_loss: 0.5480 - dense_45_loss: 0.5478 - dense_46_loss: 0.5598 - dense_47_loss: 0.5476 - dense_48_loss: 0.5481 - dense_49_loss: 0.5574 - dense_50_loss: 0.5515 - dense_51_loss: 0.5535 - dense_52_loss: 0.5591 - dense_53_loss: 0.5534 - dense_54_loss: 0.5566 - dense_55_loss: 0.5563 - dense_56_loss: 0.5602 - dense_57_loss: 0.5574 - dense_58_loss: 0.5522 - dense_59_loss: 0.5505 - dense_60_loss: 0.5569 - dense_61_loss: 0.5553 - dense_42_categorical_accuracy: 0.6747 - dense_43_categorical_accuracy: 0.7866 - dense_44_categorical_accuracy: 0.7602 - dense_45_categorical_accuracy: 0.7634 - dense_46_categorical_accuracy: 0.3989 - dense_47_categorical_accuracy: 0.8142 - dense_48_categorical_accuracy: 0.7645 - dense_49_categorical_accuracy: 0.4957 - dense_50_categorical_accuracy: 0.6969 - dense_51_categorical_accuracy: 0.6128 - dense_52_categorical_accuracy: 0.4293 - dense_53_categorical_accuracy: 0.6918 - dense_54_categorical_accuracy: 0.5082 - dense_55_categorical_accuracy: 0.5795 - dense_56_categorical_accuracy: 0.4040 - dense_57_categorical_accuracy: 0.4926 - dense_58_categorical_accuracy: 0.7116 - dense_59_categorical_accuracy: 0.7415 - dense_60_categorical_accuracy: 0.4989 - dense_61_categorical_accuracy: 0.57 - ETA: 22:01:19 - loss: 11.0702 - dense_42_loss: 0.5522 - dense_43_loss: 0.5491 - dense_44_loss: 0.5478 - dense_45_loss: 0.5475 - dense_46_loss: 0.5598 - dense_47_loss: 0.5473 - dense_48_loss: 0.5479 - dense_49_loss: 0.5573 - dense_50_loss: 0.5513 - dense_51_loss: 0.5534 - dense_52_loss: 0.5590 - dense_53_loss: 0.5533 - dense_54_loss: 0.5565 - dense_55_loss: 0.5561 - dense_56_loss: 0.5602 - dense_57_loss: 0.5573 - dense_58_loss: 0.5520 - dense_59_loss: 0.5503 - dense_60_loss: 0.5568 - dense_61_loss: 0.5552 - dense_42_categorical_accuracy: 0.6769 - dense_43_categorical_accuracy: 0.7866 - dense_44_categorical_accuracy: 0.7600 - dense_45_categorical_accuracy: 0.7653 - dense_46_categorical_accuracy: 0.3968 - dense_47_categorical_accuracy: 0.8158 - dense_48_categorical_accuracy: 0.7648 - dense_49_categorical_accuracy: 0.4975 - dense_50_categorical_accuracy: 0.6987 - dense_51_categorical_accuracy: 0.6136 - dense_52_categorical_accuracy: 0.4314 - dense_53_categorical_accuracy: 0.6914 - dense_54_categorical_accuracy: 0.5098 - dense_55_categorical_accuracy: 0.5815 - dense_56_categorical_accuracy: 0.4065 - dense_57_categorical_accuracy: 0.4922 - dense_58_categorical_accuracy: 0.7121 - dense_59_categorical_accuracy: 0.7419 - dense_60_categorical_accuracy: 0.5008 - dense_61_categorical_accuracy: 0.5770"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4032/105000 [>.............................] - ETA: 22:05:54 - loss: 11.0672 - dense_42_loss: 0.5521 - dense_43_loss: 0.5489 - dense_44_loss: 0.5477 - dense_45_loss: 0.5472 - dense_46_loss: 0.5597 - dense_47_loss: 0.5470 - dense_48_loss: 0.5476 - dense_49_loss: 0.5573 - dense_50_loss: 0.5511 - dense_51_loss: 0.5533 - dense_52_loss: 0.5589 - dense_53_loss: 0.5531 - dense_54_loss: 0.5564 - dense_55_loss: 0.5560 - dense_56_loss: 0.5601 - dense_57_loss: 0.5572 - dense_58_loss: 0.5518 - dense_59_loss: 0.5500 - dense_60_loss: 0.5567 - dense_61_loss: 0.5551 - dense_42_categorical_accuracy: 0.6768 - dense_43_categorical_accuracy: 0.7845 - dense_44_categorical_accuracy: 0.7582 - dense_45_categorical_accuracy: 0.7675 - dense_46_categorical_accuracy: 0.3975 - dense_47_categorical_accuracy: 0.8169 - dense_48_categorical_accuracy: 0.7678 - dense_49_categorical_accuracy: 0.4962 - dense_50_categorical_accuracy: 0.6996 - dense_51_categorical_accuracy: 0.6140 - dense_52_categorical_accuracy: 0.4323 - dense_53_categorical_accuracy: 0.6916 - dense_54_categorical_accuracy: 0.5115 - dense_55_categorical_accuracy: 0.5817 - dense_56_categorical_accuracy: 0.4101 - dense_57_categorical_accuracy: 0.4915 - dense_58_categorical_accuracy: 0.7133 - dense_59_categorical_accuracy: 0.7429 - dense_60_categorical_accuracy: 0.5030 - dense_61_categorical_accuracy: 0.57 - ETA: 22:08:30 - loss: 11.0639 - dense_42_loss: 0.5518 - dense_43_loss: 0.5487 - dense_44_loss: 0.5474 - dense_45_loss: 0.5469 - dense_46_loss: 0.5597 - dense_47_loss: 0.5466 - dense_48_loss: 0.5473 - dense_49_loss: 0.5572 - dense_50_loss: 0.5509 - dense_51_loss: 0.5532 - dense_52_loss: 0.5588 - dense_53_loss: 0.5529 - dense_54_loss: 0.5562 - dense_55_loss: 0.5559 - dense_56_loss: 0.5600 - dense_57_loss: 0.5571 - dense_58_loss: 0.5516 - dense_59_loss: 0.5499 - dense_60_loss: 0.5565 - dense_61_loss: 0.5550 - dense_42_categorical_accuracy: 0.6789 - dense_43_categorical_accuracy: 0.7842 - dense_44_categorical_accuracy: 0.7586 - dense_45_categorical_accuracy: 0.7691 - dense_46_categorical_accuracy: 0.3963 - dense_47_categorical_accuracy: 0.8195 - dense_48_categorical_accuracy: 0.7699 - dense_49_categorical_accuracy: 0.4970 - dense_50_categorical_accuracy: 0.7007 - dense_51_categorical_accuracy: 0.6131 - dense_52_categorical_accuracy: 0.4332 - dense_53_categorical_accuracy: 0.6921 - dense_54_categorical_accuracy: 0.5145 - dense_55_categorical_accuracy: 0.5824 - dense_56_categorical_accuracy: 0.4135 - dense_57_categorical_accuracy: 0.4930 - dense_58_categorical_accuracy: 0.7134 - dense_59_categorical_accuracy: 0.7416 - dense_60_categorical_accuracy: 0.5065 - dense_61_categorical_accuracy: 0.57 - ETA: 22:14:01 - loss: 11.0611 - dense_42_loss: 0.5516 - dense_43_loss: 0.5486 - dense_44_loss: 0.5473 - dense_45_loss: 0.5467 - dense_46_loss: 0.5597 - dense_47_loss: 0.5462 - dense_48_loss: 0.5471 - dense_49_loss: 0.5572 - dense_50_loss: 0.5507 - dense_51_loss: 0.5532 - dense_52_loss: 0.5587 - dense_53_loss: 0.5529 - dense_54_loss: 0.5561 - dense_55_loss: 0.5558 - dense_56_loss: 0.5599 - dense_57_loss: 0.5570 - dense_58_loss: 0.5514 - dense_59_loss: 0.5497 - dense_60_loss: 0.5564 - dense_61_loss: 0.5548 - dense_42_categorical_accuracy: 0.6798 - dense_43_categorical_accuracy: 0.7828 - dense_44_categorical_accuracy: 0.7577 - dense_45_categorical_accuracy: 0.7709 - dense_46_categorical_accuracy: 0.3941 - dense_47_categorical_accuracy: 0.8215 - dense_48_categorical_accuracy: 0.7709 - dense_49_categorical_accuracy: 0.4952 - dense_50_categorical_accuracy: 0.7010 - dense_51_categorical_accuracy: 0.6104 - dense_52_categorical_accuracy: 0.4322 - dense_53_categorical_accuracy: 0.6904 - dense_54_categorical_accuracy: 0.5154 - dense_55_categorical_accuracy: 0.5842 - dense_56_categorical_accuracy: 0.4150 - dense_57_categorical_accuracy: 0.4926 - dense_58_categorical_accuracy: 0.7145 - dense_59_categorical_accuracy: 0.7418 - dense_60_categorical_accuracy: 0.5087 - dense_61_categorical_accuracy: 0.57 - ETA: 22:18:31 - loss: 11.0581 - dense_42_loss: 0.5514 - dense_43_loss: 0.5484 - dense_44_loss: 0.5471 - dense_45_loss: 0.5464 - dense_46_loss: 0.5596 - dense_47_loss: 0.5459 - dense_48_loss: 0.5468 - dense_49_loss: 0.5572 - dense_50_loss: 0.5506 - dense_51_loss: 0.5531 - dense_52_loss: 0.5587 - dense_53_loss: 0.5527 - dense_54_loss: 0.5560 - dense_55_loss: 0.5557 - dense_56_loss: 0.5599 - dense_57_loss: 0.5569 - dense_58_loss: 0.5513 - dense_59_loss: 0.5495 - dense_60_loss: 0.5563 - dense_61_loss: 0.5547 - dense_42_categorical_accuracy: 0.6823 - dense_43_categorical_accuracy: 0.7815 - dense_44_categorical_accuracy: 0.7581 - dense_45_categorical_accuracy: 0.7727 - dense_46_categorical_accuracy: 0.3940 - dense_47_categorical_accuracy: 0.8240 - dense_48_categorical_accuracy: 0.7724 - dense_49_categorical_accuracy: 0.4974 - dense_50_categorical_accuracy: 0.7018 - dense_51_categorical_accuracy: 0.6094 - dense_52_categorical_accuracy: 0.4333 - dense_53_categorical_accuracy: 0.6891 - dense_54_categorical_accuracy: 0.5167 - dense_55_categorical_accuracy: 0.5831 - dense_56_categorical_accuracy: 0.4172 - dense_57_categorical_accuracy: 0.4930 - dense_58_categorical_accuracy: 0.7130 - dense_59_categorical_accuracy: 0.7427 - dense_60_categorical_accuracy: 0.5109 - dense_61_categorical_accuracy: 0.58 - ETA: 22:20:36 - loss: 11.0547 - dense_42_loss: 0.5512 - dense_43_loss: 0.5483 - dense_44_loss: 0.5470 - dense_45_loss: 0.5460 - dense_46_loss: 0.5596 - dense_47_loss: 0.5455 - dense_48_loss: 0.5465 - dense_49_loss: 0.5571 - dense_50_loss: 0.5504 - dense_51_loss: 0.5531 - dense_52_loss: 0.5586 - dense_53_loss: 0.5526 - dense_54_loss: 0.5559 - dense_55_loss: 0.5555 - dense_56_loss: 0.5598 - dense_57_loss: 0.5568 - dense_58_loss: 0.5511 - dense_59_loss: 0.5492 - dense_60_loss: 0.5562 - dense_61_loss: 0.5545 - dense_42_categorical_accuracy: 0.6839 - dense_43_categorical_accuracy: 0.7797 - dense_44_categorical_accuracy: 0.7567 - dense_45_categorical_accuracy: 0.7754 - dense_46_categorical_accuracy: 0.3947 - dense_47_categorical_accuracy: 0.8266 - dense_48_categorical_accuracy: 0.7746 - dense_49_categorical_accuracy: 0.4962 - dense_50_categorical_accuracy: 0.7018 - dense_51_categorical_accuracy: 0.6076 - dense_52_categorical_accuracy: 0.4347 - dense_53_categorical_accuracy: 0.6898 - dense_54_categorical_accuracy: 0.5200 - dense_55_categorical_accuracy: 0.5858 - dense_56_categorical_accuracy: 0.4209 - dense_57_categorical_accuracy: 0.4928 - dense_58_categorical_accuracy: 0.7139 - dense_59_categorical_accuracy: 0.7451 - dense_60_categorical_accuracy: 0.5128 - dense_61_categorical_accuracy: 0.58 - ETA: 22:24:00 - loss: 11.0512 - dense_42_loss: 0.5509 - dense_43_loss: 0.5480 - dense_44_loss: 0.5467 - dense_45_loss: 0.5457 - dense_46_loss: 0.5596 - dense_47_loss: 0.5451 - dense_48_loss: 0.5463 - dense_49_loss: 0.5571 - dense_50_loss: 0.5501 - dense_51_loss: 0.5530 - dense_52_loss: 0.5585 - dense_53_loss: 0.5524 - dense_54_loss: 0.5558 - dense_55_loss: 0.5554 - dense_56_loss: 0.5597 - dense_57_loss: 0.5567 - dense_58_loss: 0.5509 - dense_59_loss: 0.5490 - dense_60_loss: 0.5560 - dense_61_loss: 0.5544 - dense_42_categorical_accuracy: 0.6855 - dense_43_categorical_accuracy: 0.7810 - dense_44_categorical_accuracy: 0.7581 - dense_45_categorical_accuracy: 0.7777 - dense_46_categorical_accuracy: 0.3947 - dense_47_categorical_accuracy: 0.8286 - dense_48_categorical_accuracy: 0.7752 - dense_49_categorical_accuracy: 0.4962 - dense_50_categorical_accuracy: 0.7041 - dense_51_categorical_accuracy: 0.6086 - dense_52_categorical_accuracy: 0.4375 - dense_53_categorical_accuracy: 0.6910 - dense_54_categorical_accuracy: 0.5227 - dense_55_categorical_accuracy: 0.5880 - dense_56_categorical_accuracy: 0.4246 - dense_57_categorical_accuracy: 0.4940 - dense_58_categorical_accuracy: 0.7150 - dense_59_categorical_accuracy: 0.7460 - dense_60_categorical_accuracy: 0.5151 - dense_61_categorical_accuracy: 0.58 - ETA: 22:26:03 - loss: 11.0479 - dense_42_loss: 0.5507 - dense_43_loss: 0.5478 - dense_44_loss: 0.5465 - dense_45_loss: 0.5454 - dense_46_loss: 0.5595 - dense_47_loss: 0.5448 - dense_48_loss: 0.5460 - dense_49_loss: 0.5571 - dense_50_loss: 0.5499 - dense_51_loss: 0.5529 - dense_52_loss: 0.5584 - dense_53_loss: 0.5522 - dense_54_loss: 0.5557 - dense_55_loss: 0.5553 - dense_56_loss: 0.5596 - dense_57_loss: 0.5567 - dense_58_loss: 0.5507 - dense_59_loss: 0.5487 - dense_60_loss: 0.5559 - dense_61_loss: 0.5542 - dense_42_categorical_accuracy: 0.6868 - dense_43_categorical_accuracy: 0.7817 - dense_44_categorical_accuracy: 0.7587 - dense_45_categorical_accuracy: 0.7793 - dense_46_categorical_accuracy: 0.3953 - dense_47_categorical_accuracy: 0.8299 - dense_48_categorical_accuracy: 0.7765 - dense_49_categorical_accuracy: 0.4960 - dense_50_categorical_accuracy: 0.7054 - dense_51_categorical_accuracy: 0.6089 - dense_52_categorical_accuracy: 0.4368 - dense_53_categorical_accuracy: 0.6907 - dense_54_categorical_accuracy: 0.5241 - dense_55_categorical_accuracy: 0.5883 - dense_56_categorical_accuracy: 0.4253 - dense_57_categorical_accuracy: 0.4948 - dense_58_categorical_accuracy: 0.7150 - dense_59_categorical_accuracy: 0.7485 - dense_60_categorical_accuracy: 0.5179 - dense_61_categorical_accuracy: 0.5858"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4480/105000 [>.............................] - ETA: 22:28:58 - loss: 11.0451 - dense_42_loss: 0.5505 - dense_43_loss: 0.5476 - dense_44_loss: 0.5463 - dense_45_loss: 0.5452 - dense_46_loss: 0.5595 - dense_47_loss: 0.5444 - dense_48_loss: 0.5458 - dense_49_loss: 0.5570 - dense_50_loss: 0.5498 - dense_51_loss: 0.5528 - dense_52_loss: 0.5584 - dense_53_loss: 0.5521 - dense_54_loss: 0.5556 - dense_55_loss: 0.5552 - dense_56_loss: 0.5596 - dense_57_loss: 0.5566 - dense_58_loss: 0.5506 - dense_59_loss: 0.5484 - dense_60_loss: 0.5557 - dense_61_loss: 0.5541 - dense_42_categorical_accuracy: 0.6877 - dense_43_categorical_accuracy: 0.7808 - dense_44_categorical_accuracy: 0.7576 - dense_45_categorical_accuracy: 0.7793 - dense_46_categorical_accuracy: 0.3943 - dense_47_categorical_accuracy: 0.8320 - dense_48_categorical_accuracy: 0.7766 - dense_49_categorical_accuracy: 0.4961 - dense_50_categorical_accuracy: 0.7056 - dense_51_categorical_accuracy: 0.6079 - dense_52_categorical_accuracy: 0.4363 - dense_53_categorical_accuracy: 0.6902 - dense_54_categorical_accuracy: 0.5249 - dense_55_categorical_accuracy: 0.5884 - dense_56_categorical_accuracy: 0.4268 - dense_57_categorical_accuracy: 0.4946 - dense_58_categorical_accuracy: 0.7144 - dense_59_categorical_accuracy: 0.7493 - dense_60_categorical_accuracy: 0.5208 - dense_61_categorical_accuracy: 0.58 - ETA: 22:30:50 - loss: 11.0419 - dense_42_loss: 0.5503 - dense_43_loss: 0.5474 - dense_44_loss: 0.5461 - dense_45_loss: 0.5450 - dense_46_loss: 0.5594 - dense_47_loss: 0.5441 - dense_48_loss: 0.5456 - dense_49_loss: 0.5570 - dense_50_loss: 0.5496 - dense_51_loss: 0.5527 - dense_52_loss: 0.5583 - dense_53_loss: 0.5519 - dense_54_loss: 0.5555 - dense_55_loss: 0.5550 - dense_56_loss: 0.5595 - dense_57_loss: 0.5565 - dense_58_loss: 0.5504 - dense_59_loss: 0.5482 - dense_60_loss: 0.5556 - dense_61_loss: 0.5540 - dense_42_categorical_accuracy: 0.6897 - dense_43_categorical_accuracy: 0.7800 - dense_44_categorical_accuracy: 0.7577 - dense_45_categorical_accuracy: 0.7803 - dense_46_categorical_accuracy: 0.3950 - dense_47_categorical_accuracy: 0.8334 - dense_48_categorical_accuracy: 0.7769 - dense_49_categorical_accuracy: 0.4947 - dense_50_categorical_accuracy: 0.7060 - dense_51_categorical_accuracy: 0.6077 - dense_52_categorical_accuracy: 0.4385 - dense_53_categorical_accuracy: 0.6904 - dense_54_categorical_accuracy: 0.5257 - dense_55_categorical_accuracy: 0.5901 - dense_56_categorical_accuracy: 0.4274 - dense_57_categorical_accuracy: 0.4954 - dense_58_categorical_accuracy: 0.7147 - dense_59_categorical_accuracy: 0.7502 - dense_60_categorical_accuracy: 0.5231 - dense_61_categorical_accuracy: 0.58 - ETA: 22:32:25 - loss: 11.0389 - dense_42_loss: 0.5501 - dense_43_loss: 0.5472 - dense_44_loss: 0.5459 - dense_45_loss: 0.5447 - dense_46_loss: 0.5593 - dense_47_loss: 0.5438 - dense_48_loss: 0.5453 - dense_49_loss: 0.5570 - dense_50_loss: 0.5495 - dense_51_loss: 0.5526 - dense_52_loss: 0.5582 - dense_53_loss: 0.5518 - dense_54_loss: 0.5554 - dense_55_loss: 0.5548 - dense_56_loss: 0.5595 - dense_57_loss: 0.5564 - dense_58_loss: 0.5503 - dense_59_loss: 0.5480 - dense_60_loss: 0.5554 - dense_61_loss: 0.5539 - dense_42_categorical_accuracy: 0.6908 - dense_43_categorical_accuracy: 0.7803 - dense_44_categorical_accuracy: 0.7580 - dense_45_categorical_accuracy: 0.7815 - dense_46_categorical_accuracy: 0.3954 - dense_47_categorical_accuracy: 0.8348 - dense_48_categorical_accuracy: 0.7782 - dense_49_categorical_accuracy: 0.4941 - dense_50_categorical_accuracy: 0.7053 - dense_51_categorical_accuracy: 0.6072 - dense_52_categorical_accuracy: 0.4401 - dense_53_categorical_accuracy: 0.6915 - dense_54_categorical_accuracy: 0.5272 - dense_55_categorical_accuracy: 0.5921 - dense_56_categorical_accuracy: 0.4271 - dense_57_categorical_accuracy: 0.4967 - dense_58_categorical_accuracy: 0.7131 - dense_59_categorical_accuracy: 0.7498 - dense_60_categorical_accuracy: 0.5263 - dense_61_categorical_accuracy: 0.58 - ETA: 22:33:08 - loss: 11.0357 - dense_42_loss: 0.5499 - dense_43_loss: 0.5469 - dense_44_loss: 0.5457 - dense_45_loss: 0.5444 - dense_46_loss: 0.5593 - dense_47_loss: 0.5434 - dense_48_loss: 0.5450 - dense_49_loss: 0.5570 - dense_50_loss: 0.5493 - dense_51_loss: 0.5525 - dense_52_loss: 0.5581 - dense_53_loss: 0.5516 - dense_54_loss: 0.5553 - dense_55_loss: 0.5547 - dense_56_loss: 0.5594 - dense_57_loss: 0.5562 - dense_58_loss: 0.5502 - dense_59_loss: 0.5478 - dense_60_loss: 0.5553 - dense_61_loss: 0.5537 - dense_42_categorical_accuracy: 0.6917 - dense_43_categorical_accuracy: 0.7810 - dense_44_categorical_accuracy: 0.7584 - dense_45_categorical_accuracy: 0.7836 - dense_46_categorical_accuracy: 0.3953 - dense_47_categorical_accuracy: 0.8365 - dense_48_categorical_accuracy: 0.7789 - dense_49_categorical_accuracy: 0.4925 - dense_50_categorical_accuracy: 0.7059 - dense_51_categorical_accuracy: 0.6066 - dense_52_categorical_accuracy: 0.4403 - dense_53_categorical_accuracy: 0.6912 - dense_54_categorical_accuracy: 0.5282 - dense_55_categorical_accuracy: 0.5938 - dense_56_categorical_accuracy: 0.4282 - dense_57_categorical_accuracy: 0.4967 - dense_58_categorical_accuracy: 0.7120 - dense_59_categorical_accuracy: 0.7505 - dense_60_categorical_accuracy: 0.5289 - dense_61_categorical_accuracy: 0.58 - ETA: 22:39:19 - loss: 11.0325 - dense_42_loss: 0.5497 - dense_43_loss: 0.5468 - dense_44_loss: 0.5455 - dense_45_loss: 0.5441 - dense_46_loss: 0.5592 - dense_47_loss: 0.5430 - dense_48_loss: 0.5448 - dense_49_loss: 0.5569 - dense_50_loss: 0.5492 - dense_51_loss: 0.5524 - dense_52_loss: 0.5580 - dense_53_loss: 0.5515 - dense_54_loss: 0.5551 - dense_55_loss: 0.5545 - dense_56_loss: 0.5594 - dense_57_loss: 0.5562 - dense_58_loss: 0.5499 - dense_59_loss: 0.5476 - dense_60_loss: 0.5551 - dense_61_loss: 0.5536 - dense_42_categorical_accuracy: 0.6935 - dense_43_categorical_accuracy: 0.7801 - dense_44_categorical_accuracy: 0.7594 - dense_45_categorical_accuracy: 0.7847 - dense_46_categorical_accuracy: 0.3957 - dense_47_categorical_accuracy: 0.8385 - dense_48_categorical_accuracy: 0.7801 - dense_49_categorical_accuracy: 0.4920 - dense_50_categorical_accuracy: 0.7052 - dense_51_categorical_accuracy: 0.6078 - dense_52_categorical_accuracy: 0.4405 - dense_53_categorical_accuracy: 0.6912 - dense_54_categorical_accuracy: 0.5308 - dense_55_categorical_accuracy: 0.5947 - dense_56_categorical_accuracy: 0.4288 - dense_57_categorical_accuracy: 0.4975 - dense_58_categorical_accuracy: 0.7135 - dense_59_categorical_accuracy: 0.7514 - dense_60_categorical_accuracy: 0.5308 - dense_61_categorical_accuracy: 0.58 - ETA: 22:42:52 - loss: 11.0294 - dense_42_loss: 0.5495 - dense_43_loss: 0.5465 - dense_44_loss: 0.5453 - dense_45_loss: 0.5438 - dense_46_loss: 0.5592 - dense_47_loss: 0.5427 - dense_48_loss: 0.5445 - dense_49_loss: 0.5568 - dense_50_loss: 0.5489 - dense_51_loss: 0.5522 - dense_52_loss: 0.5580 - dense_53_loss: 0.5514 - dense_54_loss: 0.5550 - dense_55_loss: 0.5544 - dense_56_loss: 0.5593 - dense_57_loss: 0.5561 - dense_58_loss: 0.5498 - dense_59_loss: 0.5474 - dense_60_loss: 0.5550 - dense_61_loss: 0.5535 - dense_42_categorical_accuracy: 0.6936 - dense_43_categorical_accuracy: 0.7801 - dense_44_categorical_accuracy: 0.7591 - dense_45_categorical_accuracy: 0.7862 - dense_46_categorical_accuracy: 0.3942 - dense_47_categorical_accuracy: 0.8390 - dense_48_categorical_accuracy: 0.7810 - dense_49_categorical_accuracy: 0.4939 - dense_50_categorical_accuracy: 0.7067 - dense_51_categorical_accuracy: 0.6091 - dense_52_categorical_accuracy: 0.4402 - dense_53_categorical_accuracy: 0.6898 - dense_54_categorical_accuracy: 0.5315 - dense_55_categorical_accuracy: 0.5960 - dense_56_categorical_accuracy: 0.4303 - dense_57_categorical_accuracy: 0.4977 - dense_58_categorical_accuracy: 0.7138 - dense_59_categorical_accuracy: 0.7511 - dense_60_categorical_accuracy: 0.5328 - dense_61_categorical_accuracy: 0.58 - ETA: 22:46:41 - loss: 11.0264 - dense_42_loss: 0.5493 - dense_43_loss: 0.5463 - dense_44_loss: 0.5451 - dense_45_loss: 0.5435 - dense_46_loss: 0.5592 - dense_47_loss: 0.5424 - dense_48_loss: 0.5443 - dense_49_loss: 0.5568 - dense_50_loss: 0.5487 - dense_51_loss: 0.5521 - dense_52_loss: 0.5579 - dense_53_loss: 0.5512 - dense_54_loss: 0.5550 - dense_55_loss: 0.5542 - dense_56_loss: 0.5592 - dense_57_loss: 0.5560 - dense_58_loss: 0.5496 - dense_59_loss: 0.5472 - dense_60_loss: 0.5549 - dense_61_loss: 0.5534 - dense_42_categorical_accuracy: 0.6942 - dense_43_categorical_accuracy: 0.7804 - dense_44_categorical_accuracy: 0.7592 - dense_45_categorical_accuracy: 0.7875 - dense_46_categorical_accuracy: 0.3915 - dense_47_categorical_accuracy: 0.8400 - dense_48_categorical_accuracy: 0.7817 - dense_49_categorical_accuracy: 0.4940 - dense_50_categorical_accuracy: 0.7083 - dense_51_categorical_accuracy: 0.6105 - dense_52_categorical_accuracy: 0.4426 - dense_53_categorical_accuracy: 0.6906 - dense_54_categorical_accuracy: 0.5319 - dense_55_categorical_accuracy: 0.5973 - dense_56_categorical_accuracy: 0.4321 - dense_57_categorical_accuracy: 0.4975 - dense_58_categorical_accuracy: 0.7134 - dense_59_categorical_accuracy: 0.7516 - dense_60_categorical_accuracy: 0.5335 - dense_61_categorical_accuracy: 0.5879"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4928/105000 [>.............................] - ETA: 22:49:30 - loss: 11.0230 - dense_42_loss: 0.5491 - dense_43_loss: 0.5461 - dense_44_loss: 0.5449 - dense_45_loss: 0.5432 - dense_46_loss: 0.5592 - dense_47_loss: 0.5421 - dense_48_loss: 0.5440 - dense_49_loss: 0.5568 - dense_50_loss: 0.5485 - dense_51_loss: 0.5520 - dense_52_loss: 0.5578 - dense_53_loss: 0.5510 - dense_54_loss: 0.5548 - dense_55_loss: 0.5541 - dense_56_loss: 0.5591 - dense_57_loss: 0.5559 - dense_58_loss: 0.5495 - dense_59_loss: 0.5470 - dense_60_loss: 0.5548 - dense_61_loss: 0.5533 - dense_42_categorical_accuracy: 0.6943 - dense_43_categorical_accuracy: 0.7810 - dense_44_categorical_accuracy: 0.7597 - dense_45_categorical_accuracy: 0.7892 - dense_46_categorical_accuracy: 0.3922 - dense_47_categorical_accuracy: 0.8415 - dense_48_categorical_accuracy: 0.7830 - dense_49_categorical_accuracy: 0.4932 - dense_50_categorical_accuracy: 0.7095 - dense_51_categorical_accuracy: 0.6107 - dense_52_categorical_accuracy: 0.4428 - dense_53_categorical_accuracy: 0.6910 - dense_54_categorical_accuracy: 0.5335 - dense_55_categorical_accuracy: 0.5984 - dense_56_categorical_accuracy: 0.4338 - dense_57_categorical_accuracy: 0.4989 - dense_58_categorical_accuracy: 0.7132 - dense_59_categorical_accuracy: 0.7526 - dense_60_categorical_accuracy: 0.5357 - dense_61_categorical_accuracy: 0.58 - ETA: 22:53:43 - loss: 11.0194 - dense_42_loss: 0.5489 - dense_43_loss: 0.5458 - dense_44_loss: 0.5446 - dense_45_loss: 0.5429 - dense_46_loss: 0.5591 - dense_47_loss: 0.5417 - dense_48_loss: 0.5437 - dense_49_loss: 0.5568 - dense_50_loss: 0.5483 - dense_51_loss: 0.5518 - dense_52_loss: 0.5577 - dense_53_loss: 0.5508 - dense_54_loss: 0.5547 - dense_55_loss: 0.5539 - dense_56_loss: 0.5590 - dense_57_loss: 0.5558 - dense_58_loss: 0.5493 - dense_59_loss: 0.5467 - dense_60_loss: 0.5546 - dense_61_loss: 0.5532 - dense_42_categorical_accuracy: 0.6953 - dense_43_categorical_accuracy: 0.7823 - dense_44_categorical_accuracy: 0.7615 - dense_45_categorical_accuracy: 0.7910 - dense_46_categorical_accuracy: 0.3919 - dense_47_categorical_accuracy: 0.8427 - dense_48_categorical_accuracy: 0.7839 - dense_49_categorical_accuracy: 0.4924 - dense_50_categorical_accuracy: 0.7094 - dense_51_categorical_accuracy: 0.6113 - dense_52_categorical_accuracy: 0.4455 - dense_53_categorical_accuracy: 0.6936 - dense_54_categorical_accuracy: 0.5365 - dense_55_categorical_accuracy: 0.6011 - dense_56_categorical_accuracy: 0.4360 - dense_57_categorical_accuracy: 0.4996 - dense_58_categorical_accuracy: 0.7135 - dense_59_categorical_accuracy: 0.7539 - dense_60_categorical_accuracy: 0.5373 - dense_61_categorical_accuracy: 0.58 - ETA: 22:56:09 - loss: 11.0162 - dense_42_loss: 0.5487 - dense_43_loss: 0.5455 - dense_44_loss: 0.5444 - dense_45_loss: 0.5426 - dense_46_loss: 0.5591 - dense_47_loss: 0.5414 - dense_48_loss: 0.5435 - dense_49_loss: 0.5567 - dense_50_loss: 0.5481 - dense_51_loss: 0.5518 - dense_52_loss: 0.5576 - dense_53_loss: 0.5506 - dense_54_loss: 0.5546 - dense_55_loss: 0.5538 - dense_56_loss: 0.5590 - dense_57_loss: 0.5557 - dense_58_loss: 0.5491 - dense_59_loss: 0.5464 - dense_60_loss: 0.5545 - dense_61_loss: 0.5531 - dense_42_categorical_accuracy: 0.6969 - dense_43_categorical_accuracy: 0.7836 - dense_44_categorical_accuracy: 0.7620 - dense_45_categorical_accuracy: 0.7924 - dense_46_categorical_accuracy: 0.3902 - dense_47_categorical_accuracy: 0.8438 - dense_48_categorical_accuracy: 0.7842 - dense_49_categorical_accuracy: 0.4929 - dense_50_categorical_accuracy: 0.7106 - dense_51_categorical_accuracy: 0.6104 - dense_52_categorical_accuracy: 0.4456 - dense_53_categorical_accuracy: 0.6935 - dense_54_categorical_accuracy: 0.5368 - dense_55_categorical_accuracy: 0.6008 - dense_56_categorical_accuracy: 0.4379 - dense_57_categorical_accuracy: 0.4989 - dense_58_categorical_accuracy: 0.7140 - dense_59_categorical_accuracy: 0.7554 - dense_60_categorical_accuracy: 0.5379 - dense_61_categorical_accuracy: 0.58 - ETA: 22:59:48 - loss: 11.0125 - dense_42_loss: 0.5485 - dense_43_loss: 0.5452 - dense_44_loss: 0.5441 - dense_45_loss: 0.5423 - dense_46_loss: 0.5591 - dense_47_loss: 0.5410 - dense_48_loss: 0.5433 - dense_49_loss: 0.5567 - dense_50_loss: 0.5479 - dense_51_loss: 0.5516 - dense_52_loss: 0.5575 - dense_53_loss: 0.5504 - dense_54_loss: 0.5544 - dense_55_loss: 0.5536 - dense_56_loss: 0.5589 - dense_57_loss: 0.5556 - dense_58_loss: 0.5489 - dense_59_loss: 0.5462 - dense_60_loss: 0.5545 - dense_61_loss: 0.5529 - dense_42_categorical_accuracy: 0.6983 - dense_43_categorical_accuracy: 0.7851 - dense_44_categorical_accuracy: 0.7635 - dense_45_categorical_accuracy: 0.7937 - dense_46_categorical_accuracy: 0.3906 - dense_47_categorical_accuracy: 0.8459 - dense_48_categorical_accuracy: 0.7846 - dense_49_categorical_accuracy: 0.4924 - dense_50_categorical_accuracy: 0.7116 - dense_51_categorical_accuracy: 0.6117 - dense_52_categorical_accuracy: 0.4478 - dense_53_categorical_accuracy: 0.6947 - dense_54_categorical_accuracy: 0.5393 - dense_55_categorical_accuracy: 0.6026 - dense_56_categorical_accuracy: 0.4413 - dense_57_categorical_accuracy: 0.4985 - dense_58_categorical_accuracy: 0.7154 - dense_59_categorical_accuracy: 0.7570 - dense_60_categorical_accuracy: 0.5378 - dense_61_categorical_accuracy: 0.58 - ETA: 23:03:20 - loss: 11.0093 - dense_42_loss: 0.5483 - dense_43_loss: 0.5450 - dense_44_loss: 0.5439 - dense_45_loss: 0.5421 - dense_46_loss: 0.5590 - dense_47_loss: 0.5406 - dense_48_loss: 0.5430 - dense_49_loss: 0.5567 - dense_50_loss: 0.5477 - dense_51_loss: 0.5515 - dense_52_loss: 0.5574 - dense_53_loss: 0.5502 - dense_54_loss: 0.5543 - dense_55_loss: 0.5535 - dense_56_loss: 0.5588 - dense_57_loss: 0.5556 - dense_58_loss: 0.5487 - dense_59_loss: 0.5459 - dense_60_loss: 0.5543 - dense_61_loss: 0.5528 - dense_42_categorical_accuracy: 0.6994 - dense_43_categorical_accuracy: 0.7852 - dense_44_categorical_accuracy: 0.7644 - dense_45_categorical_accuracy: 0.7942 - dense_46_categorical_accuracy: 0.3898 - dense_47_categorical_accuracy: 0.8473 - dense_48_categorical_accuracy: 0.7854 - dense_49_categorical_accuracy: 0.4919 - dense_50_categorical_accuracy: 0.7123 - dense_51_categorical_accuracy: 0.6121 - dense_52_categorical_accuracy: 0.4487 - dense_53_categorical_accuracy: 0.6956 - dense_54_categorical_accuracy: 0.5406 - dense_55_categorical_accuracy: 0.6031 - dense_56_categorical_accuracy: 0.4429 - dense_57_categorical_accuracy: 0.4990 - dense_58_categorical_accuracy: 0.7152 - dense_59_categorical_accuracy: 0.7577 - dense_60_categorical_accuracy: 0.5396 - dense_61_categorical_accuracy: 0.58 - ETA: 23:05:19 - loss: 11.0063 - dense_42_loss: 0.5481 - dense_43_loss: 0.5447 - dense_44_loss: 0.5437 - dense_45_loss: 0.5417 - dense_46_loss: 0.5589 - dense_47_loss: 0.5403 - dense_48_loss: 0.5427 - dense_49_loss: 0.5567 - dense_50_loss: 0.5475 - dense_51_loss: 0.5514 - dense_52_loss: 0.5574 - dense_53_loss: 0.5501 - dense_54_loss: 0.5542 - dense_55_loss: 0.5533 - dense_56_loss: 0.5587 - dense_57_loss: 0.5555 - dense_58_loss: 0.5486 - dense_59_loss: 0.5457 - dense_60_loss: 0.5542 - dense_61_loss: 0.5527 - dense_42_categorical_accuracy: 0.7005 - dense_43_categorical_accuracy: 0.7850 - dense_44_categorical_accuracy: 0.7636 - dense_45_categorical_accuracy: 0.7958 - dense_46_categorical_accuracy: 0.3896 - dense_47_categorical_accuracy: 0.8479 - dense_48_categorical_accuracy: 0.7866 - dense_49_categorical_accuracy: 0.4910 - dense_50_categorical_accuracy: 0.7132 - dense_51_categorical_accuracy: 0.6127 - dense_52_categorical_accuracy: 0.4482 - dense_53_categorical_accuracy: 0.6947 - dense_54_categorical_accuracy: 0.5419 - dense_55_categorical_accuracy: 0.6034 - dense_56_categorical_accuracy: 0.4439 - dense_57_categorical_accuracy: 0.4992 - dense_58_categorical_accuracy: 0.7142 - dense_59_categorical_accuracy: 0.7576 - dense_60_categorical_accuracy: 0.5411 - dense_61_categorical_accuracy: 0.58 - ETA: 23:07:00 - loss: 11.0029 - dense_42_loss: 0.5478 - dense_43_loss: 0.5446 - dense_44_loss: 0.5435 - dense_45_loss: 0.5415 - dense_46_loss: 0.5589 - dense_47_loss: 0.5400 - dense_48_loss: 0.5425 - dense_49_loss: 0.5566 - dense_50_loss: 0.5472 - dense_51_loss: 0.5513 - dense_52_loss: 0.5573 - dense_53_loss: 0.5499 - dense_54_loss: 0.5541 - dense_55_loss: 0.5532 - dense_56_loss: 0.5586 - dense_57_loss: 0.5553 - dense_58_loss: 0.5484 - dense_59_loss: 0.5455 - dense_60_loss: 0.5541 - dense_61_loss: 0.5526 - dense_42_categorical_accuracy: 0.7019 - dense_43_categorical_accuracy: 0.7845 - dense_44_categorical_accuracy: 0.7632 - dense_45_categorical_accuracy: 0.7965 - dense_46_categorical_accuracy: 0.3902 - dense_47_categorical_accuracy: 0.8488 - dense_48_categorical_accuracy: 0.7871 - dense_49_categorical_accuracy: 0.4907 - dense_50_categorical_accuracy: 0.7149 - dense_51_categorical_accuracy: 0.6132 - dense_52_categorical_accuracy: 0.4493 - dense_53_categorical_accuracy: 0.6950 - dense_54_categorical_accuracy: 0.5436 - dense_55_categorical_accuracy: 0.6041 - dense_56_categorical_accuracy: 0.4454 - dense_57_categorical_accuracy: 0.4994 - dense_58_categorical_accuracy: 0.7157 - dense_59_categorical_accuracy: 0.7587 - dense_60_categorical_accuracy: 0.5420 - dense_61_categorical_accuracy: 0.5891"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5248/105000 [>.............................] - ETA: 23:10:14 - loss: 10.9997 - dense_42_loss: 0.5475 - dense_43_loss: 0.5443 - dense_44_loss: 0.5433 - dense_45_loss: 0.5411 - dense_46_loss: 0.5589 - dense_47_loss: 0.5397 - dense_48_loss: 0.5423 - dense_49_loss: 0.5566 - dense_50_loss: 0.5470 - dense_51_loss: 0.5512 - dense_52_loss: 0.5572 - dense_53_loss: 0.5498 - dense_54_loss: 0.5540 - dense_55_loss: 0.5531 - dense_56_loss: 0.5586 - dense_57_loss: 0.5552 - dense_58_loss: 0.5483 - dense_59_loss: 0.5453 - dense_60_loss: 0.5539 - dense_61_loss: 0.5524 - dense_42_categorical_accuracy: 0.7047 - dense_43_categorical_accuracy: 0.7847 - dense_44_categorical_accuracy: 0.7640 - dense_45_categorical_accuracy: 0.7983 - dense_46_categorical_accuracy: 0.3898 - dense_47_categorical_accuracy: 0.8500 - dense_48_categorical_accuracy: 0.7873 - dense_49_categorical_accuracy: 0.4900 - dense_50_categorical_accuracy: 0.7153 - dense_51_categorical_accuracy: 0.6130 - dense_52_categorical_accuracy: 0.4497 - dense_53_categorical_accuracy: 0.6947 - dense_54_categorical_accuracy: 0.5445 - dense_55_categorical_accuracy: 0.6040 - dense_56_categorical_accuracy: 0.4459 - dense_57_categorical_accuracy: 0.5004 - dense_58_categorical_accuracy: 0.7149 - dense_59_categorical_accuracy: 0.7592 - dense_60_categorical_accuracy: 0.5443 - dense_61_categorical_accuracy: 0.58 - ETA: 23:13:46 - loss: 10.9963 - dense_42_loss: 0.5473 - dense_43_loss: 0.5441 - dense_44_loss: 0.5431 - dense_45_loss: 0.5408 - dense_46_loss: 0.5588 - dense_47_loss: 0.5393 - dense_48_loss: 0.5420 - dense_49_loss: 0.5566 - dense_50_loss: 0.5468 - dense_51_loss: 0.5510 - dense_52_loss: 0.5571 - dense_53_loss: 0.5496 - dense_54_loss: 0.5538 - dense_55_loss: 0.5529 - dense_56_loss: 0.5585 - dense_57_loss: 0.5551 - dense_58_loss: 0.5481 - dense_59_loss: 0.5451 - dense_60_loss: 0.5538 - dense_61_loss: 0.5523 - dense_42_categorical_accuracy: 0.7065 - dense_43_categorical_accuracy: 0.7840 - dense_44_categorical_accuracy: 0.7634 - dense_45_categorical_accuracy: 0.7998 - dense_46_categorical_accuracy: 0.3894 - dense_47_categorical_accuracy: 0.8509 - dense_48_categorical_accuracy: 0.7880 - dense_49_categorical_accuracy: 0.4899 - dense_50_categorical_accuracy: 0.7168 - dense_51_categorical_accuracy: 0.6137 - dense_52_categorical_accuracy: 0.4517 - dense_53_categorical_accuracy: 0.6956 - dense_54_categorical_accuracy: 0.5467 - dense_55_categorical_accuracy: 0.6054 - dense_56_categorical_accuracy: 0.4482 - dense_57_categorical_accuracy: 0.5004 - dense_58_categorical_accuracy: 0.7156 - dense_59_categorical_accuracy: 0.7597 - dense_60_categorical_accuracy: 0.5453 - dense_61_categorical_accuracy: 0.59 - ETA: 23:15:37 - loss: 10.9933 - dense_42_loss: 0.5471 - dense_43_loss: 0.5440 - dense_44_loss: 0.5429 - dense_45_loss: 0.5405 - dense_46_loss: 0.5588 - dense_47_loss: 0.5390 - dense_48_loss: 0.5418 - dense_49_loss: 0.5566 - dense_50_loss: 0.5466 - dense_51_loss: 0.5510 - dense_52_loss: 0.5570 - dense_53_loss: 0.5495 - dense_54_loss: 0.5537 - dense_55_loss: 0.5528 - dense_56_loss: 0.5584 - dense_57_loss: 0.5551 - dense_58_loss: 0.5479 - dense_59_loss: 0.5448 - dense_60_loss: 0.5537 - dense_61_loss: 0.5523 - dense_42_categorical_accuracy: 0.7068 - dense_43_categorical_accuracy: 0.7830 - dense_44_categorical_accuracy: 0.7635 - dense_45_categorical_accuracy: 0.8010 - dense_46_categorical_accuracy: 0.3893 - dense_47_categorical_accuracy: 0.8523 - dense_48_categorical_accuracy: 0.7883 - dense_49_categorical_accuracy: 0.4895 - dense_50_categorical_accuracy: 0.7170 - dense_51_categorical_accuracy: 0.6131 - dense_52_categorical_accuracy: 0.4527 - dense_53_categorical_accuracy: 0.6957 - dense_54_categorical_accuracy: 0.5479 - dense_55_categorical_accuracy: 0.6062 - dense_56_categorical_accuracy: 0.4492 - dense_57_categorical_accuracy: 0.5000 - dense_58_categorical_accuracy: 0.7156 - dense_59_categorical_accuracy: 0.7609 - dense_60_categorical_accuracy: 0.5461 - dense_61_categorical_accuracy: 0.58 - ETA: 23:17:20 - loss: 10.9901 - dense_42_loss: 0.5469 - dense_43_loss: 0.5438 - dense_44_loss: 0.5427 - dense_45_loss: 0.5403 - dense_46_loss: 0.5587 - dense_47_loss: 0.5386 - dense_48_loss: 0.5416 - dense_49_loss: 0.5565 - dense_50_loss: 0.5464 - dense_51_loss: 0.5509 - dense_52_loss: 0.5570 - dense_53_loss: 0.5493 - dense_54_loss: 0.5536 - dense_55_loss: 0.5526 - dense_56_loss: 0.5583 - dense_57_loss: 0.5549 - dense_58_loss: 0.5477 - dense_59_loss: 0.5446 - dense_60_loss: 0.5536 - dense_61_loss: 0.5521 - dense_42_categorical_accuracy: 0.7072 - dense_43_categorical_accuracy: 0.7830 - dense_44_categorical_accuracy: 0.7637 - dense_45_categorical_accuracy: 0.8007 - dense_46_categorical_accuracy: 0.3904 - dense_47_categorical_accuracy: 0.8538 - dense_48_categorical_accuracy: 0.7884 - dense_49_categorical_accuracy: 0.4896 - dense_50_categorical_accuracy: 0.7186 - dense_51_categorical_accuracy: 0.6130 - dense_52_categorical_accuracy: 0.4531 - dense_53_categorical_accuracy: 0.6966 - dense_54_categorical_accuracy: 0.5492 - dense_55_categorical_accuracy: 0.6073 - dense_56_categorical_accuracy: 0.4500 - dense_57_categorical_accuracy: 0.5012 - dense_58_categorical_accuracy: 0.7164 - dense_59_categorical_accuracy: 0.7618 - dense_60_categorical_accuracy: 0.5475 - dense_61_categorical_accuracy: 0.58 - ETA: 23:19:40 - loss: 10.9870 - dense_42_loss: 0.5467 - dense_43_loss: 0.5436 - dense_44_loss: 0.5426 - dense_45_loss: 0.5400 - dense_46_loss: 0.5586 - dense_47_loss: 0.5382 - dense_48_loss: 0.5414 - dense_49_loss: 0.5565 - dense_50_loss: 0.5463 - dense_51_loss: 0.5507 - dense_52_loss: 0.5569 - dense_53_loss: 0.5491 - dense_54_loss: 0.5535 - dense_55_loss: 0.5525 - dense_56_loss: 0.5582 - dense_57_loss: 0.5548 - dense_58_loss: 0.5475 - dense_59_loss: 0.5443 - dense_60_loss: 0.5535 - dense_61_loss: 0.5521 - dense_42_categorical_accuracy: 0.7085 - dense_43_categorical_accuracy: 0.7830 - dense_44_categorical_accuracy: 0.7631 - dense_45_categorical_accuracy: 0.8018 - dense_46_categorical_accuracy: 0.3916 - dense_47_categorical_accuracy: 0.8554 - dense_48_categorical_accuracy: 0.7889 - dense_49_categorical_accuracy: 0.4897 - dense_50_categorical_accuracy: 0.7167 - dense_51_categorical_accuracy: 0.6139 - dense_52_categorical_accuracy: 0.4546 - dense_53_categorical_accuracy: 0.6965 - dense_54_categorical_accuracy: 0.5511 - dense_55_categorical_accuracy: 0.6080 - dense_56_categorical_accuracy: 0.4526 - dense_57_categorical_accuracy: 0.5013 - dense_58_categorical_accuracy: 0.7165 - dense_59_categorical_accuracy: 0.7630 - dense_60_categorical_accuracy: 0.5478 - dense_61_categorical_accuracy: 0.5886"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "for i in range(5):\n",
    "    name = 'model_v' + str(i)\n",
    "    model.fit(Train_pad, Train_label, epochs=1, batch_size = 64)\n",
    "    model.save(name)\n",
    "\n",
    "    val_test = model.predict(Validation_pad)\n",
    "    val_label = np.zeros((15000))\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "\n",
    "    for i in range(len(label_name)):\n",
    "        y_pred.append(np.argmax(val_test[i], axis = 1))\n",
    "        y_true.append(np.argmax(Validation_labels[label_name[i]], axis=1))\n",
    "    # val_label = np.copy(Validation_labels)\n",
    "\n",
    "    from sklearn import metrics\n",
    "\n",
    "    f1 = []\n",
    "    for j in range(len(y_pred)):\n",
    "        f1.append(metrics.f1_score(y_true[j], y_pred[j], average = 'micro'))\n",
    "\n",
    "        \n",
    "    print('================================================')\n",
    "    print(np.average(f1))\n",
    "    print('================================================')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = model.predict(Test_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(label_name)):\n",
    "    tmp = np.array(ans[j])\n",
    "    tmp = np.argmax(tmp,axis=1)\n",
    "    tmp[tmp == 3] = -2\n",
    "    tmp[tmp == 2] = -1\n",
    "    Test_data_raw[label_name[j]] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_data_raw.to_csv(\"submission_v3.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>location_traffic_convenience</th>\n",
       "      <th>location_distance_from_business_district</th>\n",
       "      <th>location_easy_to_find</th>\n",
       "      <th>service_wait_time</th>\n",
       "      <th>service_waiters_attitude</th>\n",
       "      <th>service_parking_convenience</th>\n",
       "      <th>service_serving_speed</th>\n",
       "      <th>price_level</th>\n",
       "      <th>...</th>\n",
       "      <th>environment_decoration</th>\n",
       "      <th>environment_noise</th>\n",
       "      <th>environment_space</th>\n",
       "      <th>environment_cleaness</th>\n",
       "      <th>dish_portion</th>\n",
       "      <th>dish_taste</th>\n",
       "      <th>dish_look</th>\n",
       "      <th>dish_recommendation</th>\n",
       "      <th>others_overall_experience</th>\n",
       "      <th>others_willing_to_consume_again</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\"我想说他们家的优惠活动好持久啊，我预售的时候买的券，前两天心血来潮去吃的活动还在继续\\n首...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\"终于开到心心念念的LAB loft。第一次来就随便点也一些～【香辣虾意面】蛮辣的，但其实一...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>\"地理位置好，交通方便，就在124车站对面交通方便，很好，我晚上7点多去买的了，已经没有什么...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"运气很好，抽中了大众点评的霸王餐。这家主题餐厅心仪已久了，种种原因一直未能成行，没想到抽中...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>\"幸运随点评团体验霸王餐，心情好~蜀九香刚进驻泉州不久，招牌大名气响，以至于刚到店门口的我被...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>\"尽管韩国烤肉店在无锡已经有很多家了，但因为味道好吃再加上在无锡很有人气，依旧挡不住新店的开...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>\"店铺在乙烯生活二区的西北角，旁边是国旅的旗舰店，门口就是红绿灯，挺好找的。因为这是两磅一的...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>\"朋友聚会来滴，这个地方真心不错哇，又能撸串，又能唱歌，还能看现场歌手演唱。最主要是可以上台...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>\"超喜欢这家的面食，经常来吃。这家风格及产品都很像京城御面，有时会怀疑是不是同一家的。面条比...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>\"广西阳朔，前一天晚上吃的特色啤酒鱼，就看到了隔壁有家螺蛳粉，第二天过来吃。个人比较喜欢粉，...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>\"蛮早之前就在人气美食看过报道这家的夜宵了，一直想来看看，终于这次来了~~\\n大概晚上10点...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>\"中秋花好月圆之夜,一家老小共八人选择此地吃团圆饭。吴中店是新店，环境干净大气\\n整洁，提前...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>\"地址：他家位于万达广场C区，也就是说面向万达广场正面左边方向的后面商铺，要从背面商铺一楼寻...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>\"没错，我就是楼上的室友。已经告别自助三年的我曾经发誓再也不吃自助这种只有量没有质的东西。可...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>\"我亲爱的姐姐人品爆发抽中了豪华双人霸王餐，为了能吃上这一顿我还特意提前了一天从贵阳回到成都...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>\"＃试吃/体验点评＃首先还是照例感谢大众点评和商家抽中我！感谢好运气！这次想着带父皇母后来体...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>\"原价比较贵，大众点评立减17的优惠很给力，可以点豪d，两个人原价213，折后149，吃得很...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>\"原来去过一家浮力森林，就是铂金城的那家。\\n\\n但不知道从好久那家也不复存在。\\n\\n本来...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>\"首先要感谢福之源创意料理还有大众点评给予的这次机会，知道自己被抽中免费试吃的时候心情还是很...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>\"之前参与了抢购的活动，午餐和晚餐通用，每人只限一张，每张9.9元，吃烤肉自助真是便宜到家了...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>\"腾冲市区交通方便，周日晚饭上座率6成。\\n主打烤鸭和火锅。\\n本次没有点火锅，只吃了烤鸭和...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>\"本来和几个同学一起到光谷想吃东西的，可是到处都排队，然后大众搜了一下，刚好看到这家川菜，然...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>\"菜的口味偏咸，但是味道不错，量大实惠，就是服务员的态度实在不敢恭维，一副强卖的架势，非得让...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>\"去南汇玩的时候下午无聊中就想着出去吃甜品，老公的妹妹推荐的店，说是味道、环境还不错，于是我...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>\"中午过来吃饭，因为和单位很近。之前都是一直只吃碗面就好，今天来吃了次炒菜。酸菜鱼还是有点辣...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>\"这地方高峰时期都得等位，不全是因为好吃，有特色占了很大的比率。店里环境干净整洁，桌子上纸巾...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>\"分量很大。没有吃完打包了！位于大寨沟普通公交车车站附近，价格比较亲民。来过很多次。在两个套...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>\"安排了一天去银座逛街的行程，早上10点多就坐地铁过去了，早饭也没吃，想着到了银座可以早午饭...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>\"只能说这家店懂得网络营销，盲目的看大众点评真的是人云亦云，看点评来的，榆钱48，以为是本地...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>\"#昨晚去平江路压完马路经过哑巴生煎，看到旁边的这家粽子店，早有耳闻，一直想吃吃，店面挺大也...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14970</th>\n",
       "      <td>14970</td>\n",
       "      <td>\"环境：共两层，主要就餐区位于二楼，一楼是厨房。二层包括大厅还有蒙古包式的开放单间，还有小舞...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14971</th>\n",
       "      <td>14971</td>\n",
       "      <td>\"感谢点评抽中的试吃霸王餐\\n首先说哈位置，就在现在已经成熟火爆的九街，苏荷酒吧斜对面，吃货...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14972</th>\n",
       "      <td>14972</td>\n",
       "      <td>\"这家在长辈群体里口碑相当好\\n离家很近，爷爷奶奶有时候懒得做饭了会过来吃\\n性价比也很好，...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14973</th>\n",
       "      <td>14973</td>\n",
       "      <td>\"丁丁麻辣烫位于和义路的边上，招牌很引人关注，白色的底子，红色的丁丁麻辣烫五个大字很引人注目...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14974</th>\n",
       "      <td>14974</td>\n",
       "      <td>\"香格里拉，热情好客，带宾客如家人是香格里拉主打的招牌，但是在我看来唐山这家刚刚开业没有一两...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14975</th>\n",
       "      <td>14975</td>\n",
       "      <td>\"实在是吃不下中山三院饭堂那么难吃的伙食，于是就出去寻觅好吃的早餐，要知道一个好的早餐才能病...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14976</th>\n",
       "      <td>14976</td>\n",
       "      <td>\"简单的重庆小面不简单。\\n首先来说面。筋道，那是必须的，但是不硬，软Q，爽滑。量大，女孩子...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14977</th>\n",
       "      <td>14977</td>\n",
       "      <td>\"【环境】超有日本居酒屋的氛围～店铺不大。一共俩层。一层可以坐十二个人左右～位子有些紧。二层...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14978</th>\n",
       "      <td>14978</td>\n",
       "      <td>\"作为一个一个月内来了三次，一次裸蛋糕两次冰皮月饼的人。。自我感觉还是可以来说点什么的~~D...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14979</th>\n",
       "      <td>14979</td>\n",
       "      <td>\"同事推荐的吃早饭的地方，离婆婆家不远，但平时不会特地过来\\n唐山路公平路路口，车站旁边，不...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14980</th>\n",
       "      <td>14980</td>\n",
       "      <td>\"公司聚餐 听说这个是之前和平广场的那家 于是大家中午没吃饭就等这顿哈哈哈 去了之后果然没失...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14981</th>\n",
       "      <td>14981</td>\n",
       "      <td>\"就在步行街上，非常好找，酒店check in后就出来觅食了，9点多，店铺刚开张的感觉，好多...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14982</th>\n",
       "      <td>14982</td>\n",
       "      <td>\"在附近挑了好几家火锅店最后选中了这家～冲着专门吃牛肉火锅来的～总体感觉一般吧，都是按照招牌...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14983</th>\n",
       "      <td>14983</td>\n",
       "      <td>\"Enjoy上订购的双人套餐。整体来说，店内设计雅致，环境安静、食材新鲜，服务周到。\\n店门...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14984</th>\n",
       "      <td>14984</td>\n",
       "      <td>\"新城市广场，三楼，算是靠近电影院，大概20来米的样子\\n网上的团购，比较划算\\n首先，当时...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14985</th>\n",
       "      <td>14985</td>\n",
       "      <td>\"今天给个四星，比之前多一星，胜在服务上。照常点了招牌的外婆红烧肉，肥而不腻，肉很大一块，很...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14986</th>\n",
       "      <td>14986</td>\n",
       "      <td>\"娜娜家的装修真的是别具风格，就连烟灰缸都那么有特点，里面放的不是土，貌似是咖啡类的东东，味...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14987</th>\n",
       "      <td>14987</td>\n",
       "      <td>\"每次都是吃完才记得拍照也是醉了(/ω＼)\\n\\n这次消费体验一般吧～因为太早去了，5点就到...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14988</th>\n",
       "      <td>14988</td>\n",
       "      <td>\"昨天和小伙伴去吃的夜宵，话说，吃撑了一餐，再去的奇葩真的很少见。\\n对于海底捞，对我来说是...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14989</th>\n",
       "      <td>14989</td>\n",
       "      <td>\"首先很感谢大众点评给的这次试吃机会，在周日的晚上和众多小伙伴们美美地聚餐！\\n捉虾记 or...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14990</th>\n",
       "      <td>14990</td>\n",
       "      <td>\"888附近基本没有韩式冷面的店，好想吃，最近的也就是这家了。周五翘班过来吃。来的比较晚，都...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14991</th>\n",
       "      <td>14991</td>\n",
       "      <td>\"说这里性价比很高的人，一定是没有吃过六六寿司，强烈推荐六六寿司的定食套餐，绝对比这里吃的爽...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14992</th>\n",
       "      <td>14992</td>\n",
       "      <td>\"很幸运的中了霸王餐，上午考完试用脑过度刚好补充体力。位置还是很好找的，现在的烧烤店没点特色...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14993</th>\n",
       "      <td>14993</td>\n",
       "      <td>\"经常来吃的一家披萨店，珠江路和金鹰三期都有，来的金鹰的八楼，来的时候前面还有七桌，可以扫一...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14994</th>\n",
       "      <td>14994</td>\n",
       "      <td>\"真的不得不说，里面几个男服务员服务真的很好，很耐心！收盘子也很积极！说说菜的味道吧，总体来...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>14995</td>\n",
       "      <td>\"杭州大厦周围的日料店有三上、山葵这样的连锁店，听说三上除了C座地下一楼的那家以外还要在D座...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>14996</td>\n",
       "      <td>\"非常物美价廉的一家自助餐厅，虽是中午，之前担心的货少量不足的问题完全没出现，最爱的三文鱼、...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>14997</td>\n",
       "      <td>\"生日的时候不知道去吃什么，偶然在大牌抢购里发现了这家店～感觉团购很给力，就果断团了一份～地...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>14998</td>\n",
       "      <td>\"每次来大理都有不一样的感动，还记得上次来大理遇到一个特别好的出租车司机，这次来大理同样是这...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>14999</td>\n",
       "      <td>\"这家店位于城中湖码头，靠近广场非常近，离我们的住处比较近，开车过来只要几分钟的时间就好了。...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            content  \\\n",
       "0          0  \"我想说他们家的优惠活动好持久啊，我预售的时候买的券，前两天心血来潮去吃的活动还在继续\\n首...   \n",
       "1          1  \"终于开到心心念念的LAB loft。第一次来就随便点也一些～【香辣虾意面】蛮辣的，但其实一...   \n",
       "2          2  \"地理位置好，交通方便，就在124车站对面交通方便，很好，我晚上7点多去买的了，已经没有什么...   \n",
       "3          3  \"运气很好，抽中了大众点评的霸王餐。这家主题餐厅心仪已久了，种种原因一直未能成行，没想到抽中...   \n",
       "4          4  \"幸运随点评团体验霸王餐，心情好~蜀九香刚进驻泉州不久，招牌大名气响，以至于刚到店门口的我被...   \n",
       "5          5  \"尽管韩国烤肉店在无锡已经有很多家了，但因为味道好吃再加上在无锡很有人气，依旧挡不住新店的开...   \n",
       "6          6  \"店铺在乙烯生活二区的西北角，旁边是国旅的旗舰店，门口就是红绿灯，挺好找的。因为这是两磅一的...   \n",
       "7          7  \"朋友聚会来滴，这个地方真心不错哇，又能撸串，又能唱歌，还能看现场歌手演唱。最主要是可以上台...   \n",
       "8          8  \"超喜欢这家的面食，经常来吃。这家风格及产品都很像京城御面，有时会怀疑是不是同一家的。面条比...   \n",
       "9          9  \"广西阳朔，前一天晚上吃的特色啤酒鱼，就看到了隔壁有家螺蛳粉，第二天过来吃。个人比较喜欢粉，...   \n",
       "10        10  \"蛮早之前就在人气美食看过报道这家的夜宵了，一直想来看看，终于这次来了~~\\n大概晚上10点...   \n",
       "11        11  \"中秋花好月圆之夜,一家老小共八人选择此地吃团圆饭。吴中店是新店，环境干净大气\\n整洁，提前...   \n",
       "12        12  \"地址：他家位于万达广场C区，也就是说面向万达广场正面左边方向的后面商铺，要从背面商铺一楼寻...   \n",
       "13        13  \"没错，我就是楼上的室友。已经告别自助三年的我曾经发誓再也不吃自助这种只有量没有质的东西。可...   \n",
       "14        14  \"我亲爱的姐姐人品爆发抽中了豪华双人霸王餐，为了能吃上这一顿我还特意提前了一天从贵阳回到成都...   \n",
       "15        15  \"＃试吃/体验点评＃首先还是照例感谢大众点评和商家抽中我！感谢好运气！这次想着带父皇母后来体...   \n",
       "16        16  \"原价比较贵，大众点评立减17的优惠很给力，可以点豪d，两个人原价213，折后149，吃得很...   \n",
       "17        17  \"原来去过一家浮力森林，就是铂金城的那家。\\n\\n但不知道从好久那家也不复存在。\\n\\n本来...   \n",
       "18        18  \"首先要感谢福之源创意料理还有大众点评给予的这次机会，知道自己被抽中免费试吃的时候心情还是很...   \n",
       "19        19  \"之前参与了抢购的活动，午餐和晚餐通用，每人只限一张，每张9.9元，吃烤肉自助真是便宜到家了...   \n",
       "20        20  \"腾冲市区交通方便，周日晚饭上座率6成。\\n主打烤鸭和火锅。\\n本次没有点火锅，只吃了烤鸭和...   \n",
       "21        21  \"本来和几个同学一起到光谷想吃东西的，可是到处都排队，然后大众搜了一下，刚好看到这家川菜，然...   \n",
       "22        22  \"菜的口味偏咸，但是味道不错，量大实惠，就是服务员的态度实在不敢恭维，一副强卖的架势，非得让...   \n",
       "23        23  \"去南汇玩的时候下午无聊中就想着出去吃甜品，老公的妹妹推荐的店，说是味道、环境还不错，于是我...   \n",
       "24        24  \"中午过来吃饭，因为和单位很近。之前都是一直只吃碗面就好，今天来吃了次炒菜。酸菜鱼还是有点辣...   \n",
       "25        25  \"这地方高峰时期都得等位，不全是因为好吃，有特色占了很大的比率。店里环境干净整洁，桌子上纸巾...   \n",
       "26        26  \"分量很大。没有吃完打包了！位于大寨沟普通公交车车站附近，价格比较亲民。来过很多次。在两个套...   \n",
       "27        27  \"安排了一天去银座逛街的行程，早上10点多就坐地铁过去了，早饭也没吃，想着到了银座可以早午饭...   \n",
       "28        28  \"只能说这家店懂得网络营销，盲目的看大众点评真的是人云亦云，看点评来的，榆钱48，以为是本地...   \n",
       "29        29  \"#昨晚去平江路压完马路经过哑巴生煎，看到旁边的这家粽子店，早有耳闻，一直想吃吃，店面挺大也...   \n",
       "...      ...                                                ...   \n",
       "14970  14970  \"环境：共两层，主要就餐区位于二楼，一楼是厨房。二层包括大厅还有蒙古包式的开放单间，还有小舞...   \n",
       "14971  14971  \"感谢点评抽中的试吃霸王餐\\n首先说哈位置，就在现在已经成熟火爆的九街，苏荷酒吧斜对面，吃货...   \n",
       "14972  14972  \"这家在长辈群体里口碑相当好\\n离家很近，爷爷奶奶有时候懒得做饭了会过来吃\\n性价比也很好，...   \n",
       "14973  14973  \"丁丁麻辣烫位于和义路的边上，招牌很引人关注，白色的底子，红色的丁丁麻辣烫五个大字很引人注目...   \n",
       "14974  14974  \"香格里拉，热情好客，带宾客如家人是香格里拉主打的招牌，但是在我看来唐山这家刚刚开业没有一两...   \n",
       "14975  14975  \"实在是吃不下中山三院饭堂那么难吃的伙食，于是就出去寻觅好吃的早餐，要知道一个好的早餐才能病...   \n",
       "14976  14976  \"简单的重庆小面不简单。\\n首先来说面。筋道，那是必须的，但是不硬，软Q，爽滑。量大，女孩子...   \n",
       "14977  14977  \"【环境】超有日本居酒屋的氛围～店铺不大。一共俩层。一层可以坐十二个人左右～位子有些紧。二层...   \n",
       "14978  14978  \"作为一个一个月内来了三次，一次裸蛋糕两次冰皮月饼的人。。自我感觉还是可以来说点什么的~~D...   \n",
       "14979  14979  \"同事推荐的吃早饭的地方，离婆婆家不远，但平时不会特地过来\\n唐山路公平路路口，车站旁边，不...   \n",
       "14980  14980  \"公司聚餐 听说这个是之前和平广场的那家 于是大家中午没吃饭就等这顿哈哈哈 去了之后果然没失...   \n",
       "14981  14981  \"就在步行街上，非常好找，酒店check in后就出来觅食了，9点多，店铺刚开张的感觉，好多...   \n",
       "14982  14982  \"在附近挑了好几家火锅店最后选中了这家～冲着专门吃牛肉火锅来的～总体感觉一般吧，都是按照招牌...   \n",
       "14983  14983  \"Enjoy上订购的双人套餐。整体来说，店内设计雅致，环境安静、食材新鲜，服务周到。\\n店门...   \n",
       "14984  14984  \"新城市广场，三楼，算是靠近电影院，大概20来米的样子\\n网上的团购，比较划算\\n首先，当时...   \n",
       "14985  14985  \"今天给个四星，比之前多一星，胜在服务上。照常点了招牌的外婆红烧肉，肥而不腻，肉很大一块，很...   \n",
       "14986  14986  \"娜娜家的装修真的是别具风格，就连烟灰缸都那么有特点，里面放的不是土，貌似是咖啡类的东东，味...   \n",
       "14987  14987  \"每次都是吃完才记得拍照也是醉了(/ω＼)\\n\\n这次消费体验一般吧～因为太早去了，5点就到...   \n",
       "14988  14988  \"昨天和小伙伴去吃的夜宵，话说，吃撑了一餐，再去的奇葩真的很少见。\\n对于海底捞，对我来说是...   \n",
       "14989  14989  \"首先很感谢大众点评给的这次试吃机会，在周日的晚上和众多小伙伴们美美地聚餐！\\n捉虾记 or...   \n",
       "14990  14990  \"888附近基本没有韩式冷面的店，好想吃，最近的也就是这家了。周五翘班过来吃。来的比较晚，都...   \n",
       "14991  14991  \"说这里性价比很高的人，一定是没有吃过六六寿司，强烈推荐六六寿司的定食套餐，绝对比这里吃的爽...   \n",
       "14992  14992  \"很幸运的中了霸王餐，上午考完试用脑过度刚好补充体力。位置还是很好找的，现在的烧烤店没点特色...   \n",
       "14993  14993  \"经常来吃的一家披萨店，珠江路和金鹰三期都有，来的金鹰的八楼，来的时候前面还有七桌，可以扫一...   \n",
       "14994  14994  \"真的不得不说，里面几个男服务员服务真的很好，很耐心！收盘子也很积极！说说菜的味道吧，总体来...   \n",
       "14995  14995  \"杭州大厦周围的日料店有三上、山葵这样的连锁店，听说三上除了C座地下一楼的那家以外还要在D座...   \n",
       "14996  14996  \"非常物美价廉的一家自助餐厅，虽是中午，之前担心的货少量不足的问题完全没出现，最爱的三文鱼、...   \n",
       "14997  14997  \"生日的时候不知道去吃什么，偶然在大牌抢购里发现了这家店～感觉团购很给力，就果断团了一份～地...   \n",
       "14998  14998  \"每次来大理都有不一样的感动，还记得上次来大理遇到一个特别好的出租车司机，这次来大理同样是这...   \n",
       "14999  14999  \"这家店位于城中湖码头，靠近广场非常近，离我们的住处比较近，开车过来只要几分钟的时间就好了。...   \n",
       "\n",
       "       location_traffic_convenience  location_distance_from_business_district  \\\n",
       "0                                 1                                        -2   \n",
       "1                                 1                                        -2   \n",
       "2                                 1                                         1   \n",
       "3                                 1                                         1   \n",
       "4                                 1                                        -2   \n",
       "5                                -2                                        -2   \n",
       "6                                 1                                        -2   \n",
       "7                                 1                                        -2   \n",
       "8                                -2                                        -2   \n",
       "9                                -2                                        -2   \n",
       "10                               -2                                        -2   \n",
       "11                                1                                        -2   \n",
       "12                               -2                                        -2   \n",
       "13                               -2                                        -2   \n",
       "14                               -2                                        -2   \n",
       "15                               -2                                        -2   \n",
       "16                               -2                                        -2   \n",
       "17                               -2                                        -2   \n",
       "18                                1                                        -2   \n",
       "19                               -2                                        -2   \n",
       "20                               -2                                        -2   \n",
       "21                               -2                                        -2   \n",
       "22                               -2                                        -2   \n",
       "23                               -2                                        -2   \n",
       "24                               -2                                        -2   \n",
       "25                               -2                                        -2   \n",
       "26                               -2                                        -2   \n",
       "27                               -2                                        -2   \n",
       "28                               -2                                        -2   \n",
       "29                               -2                                        -2   \n",
       "...                             ...                                       ...   \n",
       "14970                            -2                                        -2   \n",
       "14971                            -2                                        -2   \n",
       "14972                             1                                        -2   \n",
       "14973                             1                                        -2   \n",
       "14974                            -2                                        -2   \n",
       "14975                            -2                                        -2   \n",
       "14976                            -2                                        -2   \n",
       "14977                             1                                        -2   \n",
       "14978                            -2                                        -2   \n",
       "14979                             1                                        -2   \n",
       "14980                             1                                        -2   \n",
       "14981                            -2                                        -2   \n",
       "14982                             1                                        -2   \n",
       "14983                             1                                        -2   \n",
       "14984                            -2                                        -2   \n",
       "14985                            -2                                        -2   \n",
       "14986                            -2                                        -2   \n",
       "14987                            -2                                        -2   \n",
       "14988                            -2                                        -2   \n",
       "14989                            -2                                        -2   \n",
       "14990                            -2                                        -2   \n",
       "14991                            -2                                        -2   \n",
       "14992                             1                                        -2   \n",
       "14993                            -2                                        -2   \n",
       "14994                            -2                                        -2   \n",
       "14995                            -2                                        -2   \n",
       "14996                            -2                                        -2   \n",
       "14997                            -2                                        -2   \n",
       "14998                             1                                        -2   \n",
       "14999                             1                                        -2   \n",
       "\n",
       "       location_easy_to_find  service_wait_time  service_waiters_attitude  \\\n",
       "0                         -2                 -2                         1   \n",
       "1                         -2                 -2                         1   \n",
       "2                          1                 -2                         1   \n",
       "3                          1                 -2                         1   \n",
       "4                         -2                 -2                         1   \n",
       "5                         -2                 -2                         1   \n",
       "6                          1                 -2                         1   \n",
       "7                         -2                 -2                         1   \n",
       "8                         -2                 -2                        -2   \n",
       "9                         -2                 -2                         1   \n",
       "10                        -2                 -2                         1   \n",
       "11                        -2                 -2                         1   \n",
       "12                        -2                 -2                         1   \n",
       "13                        -2                 -2                         1   \n",
       "14                        -2                 -2                         1   \n",
       "15                        -2                 -2                         1   \n",
       "16                        -2                 -2                         1   \n",
       "17                        -2                 -2                         1   \n",
       "18                         1                 -2                         1   \n",
       "19                        -2                 -2                         1   \n",
       "20                        -2                 -2                         1   \n",
       "21                        -2                 -2                         1   \n",
       "22                        -2                 -2                         1   \n",
       "23                        -2                 -2                         1   \n",
       "24                        -2                 -2                         1   \n",
       "25                        -2                 -2                         1   \n",
       "26                        -2                 -2                        -2   \n",
       "27                        -2                 -2                         1   \n",
       "28                        -2                 -2                         1   \n",
       "29                        -2                 -2                         1   \n",
       "...                      ...                ...                       ...   \n",
       "14970                     -2                 -2                        -2   \n",
       "14971                     -2                 -2                         1   \n",
       "14972                     -2                 -2                         1   \n",
       "14973                     -2                 -2                         1   \n",
       "14974                     -2                 -2                         1   \n",
       "14975                     -2                 -2                         1   \n",
       "14976                     -2                 -2                         1   \n",
       "14977                     -2                 -2                         1   \n",
       "14978                     -2                 -2                         1   \n",
       "14979                     -2                 -2                         1   \n",
       "14980                     -2                 -2                         1   \n",
       "14981                     -2                 -2                         1   \n",
       "14982                     -2                 -2                         1   \n",
       "14983                     -2                 -2                         1   \n",
       "14984                     -2                 -2                         1   \n",
       "14985                     -2                 -2                         1   \n",
       "14986                     -2                 -2                         1   \n",
       "14987                     -2                 -2                         1   \n",
       "14988                     -2                 -2                         1   \n",
       "14989                     -2                 -2                         1   \n",
       "14990                     -2                 -2                         1   \n",
       "14991                     -2                 -2                         1   \n",
       "14992                      1                 -2                         1   \n",
       "14993                     -2                 -2                         1   \n",
       "14994                     -2                 -2                        -1   \n",
       "14995                     -2                 -2                         1   \n",
       "14996                     -2                 -2                         1   \n",
       "14997                     -2                 -2                         1   \n",
       "14998                      1                 -2                         1   \n",
       "14999                     -2                 -2                         1   \n",
       "\n",
       "       service_parking_convenience  service_serving_speed  price_level  \\\n",
       "0                               -2                     -2            1   \n",
       "1                               -2                     -2            1   \n",
       "2                               -2                     -2           -2   \n",
       "3                               -2                     -2           -2   \n",
       "4                               -2                     -2           -2   \n",
       "5                               -2                     -2           -2   \n",
       "6                               -2                     -2            1   \n",
       "7                               -2                     -2           -2   \n",
       "8                               -2                     -2            1   \n",
       "9                               -2                     -2           -2   \n",
       "10                              -2                     -2           -2   \n",
       "11                              -2                     -2           -2   \n",
       "12                              -2                     -2           -2   \n",
       "13                              -2                     -2           -2   \n",
       "14                              -2                     -2           -2   \n",
       "15                              -2                     -2           -2   \n",
       "16                              -2                     -2           -2   \n",
       "17                              -2                     -2           -2   \n",
       "18                              -2                     -2           -2   \n",
       "19                              -2                     -2           -2   \n",
       "20                              -2                     -2           -2   \n",
       "21                              -2                     -2           -2   \n",
       "22                              -2                     -2           -2   \n",
       "23                              -2                     -2           -2   \n",
       "24                              -2                     -2           -2   \n",
       "25                              -2                     -2           -2   \n",
       "26                              -2                     -2           -2   \n",
       "27                              -2                     -2           -2   \n",
       "28                              -2                     -2           -2   \n",
       "29                              -2                     -2           -2   \n",
       "...                            ...                    ...          ...   \n",
       "14970                           -2                     -2           -2   \n",
       "14971                           -2                     -2           -2   \n",
       "14972                           -2                     -2            1   \n",
       "14973                           -2                     -2           -2   \n",
       "14974                           -2                     -2           -2   \n",
       "14975                           -2                     -2           -2   \n",
       "14976                           -2                     -2           -2   \n",
       "14977                           -2                     -2           -2   \n",
       "14978                           -2                     -2           -2   \n",
       "14979                           -2                     -2           -2   \n",
       "14980                           -2                     -2           -2   \n",
       "14981                           -2                     -2           -2   \n",
       "14982                           -2                     -2           -2   \n",
       "14983                           -2                     -2           -2   \n",
       "14984                           -2                     -2           -2   \n",
       "14985                           -2                     -2           -1   \n",
       "14986                           -2                     -2           -2   \n",
       "14987                           -2                     -2           -2   \n",
       "14988                           -2                     -2           -2   \n",
       "14989                           -2                     -2           -2   \n",
       "14990                           -2                     -2            0   \n",
       "14991                           -2                     -2           -2   \n",
       "14992                           -2                     -2           -2   \n",
       "14993                           -2                     -2           -2   \n",
       "14994                           -2                     -2           -2   \n",
       "14995                           -2                     -2           -2   \n",
       "14996                           -2                     -2           -2   \n",
       "14997                           -2                     -2           -2   \n",
       "14998                           -2                     -2           -2   \n",
       "14999                           -2                     -2           -2   \n",
       "\n",
       "                    ...                 environment_decoration  \\\n",
       "0                   ...                                      1   \n",
       "1                   ...                                      1   \n",
       "2                   ...                                     -2   \n",
       "3                   ...                                      1   \n",
       "4                   ...                                      1   \n",
       "5                   ...                                      1   \n",
       "6                   ...                                     -2   \n",
       "7                   ...                                      1   \n",
       "8                   ...                                      1   \n",
       "9                   ...                                      1   \n",
       "10                  ...                                      1   \n",
       "11                  ...                                      1   \n",
       "12                  ...                                      1   \n",
       "13                  ...                                     -2   \n",
       "14                  ...                                      1   \n",
       "15                  ...                                      1   \n",
       "16                  ...                                      1   \n",
       "17                  ...                                      1   \n",
       "18                  ...                                      1   \n",
       "19                  ...                                     -2   \n",
       "20                  ...                                      1   \n",
       "21                  ...                                      1   \n",
       "22                  ...                                     -2   \n",
       "23                  ...                                      1   \n",
       "24                  ...                                     -2   \n",
       "25                  ...                                      1   \n",
       "26                  ...                                      1   \n",
       "27                  ...                                      1   \n",
       "28                  ...                                     -2   \n",
       "29                  ...                                      1   \n",
       "...                 ...                                    ...   \n",
       "14970               ...                                      1   \n",
       "14971               ...                                      1   \n",
       "14972               ...                                      1   \n",
       "14973               ...                                      1   \n",
       "14974               ...                                      1   \n",
       "14975               ...                                      1   \n",
       "14976               ...                                      1   \n",
       "14977               ...                                      1   \n",
       "14978               ...                                      1   \n",
       "14979               ...                                      1   \n",
       "14980               ...                                      1   \n",
       "14981               ...                                      1   \n",
       "14982               ...                                      1   \n",
       "14983               ...                                      1   \n",
       "14984               ...                                      1   \n",
       "14985               ...                                      1   \n",
       "14986               ...                                      1   \n",
       "14987               ...                                      1   \n",
       "14988               ...                                      1   \n",
       "14989               ...                                      1   \n",
       "14990               ...                                      1   \n",
       "14991               ...                                      1   \n",
       "14992               ...                                      1   \n",
       "14993               ...                                      1   \n",
       "14994               ...                                     -2   \n",
       "14995               ...                                      1   \n",
       "14996               ...                                      1   \n",
       "14997               ...                                      1   \n",
       "14998               ...                                      1   \n",
       "14999               ...                                      1   \n",
       "\n",
       "       environment_noise  environment_space  environment_cleaness  \\\n",
       "0                     -2                 -2                     1   \n",
       "1                     -2                 -2                    -2   \n",
       "2                     -2                 -2                    -2   \n",
       "3                      1                  1                     1   \n",
       "4                      1                  1                     1   \n",
       "5                     -2                 -2                    -2   \n",
       "6                     -2                 -2                     1   \n",
       "7                      1                  1                     1   \n",
       "8                     -2                 -2                    -2   \n",
       "9                     -2                 -2                     1   \n",
       "10                    -2                 -2                    -2   \n",
       "11                     1                  1                     1   \n",
       "12                    -2                  1                    -2   \n",
       "13                    -2                 -2                    -2   \n",
       "14                    -2                 -2                    -2   \n",
       "15                     1                  1                     1   \n",
       "16                     1                 -2                     1   \n",
       "17                    -2                 -2                    -2   \n",
       "18                    -2                 -2                    -2   \n",
       "19                    -2                 -2                    -2   \n",
       "20                    -2                 -2                    -2   \n",
       "21                    -2                  1                    -2   \n",
       "22                    -2                 -2                    -2   \n",
       "23                     1                  1                     1   \n",
       "24                    -2                 -2                    -2   \n",
       "25                     1                  1                     1   \n",
       "26                    -2                 -2                     1   \n",
       "27                    -2                 -2                    -2   \n",
       "28                    -2                 -2                    -2   \n",
       "29                    -2                 -2                    -2   \n",
       "...                  ...                ...                   ...   \n",
       "14970                 -2                 -2                    -2   \n",
       "14971                 -2                 -2                    -2   \n",
       "14972                  1                  1                     1   \n",
       "14973                 -2                 -2                    -2   \n",
       "14974                 -2                 -2                    -2   \n",
       "14975                 -2                 -2                    -2   \n",
       "14976                  1                  1                     1   \n",
       "14977                 -2                 -2                     1   \n",
       "14978                 -2                 -2                    -2   \n",
       "14979                 -2                 -2                    -2   \n",
       "14980                  1                  1                     1   \n",
       "14981                 -2                 -2                    -2   \n",
       "14982                 -2                 -2                    -2   \n",
       "14983                 -2                 -2                    -2   \n",
       "14984                 -2                 -2                     1   \n",
       "14985                  1                  1                     1   \n",
       "14986                 -2                  1                    -2   \n",
       "14987                 -2                 -2                    -2   \n",
       "14988                  1                  1                     1   \n",
       "14989                 -2                 -2                    -2   \n",
       "14990                 -2                 -2                    -2   \n",
       "14991                  1                  1                     1   \n",
       "14992                  1                  1                     1   \n",
       "14993                 -2                 -2                    -2   \n",
       "14994                 -2                 -2                    -2   \n",
       "14995                 -2                  1                     1   \n",
       "14996                 -2                 -2                     1   \n",
       "14997                 -2                 -2                     1   \n",
       "14998                 -2                 -2                    -2   \n",
       "14999                 -2                 -2                    -2   \n",
       "\n",
       "       dish_portion  dish_taste  dish_look  dish_recommendation  \\\n",
       "0                -2           1         -2                   -2   \n",
       "1                -2           1         -2                   -2   \n",
       "2                -2           1         -2                   -2   \n",
       "3                -2           1         -2                   -2   \n",
       "4                -2           1          1                   -2   \n",
       "5                -2           1         -2                   -2   \n",
       "6                 1           1         -2                   -2   \n",
       "7                -2           1          1                   -2   \n",
       "8                 1           1         -2                   -2   \n",
       "9                 1           1         -2                   -2   \n",
       "10               -2           1         -2                   -2   \n",
       "11               -2           1          1                   -2   \n",
       "12               -2           1         -2                   -2   \n",
       "13               -2           1         -2                   -2   \n",
       "14               -2           1         -2                   -2   \n",
       "15               -2           1          1                   -2   \n",
       "16               -2           1          1                   -2   \n",
       "17               -2           1         -2                   -2   \n",
       "18               -2           1         -2                   -2   \n",
       "19               -2           1         -2                   -2   \n",
       "20               -2           1         -2                   -2   \n",
       "21               -2           1         -2                   -2   \n",
       "22               -2           1         -2                   -2   \n",
       "23               -2           1         -2                   -2   \n",
       "24                1           1         -2                   -2   \n",
       "25               -2           1         -2                   -2   \n",
       "26               -2           1         -2                   -2   \n",
       "27               -2           1         -2                   -2   \n",
       "28               -2           1         -2                   -2   \n",
       "29               -2           1         -2                   -2   \n",
       "...             ...         ...        ...                  ...   \n",
       "14970            -2           1         -2                   -2   \n",
       "14971            -2           1         -2                   -2   \n",
       "14972            -2           1         -2                   -2   \n",
       "14973            -2           1         -2                   -2   \n",
       "14974            -2           0         -2                   -2   \n",
       "14975            -2           0         -2                   -2   \n",
       "14976            -2           1         -2                   -2   \n",
       "14977            -2           1         -2                   -2   \n",
       "14978            -2           1         -2                   -2   \n",
       "14979            -2           1         -2                   -2   \n",
       "14980            -2           1         -2                   -2   \n",
       "14981            -2           1         -2                   -2   \n",
       "14982            -2           1         -2                   -2   \n",
       "14983            -2           1         -2                   -2   \n",
       "14984            -2           1         -2                   -2   \n",
       "14985            -2           0         -2                   -2   \n",
       "14986            -2           1         -2                   -2   \n",
       "14987            -2           1         -2                   -2   \n",
       "14988            -2           1         -2                   -2   \n",
       "14989            -2           0         -2                   -2   \n",
       "14990            -2           0         -2                   -2   \n",
       "14991            -2           0         -2                   -2   \n",
       "14992            -2           1         -2                   -2   \n",
       "14993             1           1         -2                   -2   \n",
       "14994            -2           0         -2                   -2   \n",
       "14995             1           1         -2                   -2   \n",
       "14996            -2           1         -2                   -2   \n",
       "14997            -2           1         -2                   -2   \n",
       "14998            -2           1         -2                   -2   \n",
       "14999            -2           1         -2                   -2   \n",
       "\n",
       "       others_overall_experience  others_willing_to_consume_again  \n",
       "0                              1                                1  \n",
       "1                              1                                1  \n",
       "2                              1                                1  \n",
       "3                              1                                1  \n",
       "4                              1                                1  \n",
       "5                              1                                1  \n",
       "6                              1                                1  \n",
       "7                              1                                1  \n",
       "8                              1                                1  \n",
       "9                              1                                1  \n",
       "10                             1                                1  \n",
       "11                             1                               -2  \n",
       "12                             1                                1  \n",
       "13                             1                                1  \n",
       "14                             1                                1  \n",
       "15                             1                                1  \n",
       "16                             1                                1  \n",
       "17                             1                               -2  \n",
       "18                             1                                1  \n",
       "19                             1                                1  \n",
       "20                             1                               -1  \n",
       "21                             1                                1  \n",
       "22                             1                                1  \n",
       "23                             1                               -2  \n",
       "24                             1                                1  \n",
       "25                             1                                1  \n",
       "26                             1                                1  \n",
       "27                             1                               -2  \n",
       "28                             1                                1  \n",
       "29                             1                                1  \n",
       "...                          ...                              ...  \n",
       "14970                          1                                1  \n",
       "14971                          1                                1  \n",
       "14972                          1                                1  \n",
       "14973                          1                                1  \n",
       "14974                          1                                1  \n",
       "14975                          1                                1  \n",
       "14976                          1                                1  \n",
       "14977                          1                                1  \n",
       "14978                          1                               -2  \n",
       "14979                          1                                1  \n",
       "14980                          1                                1  \n",
       "14981                          1                                1  \n",
       "14982                          1                               -2  \n",
       "14983                          1                                1  \n",
       "14984                          1                                1  \n",
       "14985                          0                               -2  \n",
       "14986                          1                               -2  \n",
       "14987                          1                               -2  \n",
       "14988                          1                               -2  \n",
       "14989                          1                               -2  \n",
       "14990                          1                                1  \n",
       "14991                          1                                1  \n",
       "14992                          1                                1  \n",
       "14993                          1                               -2  \n",
       "14994                          0                               -2  \n",
       "14995                          1                                1  \n",
       "14996                          1                                1  \n",
       "14997                          1                                1  \n",
       "14998                          1                                1  \n",
       "14999                          1                                1  \n",
       "\n",
       "[15000 rows x 22 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
