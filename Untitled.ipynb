{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/donald/anaconda3/envs/tf36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "  0%|          | 0/105000 [00:00<?, ?it/s]Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/5g/5gws2dzj4k17s4jllptk0bx80000gn/T/jieba.cache\n",
      "Loading model cost 0.870 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "100%|██████████| 105000/105000 [03:44<00:00, 468.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "序列化完成，正在保存词典\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [00:31<00:00, 478.12it/s]\n",
      "100%|██████████| 15000/15000 [00:30<00:00, 489.43it/s]\n",
      "/Users/donald/PycharmProjects/Challenger-text-classification/Preprocessing.py:39: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  label = label_ori.as_matrix()\n"
     ]
    }
   ],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "from model import TextClassifier\n",
    "import config\n",
    "import Preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tp = Preprocessing.Preprocessor()\n",
    "\t\n",
    "\t#读取训练集，验证集和测试集s\n",
    "\tTrain_raw_data = pd.read_csv(config.train_data_path)\n",
    "\tValidation_raw_data = pd.read_csv(config.validate_data_path)\n",
    "\tTest_raw_data = pd.read_csv(config.test_data_path)\n",
    "\n",
    "\t# #读取所有列标签的名称\n",
    "\tlabel_names = Train_raw_data.keys().tolist()\n",
    "\tlabel_names.remove('id')\n",
    "\tlabel_names.remove('content')\n",
    "\n",
    "\t#预处理训练文本\n",
    "\ttmp = p.preprocess_content(Train_raw_data['content'])\n",
    "\tTrain_sequence = p.preprocess_text(tmp, train_flag= True)\n",
    "\n",
    "\t#预处理验证集文本\n",
    "\ttmp = p.preprocess_content(Validation_raw_data['content'])\n",
    "\tValidation_sequence = p.preprocess_text(tmp, train_flag= False)\n",
    "\n",
    "\t#预处理测试集文本\n",
    "\ttmp = p.preprocess_content(Test_raw_data['content'])\n",
    "\tTest_sequence = p.preprocess_text(tmp, train_flag = False)\n",
    "    \n",
    "\t#处理标签\n",
    "\tTrain_label = []\n",
    "\tValidation_label = []\n",
    "\tTest_label = []\n",
    "\n",
    "\tfor name in label_names:\n",
    "\t\tTrain_label.append(p.preprocess_labels(Train_raw_data[name]))\n",
    "\t\tValidation_label.append(p.preprocess_labels(Validation_raw_data[name]))\n",
    "\n",
    "\tnp.save(config.train_sequence_path, Train_sequence)\n",
    "\tnp.save(config.validation_sequence_path, Validation_sequence)\n",
    "\tnp.save(config.test_sequence_path, Test_sequence)\n",
    "\tnp.save(config.train_label_path, Train_label)\n",
    "\tnp.save(config.validation_label_path, Validation_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 400)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 400, 300)     66876600    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 400, 300, 1)  0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 398, 250, 64) 9856        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 396, 200, 32) 313376      conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 99, 50, 32)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 24, 12, 32)   0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 9216)         0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_60 (Dense)                (None, 32)           294944      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_61 (Dense)                (None, 32)           294944      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_62 (Dense)                (None, 32)           294944      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_63 (Dense)                (None, 32)           294944      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_64 (Dense)                (None, 32)           294944      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_65 (Dense)                (None, 32)           294944      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_66 (Dense)                (None, 32)           294944      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_67 (Dense)                (None, 32)           294944      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_68 (Dense)                (None, 32)           294944      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_69 (Dense)                (None, 32)           294944      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_70 (Dense)                (None, 32)           294944      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_71 (Dense)                (None, 32)           294944      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_72 (Dense)                (None, 32)           294944      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_73 (Dense)                (None, 32)           294944      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_74 (Dense)                (None, 32)           294944      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_75 (Dense)                (None, 32)           294944      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_76 (Dense)                (None, 32)           294944      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_77 (Dense)                (None, 32)           294944      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_78 (Dense)                (None, 32)           294944      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_79 (Dense)                (None, 32)           294944      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_80 (Dense)                (None, 16)           528         dense_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_81 (Dense)                (None, 16)           528         dense_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_82 (Dense)                (None, 16)           528         dense_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_83 (Dense)                (None, 16)           528         dense_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_84 (Dense)                (None, 16)           528         dense_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_85 (Dense)                (None, 16)           528         dense_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_86 (Dense)                (None, 16)           528         dense_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_87 (Dense)                (None, 16)           528         dense_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_88 (Dense)                (None, 16)           528         dense_68[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_89 (Dense)                (None, 16)           528         dense_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_90 (Dense)                (None, 16)           528         dense_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_91 (Dense)                (None, 16)           528         dense_71[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_92 (Dense)                (None, 16)           528         dense_72[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_93 (Dense)                (None, 16)           528         dense_73[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_94 (Dense)                (None, 16)           528         dense_74[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_95 (Dense)                (None, 16)           528         dense_75[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_96 (Dense)                (None, 16)           528         dense_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_97 (Dense)                (None, 16)           528         dense_77[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_98 (Dense)                (None, 16)           528         dense_78[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_99 (Dense)                (None, 16)           528         dense_79[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 16)           0           dense_80[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 16)           0           dense_81[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 16)           0           dense_82[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 16)           0           dense_83[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 16)           0           dense_84[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 16)           0           dense_85[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 16)           0           dense_86[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 16)           0           dense_87[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 16)           0           dense_88[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 16)           0           dense_89[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 16)           0           dense_90[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 16)           0           dense_91[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 16)           0           dense_92[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 16)           0           dense_93[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 16)           0           dense_94[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 16)           0           dense_95[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 16)           0           dense_96[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 16)           0           dense_97[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 16)           0           dense_98[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 16)           0           dense_99[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_100 (Dense)               (None, 4)            68          dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_101 (Dense)               (None, 4)            68          dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_102 (Dense)               (None, 4)            68          dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_103 (Dense)               (None, 4)            68          dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_104 (Dense)               (None, 4)            68          dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_105 (Dense)               (None, 4)            68          dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_106 (Dense)               (None, 4)            68          dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_107 (Dense)               (None, 4)            68          dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_108 (Dense)               (None, 4)            68          dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_109 (Dense)               (None, 4)            68          dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_110 (Dense)               (None, 4)            68          dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_111 (Dense)               (None, 4)            68          dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_112 (Dense)               (None, 4)            68          dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_113 (Dense)               (None, 4)            68          dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_114 (Dense)               (None, 4)            68          dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_115 (Dense)               (None, 4)            68          dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_116 (Dense)               (None, 4)            68          dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_117 (Dense)               (None, 4)            68          dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_118 (Dense)               (None, 4)            68          dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_119 (Dense)               (None, 4)            68          dropout_39[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 73,110,632\n",
      "Trainable params: 6,234,032\n",
      "Non-trainable params: 66,876,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/1\n",
      "105000/105000 [==============================] - 3111s 30ms/step - loss: 7.6942 - dense_100_loss: 0.3331 - dense_101_loss: 0.2908 - dense_102_loss: 0.3403 - dense_103_loss: 0.2542 - dense_104_loss: 0.5053 - dense_105_loss: 0.1864 - dense_106_loss: 0.2832 - dense_107_loss: 0.5150 - dense_108_loss: 0.3543 - dense_109_loss: 0.4447 - dense_110_loss: 0.4589 - dense_111_loss: 0.3923 - dense_112_loss: 0.4497 - dense_113_loss: 0.4204 - dense_114_loss: 0.4910 - dense_115_loss: 0.4517 - dense_116_loss: 0.3780 - dense_117_loss: 0.3153 - dense_118_loss: 0.4116 - dense_119_loss: 0.4180 - dense_100_categorical_accuracy: 0.7595 - dense_101_categorical_accuracy: 0.7886 - dense_102_categorical_accuracy: 0.7646 - dense_103_categorical_accuracy: 0.8802 - dense_104_categorical_accuracy: 0.4216 - dense_105_categorical_accuracy: 0.9212 - dense_106_categorical_accuracy: 0.8436 - dense_107_categorical_accuracy: 0.4852 - dense_108_categorical_accuracy: 0.7566 - dense_109_categorical_accuracy: 0.6041 - dense_110_categorical_accuracy: 0.5096 - dense_111_categorical_accuracy: 0.6921 - dense_112_categorical_accuracy: 0.6166 - dense_113_categorical_accuracy: 0.6293 - dense_114_categorical_accuracy: 0.5252 - dense_115_categorical_accuracy: 0.5166 - dense_116_categorical_accuracy: 0.7112 - dense_117_categorical_accuracy: 0.8025 - dense_118_categorical_accuracy: 0.6508 - dense_119_categorical_accuracy: 0.6085 - val_loss: 7.1445 - val_dense_100_loss: 0.2847 - val_dense_101_loss: 0.2620 - val_dense_102_loss: 0.3143 - val_dense_103_loss: 0.2165 - val_dense_104_loss: 0.4927 - val_dense_105_loss: 0.1347 - val_dense_106_loss: 0.2552 - val_dense_107_loss: 0.5043 - val_dense_108_loss: 0.3195 - val_dense_109_loss: 0.4238 - val_dense_110_loss: 0.4326 - val_dense_111_loss: 0.3678 - val_dense_112_loss: 0.4263 - val_dense_113_loss: 0.3975 - val_dense_114_loss: 0.4772 - val_dense_115_loss: 0.4296 - val_dense_116_loss: 0.3521 - val_dense_117_loss: 0.2778 - val_dense_118_loss: 0.3842 - val_dense_119_loss: 0.3918 - val_dense_100_categorical_accuracy: 0.7838 - val_dense_101_categorical_accuracy: 0.8021 - val_dense_102_categorical_accuracy: 0.7677 - val_dense_103_categorical_accuracy: 0.8825 - val_dense_104_categorical_accuracy: 0.4481 - val_dense_105_categorical_accuracy: 0.9364 - val_dense_106_categorical_accuracy: 0.8451 - val_dense_107_categorical_accuracy: 0.4998 - val_dense_108_categorical_accuracy: 0.7619 - val_dense_109_categorical_accuracy: 0.6175 - val_dense_110_categorical_accuracy: 0.5410 - val_dense_111_categorical_accuracy: 0.7014 - val_dense_112_categorical_accuracy: 0.6327 - val_dense_113_categorical_accuracy: 0.6397 - val_dense_114_categorical_accuracy: 0.5427 - val_dense_115_categorical_accuracy: 0.5229 - val_dense_116_categorical_accuracy: 0.7172 - val_dense_117_categorical_accuracy: 0.8055 - val_dense_118_categorical_accuracy: 0.6717 - val_dense_119_categorical_accuracy: 0.6236\n",
      "### F1 score:[0.7838, 0.8021333333333334, 0.7677333333333335, 0.8824666666666666, 0.44806666666666667, 0.9364, 0.8451333333333333, 0.4998, 0.7618666666666667, 0.6174666666666667, 0.541, 0.7014, 0.6327333333333334, 0.6397333333333334, 0.5426666666666666, 0.5229333333333334, 0.7172, 0.8055333333333333, 0.6716666666666666, 0.6236] ###\n",
      "### Avg F1:0.6871666666666666 ###\n",
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/1\n",
      "105000/105000 [==============================] - 3125s 30ms/step - loss: 7.3366 - dense_100_loss: 0.3017 - dense_101_loss: 0.2762 - dense_102_loss: 0.3238 - dense_103_loss: 0.2291 - dense_104_loss: 0.4922 - dense_105_loss: 0.1585 - dense_106_loss: 0.2691 - dense_107_loss: 0.5061 - dense_108_loss: 0.3309 - dense_109_loss: 0.4338 - dense_110_loss: 0.4419 - dense_111_loss: 0.3758 - dense_112_loss: 0.4355 - dense_113_loss: 0.4095 - dense_114_loss: 0.4755 - dense_115_loss: 0.4344 - dense_116_loss: 0.3553 - dense_117_loss: 0.2934 - dense_118_loss: 0.3887 - dense_119_loss: 0.4052 - dense_100_categorical_accuracy: 0.7751 - dense_101_categorical_accuracy: 0.7970 - dense_102_categorical_accuracy: 0.7677 - dense_103_categorical_accuracy: 0.8835 - dense_104_categorical_accuracy: 0.4509 - dense_105_categorical_accuracy: 0.9360 - dense_106_categorical_accuracy: 0.8448 - dense_107_categorical_accuracy: 0.5028 - dense_108_categorical_accuracy: 0.7642 - dense_109_categorical_accuracy: 0.6118 - dense_110_categorical_accuracy: 0.5412 - dense_111_categorical_accuracy: 0.6995 - dense_112_categorical_accuracy: 0.6228 - dense_113_categorical_accuracy: 0.6343 - dense_114_categorical_accuracy: 0.5424 - dense_115_categorical_accuracy: 0.5269 - dense_116_categorical_accuracy: 0.7239 - dense_117_categorical_accuracy: 0.8073 - dense_118_categorical_accuracy: 0.6673 - dense_119_categorical_accuracy: 0.6248 - val_loss: 7.0180 - val_dense_100_loss: 0.2786 - val_dense_101_loss: 0.2600 - val_dense_102_loss: 0.3077 - val_dense_103_loss: 0.2141 - val_dense_104_loss: 0.4811 - val_dense_105_loss: 0.1328 - val_dense_106_loss: 0.2527 - val_dense_107_loss: 0.5017 - val_dense_108_loss: 0.3184 - val_dense_109_loss: 0.4230 - val_dense_110_loss: 0.4163 - val_dense_111_loss: 0.3599 - val_dense_112_loss: 0.4185 - val_dense_113_loss: 0.3945 - val_dense_114_loss: 0.4677 - val_dense_115_loss: 0.4166 - val_dense_116_loss: 0.3480 - val_dense_117_loss: 0.2739 - val_dense_118_loss: 0.3635 - val_dense_119_loss: 0.3890 - val_dense_100_categorical_accuracy: 0.7838 - val_dense_101_categorical_accuracy: 0.8021 - val_dense_102_categorical_accuracy: 0.7677 - val_dense_103_categorical_accuracy: 0.8825 - val_dense_104_categorical_accuracy: 0.4386 - val_dense_105_categorical_accuracy: 0.9364 - val_dense_106_categorical_accuracy: 0.8451 - val_dense_107_categorical_accuracy: 0.4998 - val_dense_108_categorical_accuracy: 0.7619 - val_dense_109_categorical_accuracy: 0.6175 - val_dense_110_categorical_accuracy: 0.5887 - val_dense_111_categorical_accuracy: 0.7014 - val_dense_112_categorical_accuracy: 0.6327 - val_dense_113_categorical_accuracy: 0.6397 - val_dense_114_categorical_accuracy: 0.5432 - val_dense_115_categorical_accuracy: 0.5229 - val_dense_116_categorical_accuracy: 0.7201 - val_dense_117_categorical_accuracy: 0.8055 - val_dense_118_categorical_accuracy: 0.6717 - val_dense_119_categorical_accuracy: 0.6236\n",
      "### F1 score:[0.7838, 0.8021333333333334, 0.7677333333333335, 0.8824666666666666, 0.43859999999999993, 0.9364, 0.8451333333333333, 0.4998, 0.7618666666666667, 0.6174666666666667, 0.5887333333333333, 0.7014, 0.6327333333333334, 0.6397333333333334, 0.5432, 0.5229333333333334, 0.7200666666666667, 0.8055333333333333, 0.6716666666666666, 0.6236] ###\n",
      "### Avg F1:0.6892499999999999 ###\n",
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/1\n",
      "105000/105000 [==============================] - 3128s 30ms/step - loss: 7.1383 - dense_100_loss: 0.2899 - dense_101_loss: 0.2690 - dense_102_loss: 0.3129 - dense_103_loss: 0.2198 - dense_104_loss: 0.4732 - dense_105_loss: 0.1468 - dense_106_loss: 0.2628 - dense_107_loss: 0.5009 - dense_108_loss: 0.3250 - dense_109_loss: 0.4294 - dense_110_loss: 0.4247 - dense_111_loss: 0.3675 - dense_112_loss: 0.4286 - dense_113_loss: 0.4020 - dense_114_loss: 0.4680 - dense_115_loss: 0.4204 - dense_116_loss: 0.3498 - dense_117_loss: 0.2834 - dense_118_loss: 0.3681 - dense_119_loss: 0.3962 - dense_100_categorical_accuracy: 0.7760 - dense_101_categorical_accuracy: 0.7970 - dense_102_categorical_accuracy: 0.7676 - dense_103_categorical_accuracy: 0.8835 - dense_104_categorical_accuracy: 0.4934 - dense_105_categorical_accuracy: 0.9360 - dense_106_categorical_accuracy: 0.8448 - dense_107_categorical_accuracy: 0.5034 - dense_108_categorical_accuracy: 0.7642 - dense_109_categorical_accuracy: 0.6117 - dense_110_categorical_accuracy: 0.5810 - dense_111_categorical_accuracy: 0.6995 - dense_112_categorical_accuracy: 0.6229 - dense_113_categorical_accuracy: 0.6342 - dense_114_categorical_accuracy: 0.5442 - dense_115_categorical_accuracy: 0.5273 - dense_116_categorical_accuracy: 0.7254 - dense_117_categorical_accuracy: 0.8073 - dense_118_categorical_accuracy: 0.6717 - dense_119_categorical_accuracy: 0.6248 - val_loss: 6.8774 - val_dense_100_loss: 0.2650 - val_dense_101_loss: 0.2528 - val_dense_102_loss: 0.2984 - val_dense_103_loss: 0.2079 - val_dense_104_loss: 0.4569 - val_dense_105_loss: 0.1284 - val_dense_106_loss: 0.2488 - val_dense_107_loss: 0.4976 - val_dense_108_loss: 0.3155 - val_dense_109_loss: 0.4202 - val_dense_110_loss: 0.4043 - val_dense_111_loss: 0.3616 - val_dense_112_loss: 0.4133 - val_dense_113_loss: 0.3964 - val_dense_114_loss: 0.4621 - val_dense_115_loss: 0.4055 - val_dense_116_loss: 0.3417 - val_dense_117_loss: 0.2704 - val_dense_118_loss: 0.3487 - val_dense_119_loss: 0.3820 - val_dense_100_categorical_accuracy: 0.7842 - val_dense_101_categorical_accuracy: 0.8021 - val_dense_102_categorical_accuracy: 0.7677 - val_dense_103_categorical_accuracy: 0.8825 - val_dense_104_categorical_accuracy: 0.5176 - val_dense_105_categorical_accuracy: 0.9364 - val_dense_106_categorical_accuracy: 0.8451 - val_dense_107_categorical_accuracy: 0.5001 - val_dense_108_categorical_accuracy: 0.7619 - val_dense_109_categorical_accuracy: 0.6175 - val_dense_110_categorical_accuracy: 0.6023 - val_dense_111_categorical_accuracy: 0.7014 - val_dense_112_categorical_accuracy: 0.6327 - val_dense_113_categorical_accuracy: 0.6397 - val_dense_114_categorical_accuracy: 0.5445 - val_dense_115_categorical_accuracy: 0.5229 - val_dense_116_categorical_accuracy: 0.7200 - val_dense_117_categorical_accuracy: 0.8055 - val_dense_118_categorical_accuracy: 0.6901 - val_dense_119_categorical_accuracy: 0.6237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 score:[0.7842, 0.8021333333333334, 0.7677333333333335, 0.8824666666666666, 0.5176, 0.9364, 0.8451333333333333, 0.5001333333333333, 0.7618666666666667, 0.6174666666666667, 0.6022666666666666, 0.7014, 0.6327333333333334, 0.6397333333333334, 0.5444666666666667, 0.5228666666666667, 0.72, 0.8055333333333333, 0.6901333333333334, 0.6236666666666667] ###\n",
      "### Avg F1:0.6948966666666667 ###\n",
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/1\n",
      "105000/105000 [==============================] - 3129s 30ms/step - loss: 6.9787 - dense_100_loss: 0.2771 - dense_101_loss: 0.2634 - dense_102_loss: 0.3046 - dense_103_loss: 0.2123 - dense_104_loss: 0.4591 - dense_105_loss: 0.1374 - dense_106_loss: 0.2573 - dense_107_loss: 0.4933 - dense_108_loss: 0.3206 - dense_109_loss: 0.4252 - dense_110_loss: 0.4127 - dense_111_loss: 0.3619 - dense_112_loss: 0.4230 - dense_113_loss: 0.3948 - dense_114_loss: 0.4629 - dense_115_loss: 0.4097 - dense_116_loss: 0.3450 - dense_117_loss: 0.2770 - dense_118_loss: 0.3534 - dense_119_loss: 0.3880 - dense_100_categorical_accuracy: 0.7815 - dense_101_categorical_accuracy: 0.7969 - dense_102_categorical_accuracy: 0.7680 - dense_103_categorical_accuracy: 0.8835 - dense_104_categorical_accuracy: 0.5270 - dense_105_categorical_accuracy: 0.9360 - dense_106_categorical_accuracy: 0.8448 - dense_107_categorical_accuracy: 0.5071 - dense_108_categorical_accuracy: 0.7642 - dense_109_categorical_accuracy: 0.6112 - dense_110_categorical_accuracy: 0.6019 - dense_111_categorical_accuracy: 0.6995 - dense_112_categorical_accuracy: 0.6234 - dense_113_categorical_accuracy: 0.6354 - dense_114_categorical_accuracy: 0.5443 - dense_115_categorical_accuracy: 0.5356 - dense_116_categorical_accuracy: 0.7274 - dense_117_categorical_accuracy: 0.8073 - dense_118_categorical_accuracy: 0.6852 - dense_119_categorical_accuracy: 0.6255 - val_loss: 6.7169 - val_dense_100_loss: 0.2512 - val_dense_101_loss: 0.2491 - val_dense_102_loss: 0.2902 - val_dense_103_loss: 0.2026 - val_dense_104_loss: 0.4397 - val_dense_105_loss: 0.1255 - val_dense_106_loss: 0.2466 - val_dense_107_loss: 0.4865 - val_dense_108_loss: 0.3126 - val_dense_109_loss: 0.4160 - val_dense_110_loss: 0.3908 - val_dense_111_loss: 0.3501 - val_dense_112_loss: 0.4125 - val_dense_113_loss: 0.3791 - val_dense_114_loss: 0.4584 - val_dense_115_loss: 0.3917 - val_dense_116_loss: 0.3395 - val_dense_117_loss: 0.2671 - val_dense_118_loss: 0.3316 - val_dense_119_loss: 0.3762 - val_dense_100_categorical_accuracy: 0.7931 - val_dense_101_categorical_accuracy: 0.8021 - val_dense_102_categorical_accuracy: 0.7677 - val_dense_103_categorical_accuracy: 0.8825 - val_dense_104_categorical_accuracy: 0.5607 - val_dense_105_categorical_accuracy: 0.9364 - val_dense_106_categorical_accuracy: 0.8451 - val_dense_107_categorical_accuracy: 0.5111 - val_dense_108_categorical_accuracy: 0.7619 - val_dense_109_categorical_accuracy: 0.6176 - val_dense_110_categorical_accuracy: 0.6304 - val_dense_111_categorical_accuracy: 0.7014 - val_dense_112_categorical_accuracy: 0.6327 - val_dense_113_categorical_accuracy: 0.6425 - val_dense_114_categorical_accuracy: 0.5454 - val_dense_115_categorical_accuracy: 0.5667 - val_dense_116_categorical_accuracy: 0.7231 - val_dense_117_categorical_accuracy: 0.8055 - val_dense_118_categorical_accuracy: 0.6942 - val_dense_119_categorical_accuracy: 0.6261\n",
      "### F1 score:[0.7930666666666666, 0.8021333333333334, 0.7677333333333335, 0.8824666666666666, 0.5606666666666666, 0.9364, 0.8451333333333333, 0.5111333333333333, 0.7618666666666667, 0.6176, 0.6304, 0.7014, 0.6327333333333334, 0.6425333333333333, 0.5454, 0.5666666666666667, 0.7231333333333333, 0.8055333333333333, 0.6942, 0.6260666666666667] ###\n",
      "### Avg F1:0.7023133333333333 ###\n",
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/1\n",
      "105000/105000 [==============================] - 3129s 30ms/step - loss: 6.8527 - dense_100_loss: 0.2682 - dense_101_loss: 0.2605 - dense_102_loss: 0.2981 - dense_103_loss: 0.2068 - dense_104_loss: 0.4493 - dense_105_loss: 0.1321 - dense_106_loss: 0.2531 - dense_107_loss: 0.4842 - dense_108_loss: 0.3166 - dense_109_loss: 0.4189 - dense_110_loss: 0.4032 - dense_111_loss: 0.3575 - dense_112_loss: 0.4181 - dense_113_loss: 0.3890 - dense_114_loss: 0.4590 - dense_115_loss: 0.4006 - dense_116_loss: 0.3411 - dense_117_loss: 0.2712 - dense_118_loss: 0.3428 - dense_119_loss: 0.3825 - dense_100_categorical_accuracy: 0.7870 - dense_101_categorical_accuracy: 0.7969 - dense_102_categorical_accuracy: 0.7685 - dense_103_categorical_accuracy: 0.8835 - dense_104_categorical_accuracy: 0.5453 - dense_105_categorical_accuracy: 0.9360 - dense_106_categorical_accuracy: 0.8448 - dense_107_categorical_accuracy: 0.5186 - dense_108_categorical_accuracy: 0.7642 - dense_109_categorical_accuracy: 0.6119 - dense_110_categorical_accuracy: 0.6170 - dense_111_categorical_accuracy: 0.6997 - dense_112_categorical_accuracy: 0.6249 - dense_113_categorical_accuracy: 0.6381 - dense_114_categorical_accuracy: 0.5472 - dense_115_categorical_accuracy: 0.5715 - dense_116_categorical_accuracy: 0.7286 - dense_117_categorical_accuracy: 0.8075 - dense_118_categorical_accuracy: 0.6924 - dense_119_categorical_accuracy: 0.6281 - val_loss: 6.6184 - val_dense_100_loss: 0.2433 - val_dense_101_loss: 0.2462 - val_dense_102_loss: 0.2855 - val_dense_103_loss: 0.1997 - val_dense_104_loss: 0.4328 - val_dense_105_loss: 0.1268 - val_dense_106_loss: 0.2465 - val_dense_107_loss: 0.4778 - val_dense_108_loss: 0.3100 - val_dense_109_loss: 0.4074 - val_dense_110_loss: 0.3854 - val_dense_111_loss: 0.3464 - val_dense_112_loss: 0.4023 - val_dense_113_loss: 0.3777 - val_dense_114_loss: 0.4537 - val_dense_115_loss: 0.3831 - val_dense_116_loss: 0.3349 - val_dense_117_loss: 0.2639 - val_dense_118_loss: 0.3218 - val_dense_119_loss: 0.3732 - val_dense_100_categorical_accuracy: 0.7989 - val_dense_101_categorical_accuracy: 0.8020 - val_dense_102_categorical_accuracy: 0.7677 - val_dense_103_categorical_accuracy: 0.8825 - val_dense_104_categorical_accuracy: 0.5644 - val_dense_105_categorical_accuracy: 0.9364 - val_dense_106_categorical_accuracy: 0.8451 - val_dense_107_categorical_accuracy: 0.5280 - val_dense_108_categorical_accuracy: 0.7619 - val_dense_109_categorical_accuracy: 0.6185 - val_dense_110_categorical_accuracy: 0.6347 - val_dense_111_categorical_accuracy: 0.7014 - val_dense_112_categorical_accuracy: 0.6356 - val_dense_113_categorical_accuracy: 0.6447 - val_dense_114_categorical_accuracy: 0.5480 - val_dense_115_categorical_accuracy: 0.5926 - val_dense_116_categorical_accuracy: 0.7232 - val_dense_117_categorical_accuracy: 0.8055 - val_dense_118_categorical_accuracy: 0.7014 - val_dense_119_categorical_accuracy: 0.6345\n",
      "### F1 score:[0.7988666666666666, 0.802, 0.7677333333333335, 0.8824666666666666, 0.5644, 0.9364, 0.8451333333333333, 0.528, 0.7618666666666667, 0.6185333333333334, 0.6347333333333334, 0.7014, 0.6356, 0.6446666666666667, 0.548, 0.5926, 0.7232, 0.8055333333333333, 0.7014, 0.6344666666666666] ###\n",
      "### Avg F1:0.7063499999999999 ###\n",
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/1\n",
      "105000/105000 [==============================] - 3128s 30ms/step - loss: 6.7467 - dense_100_loss: 0.2598 - dense_101_loss: 0.2577 - dense_102_loss: 0.2930 - dense_103_loss: 0.2027 - dense_104_loss: 0.4415 - dense_105_loss: 0.1277 - dense_106_loss: 0.2490 - dense_107_loss: 0.4771 - dense_108_loss: 0.3131 - dense_109_loss: 0.4097 - dense_110_loss: 0.3973 - dense_111_loss: 0.3528 - dense_112_loss: 0.4141 - dense_113_loss: 0.3845 - dense_114_loss: 0.4559 - dense_115_loss: 0.3934 - dense_116_loss: 0.3381 - dense_117_loss: 0.2674 - dense_118_loss: 0.3337 - dense_119_loss: 0.3781 - dense_100_categorical_accuracy: 0.7910 - dense_101_categorical_accuracy: 0.7969 - dense_102_categorical_accuracy: 0.7703 - dense_103_categorical_accuracy: 0.8835 - dense_104_categorical_accuracy: 0.5593 - dense_105_categorical_accuracy: 0.9360 - dense_106_categorical_accuracy: 0.8448 - dense_107_categorical_accuracy: 0.5258 - dense_108_categorical_accuracy: 0.7642 - dense_109_categorical_accuracy: 0.6178 - dense_110_categorical_accuracy: 0.6266 - dense_111_categorical_accuracy: 0.7010 - dense_112_categorical_accuracy: 0.6269 - dense_113_categorical_accuracy: 0.6425 - dense_114_categorical_accuracy: 0.5486 - dense_115_categorical_accuracy: 0.5917 - dense_116_categorical_accuracy: 0.7292 - dense_117_categorical_accuracy: 0.8080 - dense_118_categorical_accuracy: 0.6996 - dense_119_categorical_accuracy: 0.6305 - val_loss: 6.5620 - val_dense_100_loss: 0.2337 - val_dense_101_loss: 0.2445 - val_dense_102_loss: 0.2873 - val_dense_103_loss: 0.1988 - val_dense_104_loss: 0.4193 - val_dense_105_loss: 0.1211 - val_dense_106_loss: 0.2433 - val_dense_107_loss: 0.4696 - val_dense_108_loss: 0.3060 - val_dense_109_loss: 0.3954 - val_dense_110_loss: 0.4063 - val_dense_111_loss: 0.3481 - val_dense_112_loss: 0.4014 - val_dense_113_loss: 0.3713 - val_dense_114_loss: 0.4516 - val_dense_115_loss: 0.3776 - val_dense_116_loss: 0.3359 - val_dense_117_loss: 0.2634 - val_dense_118_loss: 0.3185 - val_dense_119_loss: 0.3690 - val_dense_100_categorical_accuracy: 0.8179 - val_dense_101_categorical_accuracy: 0.8024 - val_dense_102_categorical_accuracy: 0.7679 - val_dense_103_categorical_accuracy: 0.8825 - val_dense_104_categorical_accuracy: 0.5911 - val_dense_105_categorical_accuracy: 0.9364 - val_dense_106_categorical_accuracy: 0.8451 - val_dense_107_categorical_accuracy: 0.5339 - val_dense_108_categorical_accuracy: 0.7619 - val_dense_109_categorical_accuracy: 0.6216 - val_dense_110_categorical_accuracy: 0.5937 - val_dense_111_categorical_accuracy: 0.7014 - val_dense_112_categorical_accuracy: 0.6351 - val_dense_113_categorical_accuracy: 0.6499 - val_dense_114_categorical_accuracy: 0.5524 - val_dense_115_categorical_accuracy: 0.6210 - val_dense_116_categorical_accuracy: 0.7203 - val_dense_117_categorical_accuracy: 0.8061 - val_dense_118_categorical_accuracy: 0.7112 - val_dense_119_categorical_accuracy: 0.6323\n",
      "### F1 score:[0.8178666666666667, 0.8024, 0.7679333333333332, 0.8824666666666666, 0.5911333333333333, 0.9364, 0.8451333333333333, 0.5338666666666667, 0.7618666666666667, 0.6216, 0.5936666666666667, 0.7014, 0.6350666666666667, 0.6498666666666667, 0.5524, 0.621, 0.7203333333333334, 0.8060666666666667, 0.7112, 0.6322666666666666] ###\n",
      "### Avg F1:0.7091966666666665 ###\n",
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/1\n",
      "105000/105000 [==============================] - 3128s 30ms/step - loss: 6.6516 - dense_100_loss: 0.2508 - dense_101_loss: 0.2549 - dense_102_loss: 0.2882 - dense_103_loss: 0.1991 - dense_104_loss: 0.4340 - dense_105_loss: 0.1251 - dense_106_loss: 0.2464 - dense_107_loss: 0.4719 - dense_108_loss: 0.3098 - dense_109_loss: 0.4014 - dense_110_loss: 0.3914 - dense_111_loss: 0.3482 - dense_112_loss: 0.4098 - dense_113_loss: 0.3792 - dense_114_loss: 0.4537 - dense_115_loss: 0.3876 - dense_116_loss: 0.3350 - dense_117_loss: 0.2635 - dense_118_loss: 0.3270 - dense_119_loss: 0.3747 - dense_100_categorical_accuracy: 0.7975 - dense_101_categorical_accuracy: 0.7971 - dense_102_categorical_accuracy: 0.7730 - dense_103_categorical_accuracy: 0.8835 - dense_104_categorical_accuracy: 0.5738 - dense_105_categorical_accuracy: 0.9360 - dense_106_categorical_accuracy: 0.8448 - dense_107_categorical_accuracy: 0.5332 - dense_108_categorical_accuracy: 0.7642 - dense_109_categorical_accuracy: 0.6240 - dense_110_categorical_accuracy: 0.6342 - dense_111_categorical_accuracy: 0.7032 - dense_112_categorical_accuracy: 0.6301 - dense_113_categorical_accuracy: 0.6462 - dense_114_categorical_accuracy: 0.5504 - dense_115_categorical_accuracy: 0.6059 - dense_116_categorical_accuracy: 0.7307 - dense_117_categorical_accuracy: 0.8088 - dense_118_categorical_accuracy: 0.7069 - dense_119_categorical_accuracy: 0.6352 - val_loss: 6.4974 - val_dense_100_loss: 0.2263 - val_dense_101_loss: 0.2458 - val_dense_102_loss: 0.2863 - val_dense_103_loss: 0.1982 - val_dense_104_loss: 0.4384 - val_dense_105_loss: 0.1202 - val_dense_106_loss: 0.2418 - val_dense_107_loss: 0.4642 - val_dense_108_loss: 0.3136 - val_dense_109_loss: 0.3853 - val_dense_110_loss: 0.3856 - val_dense_111_loss: 0.3379 - val_dense_112_loss: 0.3982 - val_dense_113_loss: 0.3676 - val_dense_114_loss: 0.4514 - val_dense_115_loss: 0.3712 - val_dense_116_loss: 0.3330 - val_dense_117_loss: 0.2554 - val_dense_118_loss: 0.3122 - val_dense_119_loss: 0.3648 - val_dense_100_categorical_accuracy: 0.8169 - val_dense_101_categorical_accuracy: 0.8023 - val_dense_102_categorical_accuracy: 0.7680 - val_dense_103_categorical_accuracy: 0.8825 - val_dense_104_categorical_accuracy: 0.5334 - val_dense_105_categorical_accuracy: 0.9364 - val_dense_106_categorical_accuracy: 0.8451 - val_dense_107_categorical_accuracy: 0.5377 - val_dense_108_categorical_accuracy: 0.7619 - val_dense_109_categorical_accuracy: 0.6349 - val_dense_110_categorical_accuracy: 0.6204 - val_dense_111_categorical_accuracy: 0.7034 - val_dense_112_categorical_accuracy: 0.6365 - val_dense_113_categorical_accuracy: 0.6529 - val_dense_114_categorical_accuracy: 0.5460 - val_dense_115_categorical_accuracy: 0.6236 - val_dense_116_categorical_accuracy: 0.7212 - val_dense_117_categorical_accuracy: 0.8057 - val_dense_118_categorical_accuracy: 0.7144 - val_dense_119_categorical_accuracy: 0.6405\n",
      "### F1 score:[0.8169333333333333, 0.8022666666666667, 0.768, 0.8824666666666666, 0.5334, 0.9364, 0.8451333333333333, 0.5377333333333333, 0.7618666666666667, 0.6349333333333333, 0.6204, 0.7034, 0.6365333333333333, 0.6528666666666667, 0.546, 0.6236, 0.7212, 0.8057333333333333, 0.7144, 0.6404666666666666] ###\n",
      "### Avg F1:0.7091866666666666 ###\n",
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/1\n",
      "105000/105000 [==============================] - 3129s 30ms/step - loss: 6.5752 - dense_100_loss: 0.2444 - dense_101_loss: 0.2523 - dense_102_loss: 0.2838 - dense_103_loss: 0.1965 - dense_104_loss: 0.4270 - dense_105_loss: 0.1230 - dense_106_loss: 0.2443 - dense_107_loss: 0.4676 - dense_108_loss: 0.3075 - dense_109_loss: 0.3934 - dense_110_loss: 0.3860 - dense_111_loss: 0.3442 - dense_112_loss: 0.4070 - dense_113_loss: 0.3754 - dense_114_loss: 0.4513 - dense_115_loss: 0.3830 - dense_116_loss: 0.3334 - dense_117_loss: 0.2597 - dense_118_loss: 0.3236 - dense_119_loss: 0.3716 - dense_100_categorical_accuracy: 0.8041 - dense_101_categorical_accuracy: 0.7979 - dense_102_categorical_accuracy: 0.7748 - dense_103_categorical_accuracy: 0.8835 - dense_104_categorical_accuracy: 0.5857 - dense_105_categorical_accuracy: 0.9360 - dense_106_categorical_accuracy: 0.8448 - dense_107_categorical_accuracy: 0.5379 - dense_108_categorical_accuracy: 0.7642 - dense_109_categorical_accuracy: 0.6330 - dense_110_categorical_accuracy: 0.6435 - dense_111_categorical_accuracy: 0.7042 - dense_112_categorical_accuracy: 0.6309 - dense_113_categorical_accuracy: 0.6512 - dense_114_categorical_accuracy: 0.5530 - dense_115_categorical_accuracy: 0.6132 - dense_116_categorical_accuracy: 0.7305 - dense_117_categorical_accuracy: 0.8094 - dense_118_categorical_accuracy: 0.7098 - dense_119_categorical_accuracy: 0.6379 - val_loss: 6.4373 - val_dense_100_loss: 0.2244 - val_dense_101_loss: 0.2408 - val_dense_102_loss: 0.2806 - val_dense_103_loss: 0.1998 - val_dense_104_loss: 0.4117 - val_dense_105_loss: 0.1173 - val_dense_106_loss: 0.2448 - val_dense_107_loss: 0.4615 - val_dense_108_loss: 0.3056 - val_dense_109_loss: 0.3806 - val_dense_110_loss: 0.3807 - val_dense_111_loss: 0.3379 - val_dense_112_loss: 0.3964 - val_dense_113_loss: 0.3619 - val_dense_114_loss: 0.4465 - val_dense_115_loss: 0.3808 - val_dense_116_loss: 0.3334 - val_dense_117_loss: 0.2626 - val_dense_118_loss: 0.3079 - val_dense_119_loss: 0.3622 - val_dense_100_categorical_accuracy: 0.8136 - val_dense_101_categorical_accuracy: 0.8033 - val_dense_102_categorical_accuracy: 0.7802 - val_dense_103_categorical_accuracy: 0.8825 - val_dense_104_categorical_accuracy: 0.5940 - val_dense_105_categorical_accuracy: 0.9364 - val_dense_106_categorical_accuracy: 0.8451 - val_dense_107_categorical_accuracy: 0.5384 - val_dense_108_categorical_accuracy: 0.7619 - val_dense_109_categorical_accuracy: 0.6405 - val_dense_110_categorical_accuracy: 0.6331 - val_dense_111_categorical_accuracy: 0.7045 - val_dense_112_categorical_accuracy: 0.6396 - val_dense_113_categorical_accuracy: 0.6662 - val_dense_114_categorical_accuracy: 0.5587 - val_dense_115_categorical_accuracy: 0.5948 - val_dense_116_categorical_accuracy: 0.7218 - val_dense_117_categorical_accuracy: 0.8123 - val_dense_118_categorical_accuracy: 0.7161 - val_dense_119_categorical_accuracy: 0.6392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 score:[0.8136, 0.8033333333333333, 0.7802, 0.8824666666666666, 0.594, 0.9364, 0.8451333333333333, 0.5384, 0.7618666666666667, 0.6405333333333333, 0.6330666666666667, 0.7045333333333333, 0.6396, 0.6662, 0.5586666666666666, 0.5948, 0.7218, 0.8122666666666667, 0.7161333333333332, 0.6392] ###\n",
      "### Avg F1:0.71411 ###\n",
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/1\n",
      "105000/105000 [==============================] - 3130s 30ms/step - loss: 6.5023 - dense_100_loss: 0.2380 - dense_101_loss: 0.2508 - dense_102_loss: 0.2793 - dense_103_loss: 0.1948 - dense_104_loss: 0.4214 - dense_105_loss: 0.1216 - dense_106_loss: 0.2424 - dense_107_loss: 0.4636 - dense_108_loss: 0.3052 - dense_109_loss: 0.3869 - dense_110_loss: 0.3796 - dense_111_loss: 0.3395 - dense_112_loss: 0.4036 - dense_113_loss: 0.3707 - dense_114_loss: 0.4491 - dense_115_loss: 0.3795 - dense_116_loss: 0.3306 - dense_117_loss: 0.2561 - dense_118_loss: 0.3201 - dense_119_loss: 0.3693 - dense_100_categorical_accuracy: 0.8097 - dense_101_categorical_accuracy: 0.7978 - dense_102_categorical_accuracy: 0.7776 - dense_103_categorical_accuracy: 0.8835 - dense_104_categorical_accuracy: 0.5942 - dense_105_categorical_accuracy: 0.9360 - dense_106_categorical_accuracy: 0.8448 - dense_107_categorical_accuracy: 0.5429 - dense_108_categorical_accuracy: 0.7642 - dense_109_categorical_accuracy: 0.6407 - dense_110_categorical_accuracy: 0.6518 - dense_111_categorical_accuracy: 0.7080 - dense_112_categorical_accuracy: 0.6338 - dense_113_categorical_accuracy: 0.6566 - dense_114_categorical_accuracy: 0.5546 - dense_115_categorical_accuracy: 0.6194 - dense_116_categorical_accuracy: 0.7316 - dense_117_categorical_accuracy: 0.8112 - dense_118_categorical_accuracy: 0.7124 - dense_119_categorical_accuracy: 0.6397 - val_loss: 6.3199 - val_dense_100_loss: 0.2139 - val_dense_101_loss: 0.2374 - val_dense_102_loss: 0.2674 - val_dense_103_loss: 0.1944 - val_dense_104_loss: 0.3988 - val_dense_105_loss: 0.1180 - val_dense_106_loss: 0.2464 - val_dense_107_loss: 0.4620 - val_dense_108_loss: 0.3083 - val_dense_109_loss: 0.3735 - val_dense_110_loss: 0.3594 - val_dense_111_loss: 0.3298 - val_dense_112_loss: 0.3901 - val_dense_113_loss: 0.3574 - val_dense_114_loss: 0.4465 - val_dense_115_loss: 0.3633 - val_dense_116_loss: 0.3317 - val_dense_117_loss: 0.2528 - val_dense_118_loss: 0.3076 - val_dense_119_loss: 0.3615 - val_dense_100_categorical_accuracy: 0.8341 - val_dense_101_categorical_accuracy: 0.8041 - val_dense_102_categorical_accuracy: 0.7731 - val_dense_103_categorical_accuracy: 0.8825 - val_dense_104_categorical_accuracy: 0.6206 - val_dense_105_categorical_accuracy: 0.9364 - val_dense_106_categorical_accuracy: 0.8451 - val_dense_107_categorical_accuracy: 0.5435 - val_dense_108_categorical_accuracy: 0.7619 - val_dense_109_categorical_accuracy: 0.6487 - val_dense_110_categorical_accuracy: 0.6753 - val_dense_111_categorical_accuracy: 0.7094 - val_dense_112_categorical_accuracy: 0.6433 - val_dense_113_categorical_accuracy: 0.6695 - val_dense_114_categorical_accuracy: 0.5633 - val_dense_115_categorical_accuracy: 0.6390 - val_dense_116_categorical_accuracy: 0.7215 - val_dense_117_categorical_accuracy: 0.8078 - val_dense_118_categorical_accuracy: 0.7171 - val_dense_119_categorical_accuracy: 0.6430\n",
      "### F1 score:[0.8341333333333333, 0.8040666666666668, 0.7731333333333333, 0.8824666666666666, 0.6206, 0.9364, 0.8451333333333333, 0.5434666666666667, 0.7618666666666667, 0.6486666666666666, 0.6752666666666667, 0.7094, 0.6432666666666667, 0.6694666666666667, 0.5633333333333334, 0.639, 0.7215333333333335, 0.8078, 0.7171333333333332, 0.643] ###\n",
      "### Avg F1:0.7219566666666667 ###\n",
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/1\n",
      "105000/105000 [==============================] - 3127s 30ms/step - loss: 6.4344 - dense_100_loss: 0.2320 - dense_101_loss: 0.2486 - dense_102_loss: 0.2747 - dense_103_loss: 0.1929 - dense_104_loss: 0.4160 - dense_105_loss: 0.1188 - dense_106_loss: 0.2399 - dense_107_loss: 0.4605 - dense_108_loss: 0.3033 - dense_109_loss: 0.3813 - dense_110_loss: 0.3743 - dense_111_loss: 0.3356 - dense_112_loss: 0.4005 - dense_113_loss: 0.3665 - dense_114_loss: 0.4473 - dense_115_loss: 0.3755 - dense_116_loss: 0.3296 - dense_117_loss: 0.2528 - dense_118_loss: 0.3165 - dense_119_loss: 0.3676 - dense_100_categorical_accuracy: 0.8144 - dense_101_categorical_accuracy: 0.7990 - dense_102_categorical_accuracy: 0.7796 - dense_103_categorical_accuracy: 0.8835 - dense_104_categorical_accuracy: 0.6029 - dense_105_categorical_accuracy: 0.9360 - dense_106_categorical_accuracy: 0.8448 - dense_107_categorical_accuracy: 0.5467 - dense_108_categorical_accuracy: 0.7642 - dense_109_categorical_accuracy: 0.6473 - dense_110_categorical_accuracy: 0.6597 - dense_111_categorical_accuracy: 0.7097 - dense_112_categorical_accuracy: 0.6368 - dense_113_categorical_accuracy: 0.6612 - dense_114_categorical_accuracy: 0.5569 - dense_115_categorical_accuracy: 0.6242 - dense_116_categorical_accuracy: 0.7323 - dense_117_categorical_accuracy: 0.8127 - dense_118_categorical_accuracy: 0.7144 - dense_119_categorical_accuracy: 0.6421 - val_loss: 6.3335 - val_dense_100_loss: 0.2144 - val_dense_101_loss: 0.2376 - val_dense_102_loss: 0.2752 - val_dense_103_loss: 0.1995 - val_dense_104_loss: 0.3988 - val_dense_105_loss: 0.1145 - val_dense_106_loss: 0.2558 - val_dense_107_loss: 0.4604 - val_dense_108_loss: 0.2977 - val_dense_109_loss: 0.3766 - val_dense_110_loss: 0.3705 - val_dense_111_loss: 0.3246 - val_dense_112_loss: 0.3893 - val_dense_113_loss: 0.3556 - val_dense_114_loss: 0.4567 - val_dense_115_loss: 0.3648 - val_dense_116_loss: 0.3293 - val_dense_117_loss: 0.2455 - val_dense_118_loss: 0.3086 - val_dense_119_loss: 0.3580 - val_dense_100_categorical_accuracy: 0.8382 - val_dense_101_categorical_accuracy: 0.8044 - val_dense_102_categorical_accuracy: 0.7886 - val_dense_103_categorical_accuracy: 0.8825 - val_dense_104_categorical_accuracy: 0.6167 - val_dense_105_categorical_accuracy: 0.9364 - val_dense_106_categorical_accuracy: 0.8451 - val_dense_107_categorical_accuracy: 0.5427 - val_dense_108_categorical_accuracy: 0.7619 - val_dense_109_categorical_accuracy: 0.6456 - val_dense_110_categorical_accuracy: 0.6588 - val_dense_111_categorical_accuracy: 0.7129 - val_dense_112_categorical_accuracy: 0.6459 - val_dense_113_categorical_accuracy: 0.6691 - val_dense_114_categorical_accuracy: 0.5515 - val_dense_115_categorical_accuracy: 0.6393 - val_dense_116_categorical_accuracy: 0.7239 - val_dense_117_categorical_accuracy: 0.8168 - val_dense_118_categorical_accuracy: 0.7150 - val_dense_119_categorical_accuracy: 0.6493\n",
      "### F1 score:[0.8382, 0.8044, 0.7886, 0.8824666666666666, 0.6167333333333334, 0.9364, 0.8451333333333333, 0.5427333333333333, 0.7618666666666667, 0.6456, 0.6588, 0.7128666666666665, 0.6458666666666667, 0.6690666666666667, 0.5515333333333333, 0.6392666666666666, 0.7238666666666668, 0.8167999999999999, 0.715, 0.6492666666666667] ###\n",
      "### Avg F1:0.7222233333333333 ###\n",
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/1\n",
      "  5504/105000 [>.............................] - ETA: 49:59 - loss: 6.4138 - dense_100_loss: 0.2280 - dense_101_loss: 0.2458 - dense_102_loss: 0.2669 - dense_103_loss: 0.1949 - dense_104_loss: 0.4173 - dense_105_loss: 0.1149 - dense_106_loss: 0.2434 - dense_107_loss: 0.4567 - dense_108_loss: 0.3060 - dense_109_loss: 0.3713 - dense_110_loss: 0.3761 - dense_111_loss: 0.3401 - dense_112_loss: 0.4011 - dense_113_loss: 0.3638 - dense_114_loss: 0.4493 - dense_115_loss: 0.3723 - dense_116_loss: 0.3271 - dense_117_loss: 0.2555 - dense_118_loss: 0.3128 - dense_119_loss: 0.3704 - dense_100_categorical_accuracy: 0.8210 - dense_101_categorical_accuracy: 0.7974 - dense_102_categorical_accuracy: 0.7854 - dense_103_categorical_accuracy: 0.8830 - dense_104_categorical_accuracy: 0.5976 - dense_105_categorical_accuracy: 0.9360 - dense_106_categorical_accuracy: 0.8410 - dense_107_categorical_accuracy: 0.5491 - dense_108_categorical_accuracy: 0.7589 - dense_109_categorical_accuracy: 0.6633 - dense_110_categorical_accuracy: 0.6557 - dense_111_categorical_accuracy: 0.7039 - dense_112_categorical_accuracy: 0.6370 - dense_113_categorical_accuracy: 0.6630 - dense_114_categorical_accuracy: 0.5534 - dense_115_categorical_accuracy: 0.6245 - dense_116_categorical_accuracy: 0.7369 - dense_117_categorical_accuracy: 0.8096 - dense_118_categorical_accuracy: 0.7195 - dense_119_categorical_accuracy: 0.6328"
     ]
    }
   ],
   "source": [
    "F1 = []\n",
    "model = TextClassifier(nn_type='cnn')\n",
    "\n",
    "for i in range(30):\n",
    "\tmodel.train(Train_sequence, Train_label, Validation_sequence, Validation_label)\n",
    "\n",
    "\tvalid_pred = model.model.predict(Validation_sequence)\n",
    "\ty_pred = []\n",
    "\ty_true = []\n",
    "\tfor i in range(len(label_names)):\n",
    "\t\ty_pred.append(np.argmax(valid_pred[i], axis=1))\n",
    "\t\ty_true.append(np.argmax(Validation_label[i], axis=1))\n",
    "\tf1 = model.evaluate(y_pred, y_true)\n",
    "\tF1.append(f1)\n",
    "\tprint('### F1 score:{} ###'.format(f1))\n",
    "\tprint('### Avg F1:{} ###'.format(np.average(f1)))\n",
    "\tnp.save('models/cnn_F1.npy',F1)\n",
    "\n",
    "\tmodel.save('cnn_'+str(i))\n",
    "\n",
    "\t# clf = model.TextClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(label_names)):\n",
    "    y_pred.append(np.argmax(valid_pred[i], axis=1))\n",
    "    y_true.append(np.argmax(Validation_label[i], axis=1))\n",
    "f1 = model.evaluate(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.7838,\n",
       "  0.8021333333333334,\n",
       "  0.7677333333333335,\n",
       "  0.8824666666666666,\n",
       "  0.4488,\n",
       "  0.9364,\n",
       "  0.8451333333333333,\n",
       "  0.4998,\n",
       "  0.7618666666666667,\n",
       "  0.6174666666666667,\n",
       "  0.5383333333333333,\n",
       "  0.7014,\n",
       "  0.6327333333333334,\n",
       "  0.6397333333333334,\n",
       "  0.5424,\n",
       "  0.5229333333333334,\n",
       "  0.7172666666666666,\n",
       "  0.8055333333333333,\n",
       "  0.6716666666666666,\n",
       "  0.6236]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
