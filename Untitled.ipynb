{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Preprocessing import Preprocessor\n",
    "from model import TextClassifier\n",
    "import config\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "# 读入预处理好的数据\n",
    "Train_seq_set = np.load(config.train_sequence_path)\n",
    "Train_label_set = np.load(config.train_label_path)\n",
    "Validation_seq = np.load(config.validation_sequence_path)\n",
    "Validation_label = np.load(config.validation_label_path)\n",
    "\n",
    "p = Preprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b2a1be636df6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_group\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lstm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Challenger-text-classification/Challenger-text-classification/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, output_nodes, nn_type, model_path)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m#读取预训练的wordembedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_embedding_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m#初始化模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Challenger-text-classification/Challenger-text-classification/model.py\u001b[0m in \u001b[0;36mload_embedding_weight\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;31m## 读取词向量文件中的每一行\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0;31m## 获取当前行的词\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model1 = TextClassifier(len(config.class_group[0]),'lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = TextClassifier(len(config.class_group[0]),'lstm')\n",
    "model2 = TextClassifier(len(config.class_group[1]),'lstm')\n",
    "model3 = TextClassifier(len(config.class_group[2]),'lstm')\n",
    "model4 = TextClassifier(len(config.class_group[3]),'lstm')\n",
    "model5 = TextClassifier(len(config.class_group[4]),'lstm')\n",
    "model6 = TextClassifier(len(config.class_group[5]),'lstm')\n",
    "\n",
    "F1 = []\n",
    "for i in range(30):\n",
    "    # 训练模型\n",
    "    # train_seq1, train_label1 = p.shuffle(Train_seq_set[0], Train_label_set[0])\n",
    "    # model1.train(train_seq1, [train_label1[l] for l in range(len(config.class_group[0]))], Validation_seq, Validation_label[config.class_group[0]])\n",
    "\n",
    "    train_seq2, train_label2 = p.shuffle(Train_seq_set[1], Train_label_set[1])\n",
    "    model2.train(train_seq2, [train_label2[l] for l in range(len(config.class_group[1]))], Validation_seq, Validation_label[config.class_group[1]])\n",
    "\n",
    "    train_seq3, train_label3 = p.shuffle(Train_seq_set[2], Train_label_set[2])\n",
    "    model1.train(train_seq3, [train_label3[l] for l in range(len(config.class_group[2]))], Validation_seq, Validation_label[config.class_group[2]])\n",
    "\n",
    "    train_seq4, train_label4 = p.shuffle(Train_seq_set[3], Train_label_set[3])\n",
    "    model1.train(train_seq4, [train_label4[l] for l in range(len(config.class_group[3]))], Validation_seq, Validation_label[config.class_group[3]])\n",
    "\n",
    "    train_seq5, train_label5 = p.shuffle(Train_seq_set[4], Train_label_set[4])\n",
    "    model1.train(train_seq5, [train_label5[l] for l in range(len(config.class_group[4]))], Validation_seq, Validation_label[config.class_group[4]])\n",
    "\n",
    "    train_seq6, train_label6 = p.shuffle(Train_seq_set[5], Train_label_set[5])\n",
    "    model1.train(train_seq6, [train_label6[l] for l in range(len(config.class_group[5]))], Validation_seq, Validation_label[config.class_group[5]])\n",
    "\n",
    "    # 保存模型\n",
    "    model1.save('6lstm_1.npy')\n",
    "    model2.save('6lstm_2.npy')\n",
    "    model3.save('6lstm_3.npy')\n",
    "    model4.save('6lstm_4.npy')\n",
    "    model5.save('6lstm_5.npy')\n",
    "    model6.save('6lstm_6.npy')\n",
    "\n",
    "    # 评估模型\n",
    "    valid_pred1 = model1.predict(Validation_seq)\n",
    "    valid_pred2 = model2.predict(Validation_seq)\n",
    "    valid_pred3 = model3.predict(Validation_seq)\n",
    "    valid_pred4 = model4.predict(Validation_seq)\n",
    "    valid_pred5 = model5.predict(Validation_seq)\n",
    "    valid_pred6 = model6.predict(Validation_seq)\n",
    "    valid_pred = np.concatenate((valid_pred1, valid_pred2, valid_pred3, valid_pred4, valid_pred5, valid_pred6), axis=0)\n",
    "\n",
    "    y_pred = [np.argmax(valid_pred[i], axis=1) for i in range(20)]\n",
    "    y_true = [np.argmax(Validation_label[i], axis=1) for i in range(20)]\n",
    "    f1 = [metrics.f1_score(y_true[i], y_pred[i], average='micro') for i in range(len(valid_pred))]\n",
    "    F1.append(f1)\n",
    "    np.save(config.f1_path+'6lstm.npy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
